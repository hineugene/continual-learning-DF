{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.legacy import Adamax, Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "\n",
    "import Model \n",
    "from Model import *\n",
    "\n",
    "import utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('mon_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 빌드 \n",
    "model = DFNet.build(input_shape=(10000, 1), classes=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adamax.py:99: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Training the DF model\n",
    "NB_EPOCH = 30   # Number of training epoch\n",
    "BATCH_SIZE = 128 # Batch size\n",
    "VERBOSE = 2 # Output display mode\n",
    "LENGTH = 10000 # Packet sequence length\n",
    "OPTIMIZER = Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) # Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "print (\"Model compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "250/250 [==============================] - 31s 97ms/step - loss: 3.9271 - accuracy: 0.0715\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 3.3465 - accuracy: 0.1423\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 2.9731 - accuracy: 0.2091\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 2.6903 - accuracy: 0.2845\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 24s 97ms/step - loss: 2.4481 - accuracy: 0.3296\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 2.2479 - accuracy: 0.3860\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 2.1054 - accuracy: 0.4232\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 1.9484 - accuracy: 0.4696\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 1.7603 - accuracy: 0.5210\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 1.6149 - accuracy: 0.5587\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 1.4738 - accuracy: 0.5999\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 27s 108ms/step - loss: 1.3354 - accuracy: 0.6407\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 1.2338 - accuracy: 0.6647\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 28s 114ms/step - loss: 1.1345 - accuracy: 0.6905\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 1.0354 - accuracy: 0.7241\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.9452 - accuracy: 0.7469\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.8432 - accuracy: 0.7740\n",
      "Epoch 18/30\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.8053 - accuracy: 0.7860\n",
      "Epoch 19/30\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.7352 - accuracy: 0.8046\n",
      "Epoch 20/30\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.6889 - accuracy: 0.8154\n",
      "Epoch 21/30\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.6359 - accuracy: 0.8321\n",
      "Epoch 22/30\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.5882 - accuracy: 0.8447\n",
      "Epoch 23/30\n",
      "250/250 [==============================] - 26s 102ms/step - loss: 0.5642 - accuracy: 0.8480\n",
      "Epoch 24/30\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.5158 - accuracy: 0.8654\n",
      "Epoch 25/30\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.4686 - accuracy: 0.8708\n",
      "Epoch 26/30\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.4427 - accuracy: 0.8823\n",
      "Epoch 27/30\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.4224 - accuracy: 0.8884\n",
      "Epoch 28/30\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.3916 - accuracy: 0.8964\n",
      "Epoch 29/30\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.3750 - accuracy: 0.8996\n",
      "Epoch 30/30\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.3553 - accuracy: 0.9021\n",
      "Data_A training accuracy: 0.9021\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)  # 즉시 실행 모드 강제\n",
    "\n",
    "first_part = split_by_label(data, 0, 49)\n",
    "train, test = split_train_test(first_part, test_size=0.2, random_state=11)\n",
    "\n",
    "# 3D ndarray 로 변환 \n",
    "train_seq, train_label = split_data_label(train)\n",
    "\n",
    "train_seq = np.stack(train_seq.values)\n",
    "train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "train_label = train_label.values\n",
    "train_label = to_categorical(train_label, num_classes=95)\n",
    "                \n",
    "\n",
    "history = model.fit(x=train_seq, y=train_label, epochs=30, verbose=1)\n",
    "\n",
    "print(f\"Data_A training accuracy: {history.history['accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# HDF5 형식으로 저장\n",
    "save_model(model, 'joint_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nAIvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
