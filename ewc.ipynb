{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.legacy import Adamax\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model \n",
    "from Model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ewc_penalty(model, fisher_matrix, optimal_weights, lamb):   \n",
    "    loss = 0\n",
    "    current = model.trainable_weights \n",
    "    \n",
    "    for F, c, o in zip(fisher_matrix, current, optimal_weights):\n",
    "        loss += tf.reduce_sum(F * ((c - o) ** 2))\n",
    "\n",
    "\n",
    "    return loss * (lamb / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewc_loss(model, fisher_matrix, lamb):\n",
    "    optimal_weights = deepcopy(model.trainable_weights)\n",
    "\n",
    "    def loss_fn(y_true, y_pred):\n",
    "\n",
    "        ce_loss = CategoricalCrossentropy(from_logits=False)(y_true, y_pred)\n",
    "        ewc_loss = compute_ewc_penalty(model, fisher_matrix, optimal_weights, lamb=lamb)\n",
    "\n",
    "        return ce_loss + ewc_loss\n",
    "    \n",
    "    return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fisher_matrix(model, data, num_sample=10):\n",
    "\n",
    "    weights = model.trainable_weights\n",
    "    variance = [tf.zeros_like(tensor) for tensor in weights]\n",
    "\n",
    "\n",
    "\n",
    "    # [ë””ë²„ê¹… ì¶”ê°€]\n",
    "    print(\"ðŸ” [DEBUG] Initial weights shape:\")\n",
    "    for i, w in enumerate(weights):\n",
    "        print(f\" - Weight {i}: {w.shape}\")\n",
    "    '''\n",
    "    for i, (x, y) in enumerate(data):\n",
    "        if i >= num_sample:\n",
    "            break\n",
    "\n",
    "        print(f\"\\nðŸ“¦ [DEBUG] Sample {i} input shape: x={x.shape}, y={y.shape}\")\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    # num_sample ê°œì˜ ë°ì´í„° ëžœë¤ìƒ˜í”Œë§ \n",
    "    indices = np.random.choice(len(data), size=num_sample, replace=False)\n",
    "\n",
    "    for i in indices:\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(weights)\n",
    "            x = tf.expand_dims(data[i], axis=0)\n",
    "            output = model(x, training=False) # (ìˆ˜ì •) ë©”ëª¨ë¦¬ ë¬¸ì œ, ëª¨ë“  ë°ì´í„°ë¥¼ í•œë²ˆì— ë„£ìœ¼ë©´ ì˜¤ë¥˜ ìƒê¹€. ì—¬ê¸°ì„œëŠ” í•˜ë‚˜ì”© ì—´ê°œì˜ ë°ì´í„°ë¥¼ ì‚¬ìš© \n",
    "            log_likelihood = tf.math.log(output)\n",
    "\n",
    "        gradients = tape.gradient(log_likelihood, weights)\n",
    "        variance = [var + (grad ** 2) for var, grad in zip(variance, gradients)]\n",
    "\n",
    "    fisher_matrix = [tensor / num_sample for tensor in variance]\n",
    "\n",
    "\n",
    "    # [ë””ë²„ê¹… ì¶”ê°€]\n",
    "    print(\"\\nâœ… [DEBUG] Fisher matrix shapes:\")\n",
    "    for i, f in enumerate(fisher_matrix):\n",
    "        print(f\" - Fisher {i}: {f.shape}\")\n",
    "\n",
    "    \n",
    "    return fisher_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ìˆ˜ì •) ë°°ì¹˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ \n",
    "def evaluate(model, test_set):\n",
    "  acc = tf.keras.metrics.CategoricalAccuracy(name='accuracy')\n",
    "  for i, (seq, labels) in enumerate(test_set):\n",
    "    preds = model.predict_on_batch(seq)\n",
    "    acc.update_state(labels, preds)\n",
    "  return acc.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(model, OPTIMIZER, data, test_size,\n",
    "                first_task = 44, inc_task = 5, first_epochs = 30, inc_epochs = 5,\n",
    "                  lamb=0, num_sample=10):\n",
    "    \n",
    "    first_part = split_by_label(data, 0, first_task)\n",
    "    train, test = split_train_test(first_part, test_size=test_size, random_state=11)\n",
    "    \n",
    "\n",
    "    # OPTIMIZER -> param\n",
    "    i = 0\n",
    "    while(1):\n",
    "\n",
    "        if ( first_task + i * inc_task ) < MAX_LABEL:\n",
    "            \n",
    "            if i == 0:\n",
    "                model.compile(loss=CategoricalCrossentropy(from_logits=False), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "                # 3D ndarray ë¡œ ë³€í™˜ \n",
    "                train_seq, train_label = split_data_label(train)\n",
    "\n",
    "                train_seq = np.stack(train_seq.values)\n",
    "                train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "                train_label = train_label.values\n",
    "                train_label = to_categorical(train_label, num_classes=MAX_LABEL)\n",
    "                \n",
    "\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=first_epochs, verbose=1)\n",
    "                print(f\"   Task_0 training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "                # Fisher matrix ê³„ì‚° \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "            else:\n",
    "                # ë°ì´í„° ì¤€ë¹„ \n",
    "                inc_part = split_by_label(data, first_task + (i-1) * inc_task + 1, first_task + i * inc_task )\n",
    "                train, inc_test = split_train_test(inc_part, test_size=test_size, random_state=11)\n",
    "\n",
    "                # [ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€]\n",
    "                optimal_weights = deepcopy(model.trainable_weights)\n",
    "\n",
    "                print(\"ðŸ§  [DEBUG] Optimal weights (after task):\")\n",
    "                for index, w in enumerate(optimal_weights):\n",
    "                    print(f\" - Weight {index}: {w.shape}, mean={tf.reduce_mean(w):.4f}, std={tf.math.reduce_std(w):.4f}\")\n",
    "\n",
    "\n",
    "                model.compile(loss=ewc_loss(model, fisher_matrix, lamb=lamb), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "                \n",
    "                # 3D ndarray ë¡œ ë³€í™˜ (ì´ë¶€ë¶„ í•¨ìˆ˜ë¡œ ë°”ê¾¸ê¸°)\n",
    "                train_seq, train_label = split_data_label(train)\n",
    "\n",
    "                train_seq = np.stack(train_seq.values)\n",
    "                train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "                train_label = train_label.values\n",
    "                train_label = to_categorical(train_label, num_classes=MAX_LABEL)\n",
    "\n",
    "\n",
    "\n",
    "                # train\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=inc_epochs, verbose=1)\n",
    "                print(f\"   Task_{i} training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "                # (ìˆ˜ì •) ì¼ì¢…ì˜ ì „ì²˜ë¦¬ì´ë¯€ë¡œ preprocessing ë˜ëŠ” utilsì— í•¨ìˆ˜ ìž‘ì„± \n",
    "                # ì¶•ì ëœ testë¡œ ì •í™•ë„ ì¸¡ì • (ì¤‘ìš”, EWC ì„±ëŠ¥)\n",
    "                test_seq, test_label = split_data_label(test)\n",
    "                test_seq = np.stack(test_seq.values)\n",
    "                test_seq = test_seq[..., np.newaxis]\n",
    "\n",
    "                test_label = test_label.values\n",
    "                test_label = to_categorical(test_label, num_classes=MAX_LABEL)\n",
    "\n",
    "                test_ = tf.data.Dataset.from_tensor_slices((test_seq, test_label))\n",
    "                test_ = test_.batch(32) #(ìˆ˜ì •) ëª¨ë¸ ìžì²´ ë°°ì¹˜ ì¡´ìž¬? - í•™ìŠµì‹œ fit ë””í´íŠ¸ê°’ë„ 32\n",
    "\n",
    "                inc_accuracy = evaluate(model, test_)\n",
    "                print(f\"Task ~{i-1} accuracy after training on Task_{i}: {inc_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # test ì—…ë°ì´íŠ¸ \n",
    "                test = accumulate_data(test, inc_test)\n",
    "\n",
    "                # Fisher matrix ê³„ì‚° \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "        else:\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop_nonbase(model, OPTIMIZER, data, test_size,\n",
    "                first_task = 44, inc_task = 5, first_epochs = 30, inc_epochs = 5,\n",
    "                  lamb=0, num_sample=10):\n",
    "    \n",
    "    first_part = split_by_label(data, 0, first_task)\n",
    "    train, test = split_train_test(first_part, test_size=test_size, random_state=11)\n",
    "    \n",
    "\n",
    "    # OPTIMIZER -> param\n",
    "    i = 0\n",
    "    while(1):\n",
    "\n",
    "        if ( first_task + i * inc_task ) < MAX_LABEL:\n",
    "            \n",
    "            if i == 0:\n",
    "                model.compile(loss=CategoricalCrossentropy(from_logits=False), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "                # 3D ndarray ë¡œ ë³€í™˜ \n",
    "                train_seq, train_label = split_data_label(train)\n",
    "\n",
    "                train_seq = np.stack(train_seq.values)\n",
    "                train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "                train_label = train_label.values\n",
    "                train_label = to_categorical(train_label, num_classes=MAX_LABEL)\n",
    "                \n",
    "\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=first_epochs, verbose=1)\n",
    "                print(f\"   Task_0 training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "                # Fisher matrix ê³„ì‚° \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "            else:\n",
    "                # ë°ì´í„° ì¤€ë¹„ \n",
    "                inc_part = split_by_label(data, first_task + (i-1) * inc_task + 1, first_task + i * inc_task )\n",
    "                train, inc_test = split_train_test(inc_part, test_size=test_size, random_state=11)\n",
    "\n",
    "                model.compile(loss=CategoricalCrossentropy(from_logits=False), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "                \n",
    "                # 3D ndarray ë¡œ ë³€í™˜ (ì´ë¶€ë¶„ í•¨ìˆ˜ë¡œ ë°”ê¾¸ê¸°)\n",
    "                train_seq, train_label = split_data_label(train)\n",
    "\n",
    "                train_seq = np.stack(train_seq.values)\n",
    "                train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "                train_label = train_label.values\n",
    "                train_label = to_categorical(train_label, num_classes=MAX_LABEL)\n",
    "\n",
    "\n",
    "\n",
    "                # train\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=inc_epochs, verbose=1)\n",
    "                print(f\"   Task_{i} training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "                # (ìˆ˜ì •) ì¼ì¢…ì˜ ì „ì²˜ë¦¬ì´ë¯€ë¡œ preprocessing ë˜ëŠ” utilsì— í•¨ìˆ˜ ìž‘ì„± \n",
    "                # ì¶•ì ëœ testë¡œ ì •í™•ë„ ì¸¡ì • (ì¤‘ìš”, EWC ì„±ëŠ¥)\n",
    "                test_seq, test_label = split_data_label(test)\n",
    "                test_seq = np.stack(test_seq.values)\n",
    "                test_seq = test_seq[..., np.newaxis]\n",
    "\n",
    "                test_label = test_label.values\n",
    "                test_label = to_categorical(test_label, num_classes=MAX_LABEL)\n",
    "\n",
    "                test_ = tf.data.Dataset.from_tensor_slices((test_seq, test_label))\n",
    "                test_ = test_.batch(32) #(ìˆ˜ì •) ëª¨ë¸ ìžì²´ ë°°ì¹˜ ì¡´ìž¬? - í•™ìŠµì‹œ fit ë””í´íŠ¸ê°’ë„ 32\n",
    "\n",
    "                inc_accuracy = evaluate(model, test_)\n",
    "                print(f\"Task ~{i-1} accuracy after training on Task_{i}: {inc_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # test ì—…ë°ì´íŠ¸ \n",
    "                test = accumulate_data(test, inc_test)\n",
    "\n",
    "                # Fisher matrix ê³„ì‚° \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "        else:\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_joint(model, OPTIMIZER, data, test_size,\n",
    "                first_task = 44, inc_task = 5, first_epochs = 30, inc_epochs = 5,\n",
    "                  lamb=0, num_sample=10):\n",
    "    \n",
    "    first_part = split_by_label(data, 0, first_task)\n",
    "    train, test = split_train_test(first_part, test_size=test_size, random_state=11)\n",
    "    \n",
    "\n",
    "    # OPTIMIZER -> param\n",
    "    i = 0\n",
    "    while(1):\n",
    "\n",
    "        if ( first_task + i * inc_task ) <= MAX_LABEL:\n",
    "            \n",
    "            if i == 0:\n",
    "                model.compile(loss=CategoricalCrossentropy(from_logits=False), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "                # 3D ndarray ë¡œ ë³€í™˜ \n",
    "                train_seq, train_label = split_data_label(train)\n",
    "\n",
    "                train_seq = np.stack(train_seq.values)\n",
    "                train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "                train_label = train_label.values\n",
    "                train_label = to_categorical(train_label, num_classes=MAX_LABEL)\n",
    "                \n",
    "\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=first_epochs, verbose=2)\n",
    "                print(f\"   First_task training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "                # Fisher matrix ê³„ì‚° \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "            else:\n",
    "                # ë°ì´í„° ì¤€ë¹„ \n",
    "                inc_part = split_by_label(data, first_task + (i-1) * inc_task + 1, first_task + i * inc_task )\n",
    "                inc_train, inc_test = split_train_test(inc_part, test_size=test_size, random_state=11)\n",
    "                train = accumulate_data(train, inc_train)\n",
    "\n",
    "                model.compile(loss=CategoricalCrossentropy(from_logits=False), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "                \n",
    "                # 3D ndarray ë¡œ ë³€í™˜ (ì´ë¶€ë¶„ í•¨ìˆ˜ë¡œ ë°”ê¾¸ê¸°)\n",
    "                train_seq, train_label = split_data_label(train)\n",
    "\n",
    "                train_seq = np.stack(train_seq.values)\n",
    "                train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "                train_label = train_label.values\n",
    "                train_label = to_categorical(train_label, num_classes=MAX_LABEL)\n",
    "\n",
    "\n",
    "\n",
    "                # train\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=inc_epochs, verbose=2)\n",
    "                print(f\"   {i}_task training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "                # (ìˆ˜ì •) ì¼ì¢…ì˜ ì „ì²˜ë¦¬ì´ë¯€ë¡œ preprocessing ë˜ëŠ” utilsì— í•¨ìˆ˜ ìž‘ì„± \n",
    "                # ì¶•ì ëœ testë¡œ ì •í™•ë„ ì¸¡ì • (ì¤‘ìš”, EWC ì„±ëŠ¥)\n",
    "                test_seq, test_label = split_data_label(test)\n",
    "                test_seq = np.stack(test_seq.values)\n",
    "                test_seq = test_seq[..., np.newaxis]\n",
    "\n",
    "                test_label = test_label.values\n",
    "                test_label = to_categorical(test_label, num_classes=MAX_LABEL)\n",
    "\n",
    "                test_ = tf.data.Dataset.from_tensor_slices((test_seq, test_label))\n",
    "                test_ = test_.batch(32) #(ìˆ˜ì •) ëª¨ë¸ ìžì²´ ë°°ì¹˜ ì¡´ìž¬? - í•™ìŠµì‹œ fit ë””í´íŠ¸ê°’ë„ 32\n",
    "\n",
    "                inc_accuracy = evaluate(model, test_)\n",
    "                print(f\"Task {i} accuracy after training on Task ~{i-1}: {inc_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # test ì—…ë°ì´íŠ¸ \n",
    "                test = accumulate_data(test, inc_test)\n",
    "\n",
    "                # Fisher matrix ê³„ì‚° \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "        else:\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 2)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_pickle('mon_data.pkl')\n",
    "print(data.shape)\n",
    "MAX_LABEL = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adamax.py:99: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 13s 56ms/step - loss: 3.8650 - accuracy: 0.0787\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 3.3134 - accuracy: 0.1359\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 3.0236 - accuracy: 0.1859\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 2.8391 - accuracy: 0.2202\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 2.6588 - accuracy: 0.2584\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 2.4908 - accuracy: 0.3055\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 2.3125 - accuracy: 0.3486\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 2.2086 - accuracy: 0.3734\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 2.0426 - accuracy: 0.4273\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.9206 - accuracy: 0.4602\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.8199 - accuracy: 0.4905\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.6854 - accuracy: 0.5339\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.5356 - accuracy: 0.5755\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.4420 - accuracy: 0.5972\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.3539 - accuracy: 0.6303\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.2557 - accuracy: 0.6531\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.1785 - accuracy: 0.6794\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.0690 - accuracy: 0.7100\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.0024 - accuracy: 0.7297\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.9395 - accuracy: 0.7492\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.8877 - accuracy: 0.7614\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.8197 - accuracy: 0.7830\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.7558 - accuracy: 0.7994\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.7160 - accuracy: 0.8169\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.6604 - accuracy: 0.8253\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.6407 - accuracy: 0.8305\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.5900 - accuracy: 0.8427\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.5736 - accuracy: 0.8416\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.5098 - accuracy: 0.8622\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.4930 - accuracy: 0.8730\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.4740 - accuracy: 0.8750\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.4328 - accuracy: 0.8836\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.4110 - accuracy: 0.8898\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.3954 - accuracy: 0.8958\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.3743 - accuracy: 0.9048\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.3557 - accuracy: 0.9041\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.3472 - accuracy: 0.9056\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.3185 - accuracy: 0.9131\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.2974 - accuracy: 0.9181\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.2879 - accuracy: 0.9236\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.2823 - accuracy: 0.9242\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.2620 - accuracy: 0.9291\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.2479 - accuracy: 0.9322\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.2545 - accuracy: 0.9316\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.2281 - accuracy: 0.9384\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.2375 - accuracy: 0.9372\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.2146 - accuracy: 0.9423\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.2146 - accuracy: 0.9439\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.2081 - accuracy: 0.9461\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.1847 - accuracy: 0.9511\n",
      "   Task_0 training accuracy: 0.9511\n",
      "ðŸ” [DEBUG] Initial weights shape:\n",
      " - Weight 0: (8, 1, 32)\n",
      " - Weight 1: (32,)\n",
      " - Weight 2: (32,)\n",
      " - Weight 3: (32,)\n",
      " - Weight 4: (8, 32, 32)\n",
      " - Weight 5: (32,)\n",
      " - Weight 6: (32,)\n",
      " - Weight 7: (32,)\n",
      " - Weight 8: (8, 32, 64)\n",
      " - Weight 9: (64,)\n",
      " - Weight 10: (64,)\n",
      " - Weight 11: (64,)\n",
      " - Weight 12: (8, 64, 64)\n",
      " - Weight 13: (64,)\n",
      " - Weight 14: (64,)\n",
      " - Weight 15: (64,)\n",
      " - Weight 16: (8, 64, 128)\n",
      " - Weight 17: (128,)\n",
      " - Weight 18: (128,)\n",
      " - Weight 19: (128,)\n",
      " - Weight 20: (8, 128, 128)\n",
      " - Weight 21: (128,)\n",
      " - Weight 22: (128,)\n",
      " - Weight 23: (128,)\n",
      " - Weight 24: (8, 128, 256)\n",
      " - Weight 25: (256,)\n",
      " - Weight 26: (256,)\n",
      " - Weight 27: (256,)\n",
      " - Weight 28: (8, 256, 256)\n",
      " - Weight 29: (256,)\n",
      " - Weight 30: (256,)\n",
      " - Weight 31: (256,)\n",
      " - Weight 32: (8, 256, 512)\n",
      " - Weight 33: (512,)\n",
      " - Weight 34: (512,)\n",
      " - Weight 35: (512,)\n",
      " - Weight 36: (8, 512, 512)\n",
      " - Weight 37: (512,)\n",
      " - Weight 38: (512,)\n",
      " - Weight 39: (512,)\n",
      " - Weight 40: (5120, 512)\n",
      " - Weight 41: (512,)\n",
      " - Weight 42: (512,)\n",
      " - Weight 43: (512,)\n",
      " - Weight 44: (512, 512)\n",
      " - Weight 45: (512,)\n",
      " - Weight 46: (512,)\n",
      " - Weight 47: (512,)\n",
      " - Weight 48: (512, 95)\n",
      " - Weight 49: (95,)\n",
      "\n",
      "âœ… [DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32)\n",
      " - Fisher 1: (32,)\n",
      " - Fisher 2: (32,)\n",
      " - Fisher 3: (32,)\n",
      " - Fisher 4: (8, 32, 32)\n",
      " - Fisher 5: (32,)\n",
      " - Fisher 6: (32,)\n",
      " - Fisher 7: (32,)\n",
      " - Fisher 8: (8, 32, 64)\n",
      " - Fisher 9: (64,)\n",
      " - Fisher 10: (64,)\n",
      " - Fisher 11: (64,)\n",
      " - Fisher 12: (8, 64, 64)\n",
      " - Fisher 13: (64,)\n",
      " - Fisher 14: (64,)\n",
      " - Fisher 15: (64,)\n",
      " - Fisher 16: (8, 64, 128)\n",
      " - Fisher 17: (128,)\n",
      " - Fisher 18: (128,)\n",
      " - Fisher 19: (128,)\n",
      " - Fisher 20: (8, 128, 128)\n",
      " - Fisher 21: (128,)\n",
      " - Fisher 22: (128,)\n",
      " - Fisher 23: (128,)\n",
      " - Fisher 24: (8, 128, 256)\n",
      " - Fisher 25: (256,)\n",
      " - Fisher 26: (256,)\n",
      " - Fisher 27: (256,)\n",
      " - Fisher 28: (8, 256, 256)\n",
      " - Fisher 29: (256,)\n",
      " - Fisher 30: (256,)\n",
      " - Fisher 31: (256,)\n",
      " - Fisher 32: (8, 256, 512)\n",
      " - Fisher 33: (512,)\n",
      " - Fisher 34: (512,)\n",
      " - Fisher 35: (512,)\n",
      " - Fisher 36: (8, 512, 512)\n",
      " - Fisher 37: (512,)\n",
      " - Fisher 38: (512,)\n",
      " - Fisher 39: (512,)\n",
      " - Fisher 40: (5120, 512)\n",
      " - Fisher 41: (512,)\n",
      " - Fisher 42: (512,)\n",
      " - Fisher 43: (512,)\n",
      " - Fisher 44: (512, 512)\n",
      " - Fisher 45: (512,)\n",
      " - Fisher 46: (512,)\n",
      " - Fisher 47: (512,)\n",
      " - Fisher 48: (512, 95)\n",
      " - Fisher 49: (95,)\n",
      "ðŸ§  [DEBUG] Optimal weights (after task):\n",
      " - Weight 0: (8, 1, 32), mean=-0.0086, std=0.0927\n",
      " - Weight 1: (32,), mean=-0.0036, std=0.0200\n",
      " - Weight 2: (32,), mean=1.0196, std=0.0372\n",
      " - Weight 3: (32,), mean=-0.0284, std=0.0392\n",
      " - Weight 4: (8, 32, 32), mean=0.0042, std=0.0687\n",
      " - Weight 5: (32,), mean=0.0030, std=0.0270\n",
      " - Weight 6: (32,), mean=0.9998, std=0.0442\n",
      " - Weight 7: (32,), mean=-0.1683, std=0.0543\n",
      " - Weight 8: (8, 32, 64), mean=0.0012, std=0.0579\n",
      " - Weight 9: (64,), mean=-0.0009, std=0.0079\n",
      " - Weight 10: (64,), mean=1.0031, std=0.0361\n",
      " - Weight 11: (64,), mean=-0.0251, std=0.0551\n",
      " - Weight 12: (8, 64, 64), mean=0.0035, std=0.0507\n",
      " - Weight 13: (64,), mean=-0.0018, std=0.0068\n",
      " - Weight 14: (64,), mean=1.0028, std=0.0402\n",
      " - Weight 15: (64,), mean=-0.0791, std=0.0332\n",
      " - Weight 16: (8, 64, 128), mean=-0.0005, std=0.0444\n",
      " - Weight 17: (128,), mean=0.0001, std=0.0048\n",
      " - Weight 18: (128,), mean=1.0031, std=0.0582\n",
      " - Weight 19: (128,), mean=-0.0079, std=0.0466\n",
      " - Weight 20: (8, 128, 128), mean=-0.0016, std=0.0393\n",
      " - Weight 21: (128,), mean=-0.0006, std=0.0048\n",
      " - Weight 22: (128,), mean=1.0063, std=0.0483\n",
      " - Weight 23: (128,), mean=-0.0778, std=0.0429\n",
      " - Weight 24: (8, 128, 256), mean=-0.0007, std=0.0359\n",
      " - Weight 25: (256,), mean=0.0003, std=0.0030\n",
      " - Weight 26: (256,), mean=0.9992, std=0.0702\n",
      " - Weight 27: (256,), mean=-0.0715, std=0.0554\n",
      " - Weight 28: (8, 256, 256), mean=-0.0029, std=0.0320\n",
      " - Weight 29: (256,), mean=0.0007, std=0.0036\n",
      " - Weight 30: (256,), mean=0.9982, std=0.0488\n",
      " - Weight 31: (256,), mean=-0.1319, std=0.0497\n",
      " - Weight 32: (8, 256, 512), mean=-0.0024, std=0.0303\n",
      " - Weight 33: (512,), mean=0.0003, std=0.0021\n",
      " - Weight 34: (512,), mean=0.9904, std=0.0523\n",
      " - Weight 35: (512,), mean=-0.1572, std=0.0473\n",
      " - Weight 36: (8, 512, 512), mean=-0.0021, std=0.0277\n",
      " - Weight 37: (512,), mean=0.0007, std=0.0029\n",
      " - Weight 38: (512,), mean=0.9903, std=0.0502\n",
      " - Weight 39: (512,), mean=-0.1828, std=0.0345\n",
      " - Weight 40: (5120, 512), mean=0.0003, std=0.0255\n",
      " - Weight 41: (512,), mean=0.0001, std=0.0021\n",
      " - Weight 42: (512,), mean=1.0013, std=0.0222\n",
      " - Weight 43: (512,), mean=-0.0734, std=0.0281\n",
      " - Weight 44: (512, 512), mean=-0.0006, std=0.0479\n",
      " - Weight 45: (512,), mean=-0.0000, std=0.0033\n",
      " - Weight 46: (512,), mean=1.0915, std=0.0442\n",
      " - Weight 47: (512,), mean=0.0658, std=0.0422\n",
      " - Weight 48: (512, 95), mean=-0.0570, std=0.0797\n",
      " - Weight 49: (95,), mean=-0.1186, std=0.1085\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 6s 62ms/step - loss: 25.2317 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 19.7198 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 15.8100 - accuracy: 6.2500e-04\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 12.6813 - accuracy: 0.0075\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 10.2856 - accuracy: 0.0506\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 8.8502 - accuracy: 0.1238\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 7.5628 - accuracy: 0.2294\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 6.6320 - accuracy: 0.3212\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 5.9416 - accuracy: 0.3981\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 5.6986 - accuracy: 0.4256\n",
      "   Task_1 training accuracy: 0.4256\n",
      "Task ~0 accuracy after training on Task_1: 0.5462\n",
      "ðŸ” [DEBUG] Initial weights shape:\n",
      " - Weight 0: (8, 1, 32)\n",
      " - Weight 1: (32,)\n",
      " - Weight 2: (32,)\n",
      " - Weight 3: (32,)\n",
      " - Weight 4: (8, 32, 32)\n",
      " - Weight 5: (32,)\n",
      " - Weight 6: (32,)\n",
      " - Weight 7: (32,)\n",
      " - Weight 8: (8, 32, 64)\n",
      " - Weight 9: (64,)\n",
      " - Weight 10: (64,)\n",
      " - Weight 11: (64,)\n",
      " - Weight 12: (8, 64, 64)\n",
      " - Weight 13: (64,)\n",
      " - Weight 14: (64,)\n",
      " - Weight 15: (64,)\n",
      " - Weight 16: (8, 64, 128)\n",
      " - Weight 17: (128,)\n",
      " - Weight 18: (128,)\n",
      " - Weight 19: (128,)\n",
      " - Weight 20: (8, 128, 128)\n",
      " - Weight 21: (128,)\n",
      " - Weight 22: (128,)\n",
      " - Weight 23: (128,)\n",
      " - Weight 24: (8, 128, 256)\n",
      " - Weight 25: (256,)\n",
      " - Weight 26: (256,)\n",
      " - Weight 27: (256,)\n",
      " - Weight 28: (8, 256, 256)\n",
      " - Weight 29: (256,)\n",
      " - Weight 30: (256,)\n",
      " - Weight 31: (256,)\n",
      " - Weight 32: (8, 256, 512)\n",
      " - Weight 33: (512,)\n",
      " - Weight 34: (512,)\n",
      " - Weight 35: (512,)\n",
      " - Weight 36: (8, 512, 512)\n",
      " - Weight 37: (512,)\n",
      " - Weight 38: (512,)\n",
      " - Weight 39: (512,)\n",
      " - Weight 40: (5120, 512)\n",
      " - Weight 41: (512,)\n",
      " - Weight 42: (512,)\n",
      " - Weight 43: (512,)\n",
      " - Weight 44: (512, 512)\n",
      " - Weight 45: (512,)\n",
      " - Weight 46: (512,)\n",
      " - Weight 47: (512,)\n",
      " - Weight 48: (512, 95)\n",
      " - Weight 49: (95,)\n",
      "\n",
      "âœ… [DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32)\n",
      " - Fisher 1: (32,)\n",
      " - Fisher 2: (32,)\n",
      " - Fisher 3: (32,)\n",
      " - Fisher 4: (8, 32, 32)\n",
      " - Fisher 5: (32,)\n",
      " - Fisher 6: (32,)\n",
      " - Fisher 7: (32,)\n",
      " - Fisher 8: (8, 32, 64)\n",
      " - Fisher 9: (64,)\n",
      " - Fisher 10: (64,)\n",
      " - Fisher 11: (64,)\n",
      " - Fisher 12: (8, 64, 64)\n",
      " - Fisher 13: (64,)\n",
      " - Fisher 14: (64,)\n",
      " - Fisher 15: (64,)\n",
      " - Fisher 16: (8, 64, 128)\n",
      " - Fisher 17: (128,)\n",
      " - Fisher 18: (128,)\n",
      " - Fisher 19: (128,)\n",
      " - Fisher 20: (8, 128, 128)\n",
      " - Fisher 21: (128,)\n",
      " - Fisher 22: (128,)\n",
      " - Fisher 23: (128,)\n",
      " - Fisher 24: (8, 128, 256)\n",
      " - Fisher 25: (256,)\n",
      " - Fisher 26: (256,)\n",
      " - Fisher 27: (256,)\n",
      " - Fisher 28: (8, 256, 256)\n",
      " - Fisher 29: (256,)\n",
      " - Fisher 30: (256,)\n",
      " - Fisher 31: (256,)\n",
      " - Fisher 32: (8, 256, 512)\n",
      " - Fisher 33: (512,)\n",
      " - Fisher 34: (512,)\n",
      " - Fisher 35: (512,)\n",
      " - Fisher 36: (8, 512, 512)\n",
      " - Fisher 37: (512,)\n",
      " - Fisher 38: (512,)\n",
      " - Fisher 39: (512,)\n",
      " - Fisher 40: (5120, 512)\n",
      " - Fisher 41: (512,)\n",
      " - Fisher 42: (512,)\n",
      " - Fisher 43: (512,)\n",
      " - Fisher 44: (512, 512)\n",
      " - Fisher 45: (512,)\n",
      " - Fisher 46: (512,)\n",
      " - Fisher 47: (512,)\n",
      " - Fisher 48: (512, 95)\n",
      " - Fisher 49: (95,)\n",
      "ðŸ§  [DEBUG] Optimal weights (after task):\n",
      " - Weight 0: (8, 1, 32), mean=-0.0086, std=0.0927\n",
      " - Weight 1: (32,), mean=-0.0036, std=0.0200\n",
      " - Weight 2: (32,), mean=1.0196, std=0.0371\n",
      " - Weight 3: (32,), mean=-0.0284, std=0.0392\n",
      " - Weight 4: (8, 32, 32), mean=0.0041, std=0.0687\n",
      " - Weight 5: (32,), mean=0.0030, std=0.0270\n",
      " - Weight 6: (32,), mean=0.9998, std=0.0442\n",
      " - Weight 7: (32,), mean=-0.1683, std=0.0543\n",
      " - Weight 8: (8, 32, 64), mean=0.0012, std=0.0580\n",
      " - Weight 9: (64,), mean=-0.0009, std=0.0079\n",
      " - Weight 10: (64,), mean=1.0032, std=0.0361\n",
      " - Weight 11: (64,), mean=-0.0251, std=0.0551\n",
      " - Weight 12: (8, 64, 64), mean=0.0040, std=0.0510\n",
      " - Weight 13: (64,), mean=-0.0018, std=0.0068\n",
      " - Weight 14: (64,), mean=1.0028, std=0.0402\n",
      " - Weight 15: (64,), mean=-0.0791, std=0.0332\n",
      " - Weight 16: (8, 64, 128), mean=-0.0003, std=0.0444\n",
      " - Weight 17: (128,), mean=0.0001, std=0.0048\n",
      " - Weight 18: (128,), mean=1.0033, std=0.0581\n",
      " - Weight 19: (128,), mean=-0.0079, std=0.0466\n",
      " - Weight 20: (8, 128, 128), mean=-0.0014, std=0.0395\n",
      " - Weight 21: (128,), mean=-0.0006, std=0.0048\n",
      " - Weight 22: (128,), mean=1.0063, std=0.0482\n",
      " - Weight 23: (128,), mean=-0.0778, std=0.0429\n",
      " - Weight 24: (8, 128, 256), mean=-0.0005, std=0.0359\n",
      " - Weight 25: (256,), mean=0.0003, std=0.0030\n",
      " - Weight 26: (256,), mean=0.9992, std=0.0701\n",
      " - Weight 27: (256,), mean=-0.0715, std=0.0553\n",
      " - Weight 28: (8, 256, 256), mean=-0.0028, std=0.0321\n",
      " - Weight 29: (256,), mean=0.0007, std=0.0036\n",
      " - Weight 30: (256,), mean=0.9982, std=0.0488\n",
      " - Weight 31: (256,), mean=-0.1319, std=0.0497\n",
      " - Weight 32: (8, 256, 512), mean=-0.0023, std=0.0303\n",
      " - Weight 33: (512,), mean=0.0003, std=0.0021\n",
      " - Weight 34: (512,), mean=0.9904, std=0.0522\n",
      " - Weight 35: (512,), mean=-0.1572, std=0.0473\n",
      " - Weight 36: (8, 512, 512), mean=-0.0019, std=0.0277\n",
      " - Weight 37: (512,), mean=0.0007, std=0.0029\n",
      " - Weight 38: (512,), mean=0.9903, std=0.0501\n",
      " - Weight 39: (512,), mean=-0.1828, std=0.0345\n",
      " - Weight 40: (5120, 512), mean=0.0008, std=0.0255\n",
      " - Weight 41: (512,), mean=0.0001, std=0.0021\n",
      " - Weight 42: (512,), mean=1.0015, std=0.0221\n",
      " - Weight 43: (512,), mean=-0.0735, std=0.0281\n",
      " - Weight 44: (512, 512), mean=-0.0002, std=0.0478\n",
      " - Weight 45: (512,), mean=-0.0000, std=0.0033\n",
      " - Weight 46: (512,), mean=1.0915, std=0.0441\n",
      " - Weight 47: (512,), mean=0.0660, std=0.0420\n",
      " - Weight 48: (512, 95), mean=-0.0574, std=0.0813\n",
      " - Weight 49: (95,), mean=-0.1044, std=0.1031\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 6s 62ms/step - loss: 17.8122 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 12.8813 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 10.1133 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 8.3552 - accuracy: 0.0125\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 6.7996 - accuracy: 0.0613\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 5.6302 - accuracy: 0.1187\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 4.9783 - accuracy: 0.1756\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 4.6003 - accuracy: 0.2387\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 4.1197 - accuracy: 0.3119\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 3.9004 - accuracy: 0.3925\n",
      "   Task_2 training accuracy: 0.3925\n",
      "Task ~1 accuracy after training on Task_2: 0.0040\n",
      "ðŸ” [DEBUG] Initial weights shape:\n",
      " - Weight 0: (8, 1, 32)\n",
      " - Weight 1: (32,)\n",
      " - Weight 2: (32,)\n",
      " - Weight 3: (32,)\n",
      " - Weight 4: (8, 32, 32)\n",
      " - Weight 5: (32,)\n",
      " - Weight 6: (32,)\n",
      " - Weight 7: (32,)\n",
      " - Weight 8: (8, 32, 64)\n",
      " - Weight 9: (64,)\n",
      " - Weight 10: (64,)\n",
      " - Weight 11: (64,)\n",
      " - Weight 12: (8, 64, 64)\n",
      " - Weight 13: (64,)\n",
      " - Weight 14: (64,)\n",
      " - Weight 15: (64,)\n",
      " - Weight 16: (8, 64, 128)\n",
      " - Weight 17: (128,)\n",
      " - Weight 18: (128,)\n",
      " - Weight 19: (128,)\n",
      " - Weight 20: (8, 128, 128)\n",
      " - Weight 21: (128,)\n",
      " - Weight 22: (128,)\n",
      " - Weight 23: (128,)\n",
      " - Weight 24: (8, 128, 256)\n",
      " - Weight 25: (256,)\n",
      " - Weight 26: (256,)\n",
      " - Weight 27: (256,)\n",
      " - Weight 28: (8, 256, 256)\n",
      " - Weight 29: (256,)\n",
      " - Weight 30: (256,)\n",
      " - Weight 31: (256,)\n",
      " - Weight 32: (8, 256, 512)\n",
      " - Weight 33: (512,)\n",
      " - Weight 34: (512,)\n",
      " - Weight 35: (512,)\n",
      " - Weight 36: (8, 512, 512)\n",
      " - Weight 37: (512,)\n",
      " - Weight 38: (512,)\n",
      " - Weight 39: (512,)\n",
      " - Weight 40: (5120, 512)\n",
      " - Weight 41: (512,)\n",
      " - Weight 42: (512,)\n",
      " - Weight 43: (512,)\n",
      " - Weight 44: (512, 512)\n",
      " - Weight 45: (512,)\n",
      " - Weight 46: (512,)\n",
      " - Weight 47: (512,)\n",
      " - Weight 48: (512, 95)\n",
      " - Weight 49: (95,)\n",
      "\n",
      "âœ… [DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32)\n",
      " - Fisher 1: (32,)\n",
      " - Fisher 2: (32,)\n",
      " - Fisher 3: (32,)\n",
      " - Fisher 4: (8, 32, 32)\n",
      " - Fisher 5: (32,)\n",
      " - Fisher 6: (32,)\n",
      " - Fisher 7: (32,)\n",
      " - Fisher 8: (8, 32, 64)\n",
      " - Fisher 9: (64,)\n",
      " - Fisher 10: (64,)\n",
      " - Fisher 11: (64,)\n",
      " - Fisher 12: (8, 64, 64)\n",
      " - Fisher 13: (64,)\n",
      " - Fisher 14: (64,)\n",
      " - Fisher 15: (64,)\n",
      " - Fisher 16: (8, 64, 128)\n",
      " - Fisher 17: (128,)\n",
      " - Fisher 18: (128,)\n",
      " - Fisher 19: (128,)\n",
      " - Fisher 20: (8, 128, 128)\n",
      " - Fisher 21: (128,)\n",
      " - Fisher 22: (128,)\n",
      " - Fisher 23: (128,)\n",
      " - Fisher 24: (8, 128, 256)\n",
      " - Fisher 25: (256,)\n",
      " - Fisher 26: (256,)\n",
      " - Fisher 27: (256,)\n",
      " - Fisher 28: (8, 256, 256)\n",
      " - Fisher 29: (256,)\n",
      " - Fisher 30: (256,)\n",
      " - Fisher 31: (256,)\n",
      " - Fisher 32: (8, 256, 512)\n",
      " - Fisher 33: (512,)\n",
      " - Fisher 34: (512,)\n",
      " - Fisher 35: (512,)\n",
      " - Fisher 36: (8, 512, 512)\n",
      " - Fisher 37: (512,)\n",
      " - Fisher 38: (512,)\n",
      " - Fisher 39: (512,)\n",
      " - Fisher 40: (5120, 512)\n",
      " - Fisher 41: (512,)\n",
      " - Fisher 42: (512,)\n",
      " - Fisher 43: (512,)\n",
      " - Fisher 44: (512, 512)\n",
      " - Fisher 45: (512,)\n",
      " - Fisher 46: (512,)\n",
      " - Fisher 47: (512,)\n",
      " - Fisher 48: (512, 95)\n",
      " - Fisher 49: (95,)\n",
      "ðŸ§  [DEBUG] Optimal weights (after task):\n",
      " - Weight 0: (8, 1, 32), mean=-0.0086, std=0.0927\n",
      " - Weight 1: (32,), mean=-0.0036, std=0.0200\n",
      " - Weight 2: (32,), mean=1.0196, std=0.0371\n",
      " - Weight 3: (32,), mean=-0.0284, std=0.0392\n",
      " - Weight 4: (8, 32, 32), mean=0.0042, std=0.0687\n",
      " - Weight 5: (32,), mean=0.0030, std=0.0270\n",
      " - Weight 6: (32,), mean=0.9998, std=0.0443\n",
      " - Weight 7: (32,), mean=-0.1682, std=0.0543\n",
      " - Weight 8: (8, 32, 64), mean=0.0013, std=0.0579\n",
      " - Weight 9: (64,), mean=-0.0009, std=0.0079\n",
      " - Weight 10: (64,), mean=1.0034, std=0.0362\n",
      " - Weight 11: (64,), mean=-0.0251, std=0.0553\n",
      " - Weight 12: (8, 64, 64), mean=0.0048, std=0.0516\n",
      " - Weight 13: (64,), mean=-0.0018, std=0.0068\n",
      " - Weight 14: (64,), mean=1.0028, std=0.0402\n",
      " - Weight 15: (64,), mean=-0.0792, std=0.0333\n",
      " - Weight 16: (8, 64, 128), mean=0.0002, std=0.0443\n",
      " - Weight 17: (128,), mean=0.0001, std=0.0048\n",
      " - Weight 18: (128,), mean=1.0041, std=0.0583\n",
      " - Weight 19: (128,), mean=-0.0078, std=0.0466\n",
      " - Weight 20: (8, 128, 128), mean=-0.0003, std=0.0398\n",
      " - Weight 21: (128,), mean=-0.0006, std=0.0048\n",
      " - Weight 22: (128,), mean=1.0064, std=0.0483\n",
      " - Weight 23: (128,), mean=-0.0780, std=0.0430\n",
      " - Weight 24: (8, 128, 256), mean=-0.0003, std=0.0358\n",
      " - Weight 25: (256,), mean=0.0003, std=0.0030\n",
      " - Weight 26: (256,), mean=0.9996, std=0.0701\n",
      " - Weight 27: (256,), mean=-0.0714, std=0.0555\n",
      " - Weight 28: (8, 256, 256), mean=-0.0027, std=0.0322\n",
      " - Weight 29: (256,), mean=0.0007, std=0.0036\n",
      " - Weight 30: (256,), mean=0.9983, std=0.0487\n",
      " - Weight 31: (256,), mean=-0.1320, std=0.0497\n",
      " - Weight 32: (8, 256, 512), mean=-0.0022, std=0.0304\n",
      " - Weight 33: (512,), mean=0.0003, std=0.0021\n",
      " - Weight 34: (512,), mean=0.9906, std=0.0521\n",
      " - Weight 35: (512,), mean=-0.1572, std=0.0473\n",
      " - Weight 36: (8, 512, 512), mean=-0.0016, std=0.0277\n",
      " - Weight 37: (512,), mean=0.0007, std=0.0029\n",
      " - Weight 38: (512,), mean=0.9905, std=0.0500\n",
      " - Weight 39: (512,), mean=-0.1831, std=0.0344\n",
      " - Weight 40: (5120, 512), mean=0.0009, std=0.0256\n",
      " - Weight 41: (512,), mean=0.0001, std=0.0021\n",
      " - Weight 42: (512,), mean=1.0013, std=0.0220\n",
      " - Weight 43: (512,), mean=-0.0745, std=0.0281\n",
      " - Weight 44: (512, 512), mean=0.0008, std=0.0478\n",
      " - Weight 45: (512,), mean=-0.0000, std=0.0033\n",
      " - Weight 46: (512,), mean=1.0900, std=0.0459\n",
      " - Weight 47: (512,), mean=0.0664, std=0.0422\n",
      " - Weight 48: (512, 95), mean=-0.0591, std=0.0812\n",
      " - Weight 49: (95,), mean=-0.1074, std=0.0830\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 6s 62ms/step - loss: 14.8660 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 12.3810 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 10.3764 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 8.5081 - accuracy: 6.2500e-04\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 7.0729 - accuracy: 0.0381\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 5.8175 - accuracy: 0.1369\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 4.8146 - accuracy: 0.2606\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 4.0419 - accuracy: 0.3781\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 3.4406 - accuracy: 0.4925\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 2.9879 - accuracy: 0.5537\n",
      "   Task_3 training accuracy: 0.5537\n",
      "Task ~2 accuracy after training on Task_3: 0.0046\n",
      "ðŸ” [DEBUG] Initial weights shape:\n",
      " - Weight 0: (8, 1, 32)\n",
      " - Weight 1: (32,)\n",
      " - Weight 2: (32,)\n",
      " - Weight 3: (32,)\n",
      " - Weight 4: (8, 32, 32)\n",
      " - Weight 5: (32,)\n",
      " - Weight 6: (32,)\n",
      " - Weight 7: (32,)\n",
      " - Weight 8: (8, 32, 64)\n",
      " - Weight 9: (64,)\n",
      " - Weight 10: (64,)\n",
      " - Weight 11: (64,)\n",
      " - Weight 12: (8, 64, 64)\n",
      " - Weight 13: (64,)\n",
      " - Weight 14: (64,)\n",
      " - Weight 15: (64,)\n",
      " - Weight 16: (8, 64, 128)\n",
      " - Weight 17: (128,)\n",
      " - Weight 18: (128,)\n",
      " - Weight 19: (128,)\n",
      " - Weight 20: (8, 128, 128)\n",
      " - Weight 21: (128,)\n",
      " - Weight 22: (128,)\n",
      " - Weight 23: (128,)\n",
      " - Weight 24: (8, 128, 256)\n",
      " - Weight 25: (256,)\n",
      " - Weight 26: (256,)\n",
      " - Weight 27: (256,)\n",
      " - Weight 28: (8, 256, 256)\n",
      " - Weight 29: (256,)\n",
      " - Weight 30: (256,)\n",
      " - Weight 31: (256,)\n",
      " - Weight 32: (8, 256, 512)\n",
      " - Weight 33: (512,)\n",
      " - Weight 34: (512,)\n",
      " - Weight 35: (512,)\n",
      " - Weight 36: (8, 512, 512)\n",
      " - Weight 37: (512,)\n",
      " - Weight 38: (512,)\n",
      " - Weight 39: (512,)\n",
      " - Weight 40: (5120, 512)\n",
      " - Weight 41: (512,)\n",
      " - Weight 42: (512,)\n",
      " - Weight 43: (512,)\n",
      " - Weight 44: (512, 512)\n",
      " - Weight 45: (512,)\n",
      " - Weight 46: (512,)\n",
      " - Weight 47: (512,)\n",
      " - Weight 48: (512, 95)\n",
      " - Weight 49: (95,)\n",
      "\n",
      "âœ… [DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32)\n",
      " - Fisher 1: (32,)\n",
      " - Fisher 2: (32,)\n",
      " - Fisher 3: (32,)\n",
      " - Fisher 4: (8, 32, 32)\n",
      " - Fisher 5: (32,)\n",
      " - Fisher 6: (32,)\n",
      " - Fisher 7: (32,)\n",
      " - Fisher 8: (8, 32, 64)\n",
      " - Fisher 9: (64,)\n",
      " - Fisher 10: (64,)\n",
      " - Fisher 11: (64,)\n",
      " - Fisher 12: (8, 64, 64)\n",
      " - Fisher 13: (64,)\n",
      " - Fisher 14: (64,)\n",
      " - Fisher 15: (64,)\n",
      " - Fisher 16: (8, 64, 128)\n",
      " - Fisher 17: (128,)\n",
      " - Fisher 18: (128,)\n",
      " - Fisher 19: (128,)\n",
      " - Fisher 20: (8, 128, 128)\n",
      " - Fisher 21: (128,)\n",
      " - Fisher 22: (128,)\n",
      " - Fisher 23: (128,)\n",
      " - Fisher 24: (8, 128, 256)\n",
      " - Fisher 25: (256,)\n",
      " - Fisher 26: (256,)\n",
      " - Fisher 27: (256,)\n",
      " - Fisher 28: (8, 256, 256)\n",
      " - Fisher 29: (256,)\n",
      " - Fisher 30: (256,)\n",
      " - Fisher 31: (256,)\n",
      " - Fisher 32: (8, 256, 512)\n",
      " - Fisher 33: (512,)\n",
      " - Fisher 34: (512,)\n",
      " - Fisher 35: (512,)\n",
      " - Fisher 36: (8, 512, 512)\n",
      " - Fisher 37: (512,)\n",
      " - Fisher 38: (512,)\n",
      " - Fisher 39: (512,)\n",
      " - Fisher 40: (5120, 512)\n",
      " - Fisher 41: (512,)\n",
      " - Fisher 42: (512,)\n",
      " - Fisher 43: (512,)\n",
      " - Fisher 44: (512, 512)\n",
      " - Fisher 45: (512,)\n",
      " - Fisher 46: (512,)\n",
      " - Fisher 47: (512,)\n",
      " - Fisher 48: (512, 95)\n",
      " - Fisher 49: (95,)\n",
      "ðŸ§  [DEBUG] Optimal weights (after task):\n",
      " - Weight 0: (8, 1, 32), mean=-0.0086, std=0.0927\n",
      " - Weight 1: (32,), mean=-0.0036, std=0.0200\n",
      " - Weight 2: (32,), mean=1.0196, std=0.0371\n",
      " - Weight 3: (32,), mean=-0.0284, std=0.0391\n",
      " - Weight 4: (8, 32, 32), mean=0.0041, std=0.0687\n",
      " - Weight 5: (32,), mean=0.0030, std=0.0270\n",
      " - Weight 6: (32,), mean=0.9998, std=0.0443\n",
      " - Weight 7: (32,), mean=-0.1682, std=0.0544\n",
      " - Weight 8: (8, 32, 64), mean=0.0014, std=0.0579\n",
      " - Weight 9: (64,), mean=-0.0009, std=0.0079\n",
      " - Weight 10: (64,), mean=1.0035, std=0.0362\n",
      " - Weight 11: (64,), mean=-0.0250, std=0.0555\n",
      " - Weight 12: (8, 64, 64), mean=0.0049, std=0.0519\n",
      " - Weight 13: (64,), mean=-0.0018, std=0.0068\n",
      " - Weight 14: (64,), mean=1.0029, std=0.0403\n",
      " - Weight 15: (64,), mean=-0.0792, std=0.0332\n",
      " - Weight 16: (8, 64, 128), mean=0.0003, std=0.0443\n",
      " - Weight 17: (128,), mean=0.0001, std=0.0048\n",
      " - Weight 18: (128,), mean=1.0042, std=0.0584\n",
      " - Weight 19: (128,), mean=-0.0078, std=0.0466\n",
      " - Weight 20: (8, 128, 128), mean=-0.0000, std=0.0400\n",
      " - Weight 21: (128,), mean=-0.0006, std=0.0048\n",
      " - Weight 22: (128,), mean=1.0066, std=0.0484\n",
      " - Weight 23: (128,), mean=-0.0780, std=0.0429\n",
      " - Weight 24: (8, 128, 256), mean=-0.0003, std=0.0359\n",
      " - Weight 25: (256,), mean=0.0003, std=0.0030\n",
      " - Weight 26: (256,), mean=0.9999, std=0.0702\n",
      " - Weight 27: (256,), mean=-0.0713, std=0.0555\n",
      " - Weight 28: (8, 256, 256), mean=-0.0025, std=0.0324\n",
      " - Weight 29: (256,), mean=0.0007, std=0.0036\n",
      " - Weight 30: (256,), mean=0.9987, std=0.0489\n",
      " - Weight 31: (256,), mean=-0.1321, std=0.0497\n",
      " - Weight 32: (8, 256, 512), mean=-0.0022, std=0.0305\n",
      " - Weight 33: (512,), mean=0.0003, std=0.0021\n",
      " - Weight 34: (512,), mean=0.9913, std=0.0520\n",
      " - Weight 35: (512,), mean=-0.1570, std=0.0474\n",
      " - Weight 36: (8, 512, 512), mean=-0.0014, std=0.0280\n",
      " - Weight 37: (512,), mean=0.0007, std=0.0029\n",
      " - Weight 38: (512,), mean=0.9907, std=0.0498\n",
      " - Weight 39: (512,), mean=-0.1846, std=0.0343\n",
      " - Weight 40: (5120, 512), mean=0.0012, std=0.0258\n",
      " - Weight 41: (512,), mean=0.0001, std=0.0021\n",
      " - Weight 42: (512,), mean=1.0017, std=0.0222\n",
      " - Weight 43: (512,), mean=-0.0773, std=0.0289\n",
      " - Weight 44: (512, 512), mean=0.0017, std=0.0478\n",
      " - Weight 45: (512,), mean=-0.0000, std=0.0033\n",
      " - Weight 46: (512,), mean=1.0844, std=0.0534\n",
      " - Weight 47: (512,), mean=0.0619, std=0.0466\n",
      " - Weight 48: (512, 95), mean=-0.0618, std=0.0812\n",
      " - Weight 49: (95,), mean=-0.1293, std=0.0631\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 6s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "   Task_4 training accuracy: 0.0000\n",
      "Task ~3 accuracy after training on Task_4: 0.0143\n",
      "ðŸ” [DEBUG] Initial weights shape:\n",
      " - Weight 0: (8, 1, 32)\n",
      " - Weight 1: (32,)\n",
      " - Weight 2: (32,)\n",
      " - Weight 3: (32,)\n",
      " - Weight 4: (8, 32, 32)\n",
      " - Weight 5: (32,)\n",
      " - Weight 6: (32,)\n",
      " - Weight 7: (32,)\n",
      " - Weight 8: (8, 32, 64)\n",
      " - Weight 9: (64,)\n",
      " - Weight 10: (64,)\n",
      " - Weight 11: (64,)\n",
      " - Weight 12: (8, 64, 64)\n",
      " - Weight 13: (64,)\n",
      " - Weight 14: (64,)\n",
      " - Weight 15: (64,)\n",
      " - Weight 16: (8, 64, 128)\n",
      " - Weight 17: (128,)\n",
      " - Weight 18: (128,)\n",
      " - Weight 19: (128,)\n",
      " - Weight 20: (8, 128, 128)\n",
      " - Weight 21: (128,)\n",
      " - Weight 22: (128,)\n",
      " - Weight 23: (128,)\n",
      " - Weight 24: (8, 128, 256)\n",
      " - Weight 25: (256,)\n",
      " - Weight 26: (256,)\n",
      " - Weight 27: (256,)\n",
      " - Weight 28: (8, 256, 256)\n",
      " - Weight 29: (256,)\n",
      " - Weight 30: (256,)\n",
      " - Weight 31: (256,)\n",
      " - Weight 32: (8, 256, 512)\n",
      " - Weight 33: (512,)\n",
      " - Weight 34: (512,)\n",
      " - Weight 35: (512,)\n",
      " - Weight 36: (8, 512, 512)\n",
      " - Weight 37: (512,)\n",
      " - Weight 38: (512,)\n",
      " - Weight 39: (512,)\n",
      " - Weight 40: (5120, 512)\n",
      " - Weight 41: (512,)\n",
      " - Weight 42: (512,)\n",
      " - Weight 43: (512,)\n",
      " - Weight 44: (512, 512)\n",
      " - Weight 45: (512,)\n",
      " - Weight 46: (512,)\n",
      " - Weight 47: (512,)\n",
      " - Weight 48: (512, 95)\n",
      " - Weight 49: (95,)\n",
      "\n",
      "âœ… [DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32)\n",
      " - Fisher 1: (32,)\n",
      " - Fisher 2: (32,)\n",
      " - Fisher 3: (32,)\n",
      " - Fisher 4: (8, 32, 32)\n",
      " - Fisher 5: (32,)\n",
      " - Fisher 6: (32,)\n",
      " - Fisher 7: (32,)\n",
      " - Fisher 8: (8, 32, 64)\n",
      " - Fisher 9: (64,)\n",
      " - Fisher 10: (64,)\n",
      " - Fisher 11: (64,)\n",
      " - Fisher 12: (8, 64, 64)\n",
      " - Fisher 13: (64,)\n",
      " - Fisher 14: (64,)\n",
      " - Fisher 15: (64,)\n",
      " - Fisher 16: (8, 64, 128)\n",
      " - Fisher 17: (128,)\n",
      " - Fisher 18: (128,)\n",
      " - Fisher 19: (128,)\n",
      " - Fisher 20: (8, 128, 128)\n",
      " - Fisher 21: (128,)\n",
      " - Fisher 22: (128,)\n",
      " - Fisher 23: (128,)\n",
      " - Fisher 24: (8, 128, 256)\n",
      " - Fisher 25: (256,)\n",
      " - Fisher 26: (256,)\n",
      " - Fisher 27: (256,)\n",
      " - Fisher 28: (8, 256, 256)\n",
      " - Fisher 29: (256,)\n",
      " - Fisher 30: (256,)\n",
      " - Fisher 31: (256,)\n",
      " - Fisher 32: (8, 256, 512)\n",
      " - Fisher 33: (512,)\n",
      " - Fisher 34: (512,)\n",
      " - Fisher 35: (512,)\n",
      " - Fisher 36: (8, 512, 512)\n",
      " - Fisher 37: (512,)\n",
      " - Fisher 38: (512,)\n",
      " - Fisher 39: (512,)\n",
      " - Fisher 40: (5120, 512)\n",
      " - Fisher 41: (512,)\n",
      " - Fisher 42: (512,)\n",
      " - Fisher 43: (512,)\n",
      " - Fisher 44: (512, 512)\n",
      " - Fisher 45: (512,)\n",
      " - Fisher 46: (512,)\n",
      " - Fisher 47: (512,)\n",
      " - Fisher 48: (512, 95)\n",
      " - Fisher 49: (95,)\n",
      "ðŸ§  [DEBUG] Optimal weights (after task):\n",
      " - Weight 0: (8, 1, 32), mean=nan, std=nan\n",
      " - Weight 1: (32,), mean=nan, std=nan\n",
      " - Weight 2: (32,), mean=nan, std=nan\n",
      " - Weight 3: (32,), mean=nan, std=nan\n",
      " - Weight 4: (8, 32, 32), mean=nan, std=nan\n",
      " - Weight 5: (32,), mean=nan, std=nan\n",
      " - Weight 6: (32,), mean=nan, std=nan\n",
      " - Weight 7: (32,), mean=nan, std=nan\n",
      " - Weight 8: (8, 32, 64), mean=nan, std=nan\n",
      " - Weight 9: (64,), mean=nan, std=nan\n",
      " - Weight 10: (64,), mean=nan, std=nan\n",
      " - Weight 11: (64,), mean=nan, std=nan\n",
      " - Weight 12: (8, 64, 64), mean=nan, std=nan\n",
      " - Weight 13: (64,), mean=nan, std=nan\n",
      " - Weight 14: (64,), mean=nan, std=nan\n",
      " - Weight 15: (64,), mean=nan, std=nan\n",
      " - Weight 16: (8, 64, 128), mean=nan, std=nan\n",
      " - Weight 17: (128,), mean=nan, std=nan\n",
      " - Weight 18: (128,), mean=nan, std=nan\n",
      " - Weight 19: (128,), mean=nan, std=nan\n",
      " - Weight 20: (8, 128, 128), mean=nan, std=nan\n",
      " - Weight 21: (128,), mean=nan, std=nan\n",
      " - Weight 22: (128,), mean=nan, std=nan\n",
      " - Weight 23: (128,), mean=nan, std=nan\n",
      " - Weight 24: (8, 128, 256), mean=nan, std=nan\n",
      " - Weight 25: (256,), mean=nan, std=nan\n",
      " - Weight 26: (256,), mean=nan, std=nan\n",
      " - Weight 27: (256,), mean=nan, std=nan\n",
      " - Weight 28: (8, 256, 256), mean=nan, std=nan\n",
      " - Weight 29: (256,), mean=nan, std=nan\n",
      " - Weight 30: (256,), mean=nan, std=nan\n",
      " - Weight 31: (256,), mean=nan, std=nan\n",
      " - Weight 32: (8, 256, 512), mean=nan, std=nan\n",
      " - Weight 33: (512,), mean=nan, std=nan\n",
      " - Weight 34: (512,), mean=nan, std=nan\n",
      " - Weight 35: (512,), mean=nan, std=nan\n",
      " - Weight 36: (8, 512, 512), mean=nan, std=nan\n",
      " - Weight 37: (512,), mean=nan, std=nan\n",
      " - Weight 38: (512,), mean=nan, std=nan\n",
      " - Weight 39: (512,), mean=nan, std=nan\n",
      " - Weight 40: (5120, 512), mean=nan, std=nan\n",
      " - Weight 41: (512,), mean=nan, std=nan\n",
      " - Weight 42: (512,), mean=nan, std=nan\n",
      " - Weight 43: (512,), mean=nan, std=nan\n",
      " - Weight 44: (512, 512), mean=nan, std=nan\n",
      " - Weight 45: (512,), mean=nan, std=nan\n",
      " - Weight 46: (512,), mean=nan, std=nan\n",
      " - Weight 47: (512,), mean=nan, std=nan\n",
      " - Weight 48: (512, 95), mean=nan, std=nan\n",
      " - Weight 49: (95,), mean=nan, std=nan\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 6s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: nan - accuracy: 0.0000e+00\n",
      "   Task_5 training accuracy: 0.0000\n",
      "Task ~4 accuracy after training on Task_5: 0.0125\n",
      "ðŸ” [DEBUG] Initial weights shape:\n",
      " - Weight 0: (8, 1, 32)\n",
      " - Weight 1: (32,)\n",
      " - Weight 2: (32,)\n",
      " - Weight 3: (32,)\n",
      " - Weight 4: (8, 32, 32)\n",
      " - Weight 5: (32,)\n",
      " - Weight 6: (32,)\n",
      " - Weight 7: (32,)\n",
      " - Weight 8: (8, 32, 64)\n",
      " - Weight 9: (64,)\n",
      " - Weight 10: (64,)\n",
      " - Weight 11: (64,)\n",
      " - Weight 12: (8, 64, 64)\n",
      " - Weight 13: (64,)\n",
      " - Weight 14: (64,)\n",
      " - Weight 15: (64,)\n",
      " - Weight 16: (8, 64, 128)\n",
      " - Weight 17: (128,)\n",
      " - Weight 18: (128,)\n",
      " - Weight 19: (128,)\n",
      " - Weight 20: (8, 128, 128)\n",
      " - Weight 21: (128,)\n",
      " - Weight 22: (128,)\n",
      " - Weight 23: (128,)\n",
      " - Weight 24: (8, 128, 256)\n",
      " - Weight 25: (256,)\n",
      " - Weight 26: (256,)\n",
      " - Weight 27: (256,)\n",
      " - Weight 28: (8, 256, 256)\n",
      " - Weight 29: (256,)\n",
      " - Weight 30: (256,)\n",
      " - Weight 31: (256,)\n",
      " - Weight 32: (8, 256, 512)\n",
      " - Weight 33: (512,)\n",
      " - Weight 34: (512,)\n",
      " - Weight 35: (512,)\n",
      " - Weight 36: (8, 512, 512)\n",
      " - Weight 37: (512,)\n",
      " - Weight 38: (512,)\n",
      " - Weight 39: (512,)\n",
      " - Weight 40: (5120, 512)\n",
      " - Weight 41: (512,)\n",
      " - Weight 42: (512,)\n",
      " - Weight 43: (512,)\n",
      " - Weight 44: (512, 512)\n",
      " - Weight 45: (512,)\n",
      " - Weight 46: (512,)\n",
      " - Weight 47: (512,)\n",
      " - Weight 48: (512, 95)\n",
      " - Weight 49: (95,)\n",
      "\n",
      "âœ… [DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32)\n",
      " - Fisher 1: (32,)\n",
      " - Fisher 2: (32,)\n",
      " - Fisher 3: (32,)\n",
      " - Fisher 4: (8, 32, 32)\n",
      " - Fisher 5: (32,)\n",
      " - Fisher 6: (32,)\n",
      " - Fisher 7: (32,)\n",
      " - Fisher 8: (8, 32, 64)\n",
      " - Fisher 9: (64,)\n",
      " - Fisher 10: (64,)\n",
      " - Fisher 11: (64,)\n",
      " - Fisher 12: (8, 64, 64)\n",
      " - Fisher 13: (64,)\n",
      " - Fisher 14: (64,)\n",
      " - Fisher 15: (64,)\n",
      " - Fisher 16: (8, 64, 128)\n",
      " - Fisher 17: (128,)\n",
      " - Fisher 18: (128,)\n",
      " - Fisher 19: (128,)\n",
      " - Fisher 20: (8, 128, 128)\n",
      " - Fisher 21: (128,)\n",
      " - Fisher 22: (128,)\n",
      " - Fisher 23: (128,)\n",
      " - Fisher 24: (8, 128, 256)\n",
      " - Fisher 25: (256,)\n",
      " - Fisher 26: (256,)\n",
      " - Fisher 27: (256,)\n",
      " - Fisher 28: (8, 256, 256)\n",
      " - Fisher 29: (256,)\n",
      " - Fisher 30: (256,)\n",
      " - Fisher 31: (256,)\n",
      " - Fisher 32: (8, 256, 512)\n",
      " - Fisher 33: (512,)\n",
      " - Fisher 34: (512,)\n",
      " - Fisher 35: (512,)\n",
      " - Fisher 36: (8, 512, 512)\n",
      " - Fisher 37: (512,)\n",
      " - Fisher 38: (512,)\n",
      " - Fisher 39: (512,)\n",
      " - Fisher 40: (5120, 512)\n",
      " - Fisher 41: (512,)\n",
      " - Fisher 42: (512,)\n",
      " - Fisher 43: (512,)\n",
      " - Fisher 44: (512, 512)\n",
      " - Fisher 45: (512,)\n",
      " - Fisher 46: (512,)\n",
      " - Fisher 47: (512,)\n",
      " - Fisher 48: (512, 95)\n",
      " - Fisher 49: (95,)\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ë¹Œë“œ \n",
    "model = DFNet.build(input_shape=(10000, 1), classes=MAX_LABEL)\n",
    "# ì˜µí‹°ë§ˆì´ì € ì„¤ì • \n",
    "OPTIMIZER = Adamax(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "train_loop(model, OPTIMIZER, data, test_size=0.2, first_task = 39, inc_task = 10, first_epochs = 50, inc_epochs = 10, lamb=0.1, num_sample=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adamax.py:99: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 14s 59ms/step - loss: 4.5246 - accuracy: 0.0392\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.9980 - accuracy: 0.0636\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.7535 - accuracy: 0.0817\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.5757 - accuracy: 0.1031\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.4411 - accuracy: 0.1169\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.3163 - accuracy: 0.1411\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.2185 - accuracy: 0.1517\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.1344 - accuracy: 0.1758\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.0746 - accuracy: 0.1866\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.9964 - accuracy: 0.1984\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.9197 - accuracy: 0.2091\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.8177 - accuracy: 0.2314\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.7838 - accuracy: 0.2461\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 2.6761 - accuracy: 0.2639\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 2.6237 - accuracy: 0.2798\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.5377 - accuracy: 0.3020\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 2.4732 - accuracy: 0.3175\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.4031 - accuracy: 0.3344\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.3591 - accuracy: 0.3438\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.2677 - accuracy: 0.3747\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.2091 - accuracy: 0.3850\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.1694 - accuracy: 0.3917\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.1207 - accuracy: 0.4159\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.0375 - accuracy: 0.4402\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.0040 - accuracy: 0.4417\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.9262 - accuracy: 0.4691\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.8874 - accuracy: 0.4794\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.8149 - accuracy: 0.4998\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.7539 - accuracy: 0.5167\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.7013 - accuracy: 0.5258\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 12s 62ms/step - loss: 1.6714 - accuracy: 0.5423\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.6206 - accuracy: 0.5575\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.5444 - accuracy: 0.5767\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.4998 - accuracy: 0.5938\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 12s 61ms/step - loss: 1.4487 - accuracy: 0.6067\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.4063 - accuracy: 0.6263\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.3628 - accuracy: 0.6264\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.3454 - accuracy: 0.6400\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.2728 - accuracy: 0.6619\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.2496 - accuracy: 0.6705\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.2062 - accuracy: 0.6789\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.1676 - accuracy: 0.6898\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.1269 - accuracy: 0.7048\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.0940 - accuracy: 0.7083\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.0368 - accuracy: 0.7272\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.0205 - accuracy: 0.7339\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.9957 - accuracy: 0.7423\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.9487 - accuracy: 0.7598\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.9152 - accuracy: 0.7642\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.8957 - accuracy: 0.7664\n",
      "   Task_0 training accuracy: 0.7664\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 6s 59ms/step - loss: 19.0733 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 15.4566 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 12.6425 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 11.5945 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.2294 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.6212 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.2436 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.9745 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.6455 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.3246 - accuracy: 0.0000e+00\n",
      "   Task_1 training accuracy: 0.0000\n",
      "Task ~0 accuracy after training on Task_1: 0.0456\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 5s 59ms/step - loss: 12.9699 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 12.4554 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 12.2216 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.8958 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.4278 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.0144 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.1763 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.6828 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.4158 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.9798 - accuracy: 0.0000e+00\n",
      "   Task_2 training accuracy: 0.0000\n",
      "Task ~1 accuracy after training on Task_2: 0.0195\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 5s 59ms/step - loss: 12.9692 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 12.3616 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.9394 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.7081 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.2376 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.1134 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.8034 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.4639 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.5045 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.9315 - accuracy: 0.0000e+00\n",
      "   Task_3 training accuracy: 0.0000\n",
      "Task ~2 accuracy after training on Task_3: 0.0167\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 5s 59ms/step - loss: 12.3363 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.7804 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.5398 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.0839 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.5408 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.2734 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.1743 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.5608 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.4279 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.2957 - accuracy: 0.0000e+00\n",
      "   Task_4 training accuracy: 0.0000\n",
      "Task ~3 accuracy after training on Task_4: 0.0189\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 5s 59ms/step - loss: 11.5175 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.7031 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.2423 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.1666 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 9.7457 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.4408 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.2005 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 8.7827 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 8.6980 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 8.3323 - accuracy: 0.0000e+00\n",
      "   Task_5 training accuracy: 0.0000\n",
      "Task ~4 accuracy after training on Task_5: 0.0153\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ë¹Œë“œ \n",
    "model = DFNet.build(input_shape=(10000, 1), classes=MAX_LABEL)\n",
    "# ì˜µí‹°ë§ˆì´ì € ì„¤ì • \n",
    "OPTIMIZER = Adamax(lr=0.0002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "train_loop_nonbase(model, OPTIMIZER, data, test_size=0.2, first_task = 39, inc_task = 10, first_epochs = 50, inc_epochs = 10, lamb=0, num_sample=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adamax.py:99: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 - 14s - loss: 3.8412 - accuracy: 0.0864 - 14s/epoch - 71ms/step\n",
      "Epoch 2/50\n",
      "200/200 - 12s - loss: 3.2819 - accuracy: 0.1431 - 12s/epoch - 58ms/step\n",
      "Epoch 3/50\n",
      "200/200 - 11s - loss: 3.0243 - accuracy: 0.1838 - 11s/epoch - 57ms/step\n",
      "Epoch 4/50\n",
      "200/200 - 11s - loss: 2.7955 - accuracy: 0.2414 - 11s/epoch - 57ms/step\n",
      "Epoch 5/50\n",
      "200/200 - 11s - loss: 2.6375 - accuracy: 0.2722 - 11s/epoch - 57ms/step\n",
      "Epoch 6/50\n",
      "200/200 - 11s - loss: 2.4461 - accuracy: 0.3209 - 11s/epoch - 57ms/step\n",
      "Epoch 7/50\n",
      "200/200 - 11s - loss: 2.2863 - accuracy: 0.3636 - 11s/epoch - 57ms/step\n",
      "Epoch 8/50\n",
      "200/200 - 11s - loss: 2.1523 - accuracy: 0.4011 - 11s/epoch - 57ms/step\n",
      "Epoch 9/50\n",
      "200/200 - 11s - loss: 2.0190 - accuracy: 0.4259 - 11s/epoch - 57ms/step\n",
      "Epoch 10/50\n",
      "200/200 - 11s - loss: 1.8516 - accuracy: 0.4811 - 11s/epoch - 57ms/step\n",
      "Epoch 11/50\n",
      "200/200 - 11s - loss: 1.7139 - accuracy: 0.5219 - 11s/epoch - 57ms/step\n",
      "Epoch 12/50\n",
      "200/200 - 11s - loss: 1.5980 - accuracy: 0.5545 - 11s/epoch - 57ms/step\n",
      "Epoch 13/50\n",
      "200/200 - 11s - loss: 1.4840 - accuracy: 0.5898 - 11s/epoch - 57ms/step\n",
      "Epoch 14/50\n",
      "200/200 - 11s - loss: 1.3798 - accuracy: 0.6186 - 11s/epoch - 57ms/step\n",
      "Epoch 15/50\n",
      "200/200 - 11s - loss: 1.2968 - accuracy: 0.6425 - 11s/epoch - 57ms/step\n",
      "Epoch 16/50\n",
      "200/200 - 11s - loss: 1.2107 - accuracy: 0.6703 - 11s/epoch - 57ms/step\n",
      "Epoch 17/50\n",
      "200/200 - 11s - loss: 1.0965 - accuracy: 0.7014 - 11s/epoch - 57ms/step\n",
      "Epoch 18/50\n",
      "200/200 - 11s - loss: 0.9998 - accuracy: 0.7269 - 11s/epoch - 57ms/step\n",
      "Epoch 19/50\n",
      "200/200 - 11s - loss: 0.9531 - accuracy: 0.7397 - 11s/epoch - 57ms/step\n",
      "Epoch 20/50\n",
      "200/200 - 11s - loss: 0.8827 - accuracy: 0.7595 - 11s/epoch - 57ms/step\n",
      "Epoch 21/50\n",
      "200/200 - 11s - loss: 0.8186 - accuracy: 0.7825 - 11s/epoch - 57ms/step\n",
      "Epoch 22/50\n",
      "200/200 - 11s - loss: 0.7648 - accuracy: 0.7961 - 11s/epoch - 57ms/step\n",
      "Epoch 23/50\n",
      "200/200 - 11s - loss: 0.6962 - accuracy: 0.8133 - 11s/epoch - 57ms/step\n",
      "Epoch 24/50\n",
      "200/200 - 11s - loss: 0.6537 - accuracy: 0.8253 - 11s/epoch - 57ms/step\n",
      "Epoch 25/50\n",
      "200/200 - 11s - loss: 0.5985 - accuracy: 0.8423 - 11s/epoch - 57ms/step\n",
      "Epoch 26/50\n",
      "200/200 - 11s - loss: 0.5798 - accuracy: 0.8484 - 11s/epoch - 57ms/step\n",
      "Epoch 27/50\n",
      "200/200 - 11s - loss: 0.5368 - accuracy: 0.8570 - 11s/epoch - 57ms/step\n",
      "Epoch 28/50\n",
      "200/200 - 11s - loss: 0.5219 - accuracy: 0.8600 - 11s/epoch - 57ms/step\n",
      "Epoch 29/50\n",
      "200/200 - 11s - loss: 0.4817 - accuracy: 0.8750 - 11s/epoch - 57ms/step\n",
      "Epoch 30/50\n",
      "200/200 - 11s - loss: 0.4431 - accuracy: 0.8808 - 11s/epoch - 57ms/step\n",
      "Epoch 31/50\n",
      "200/200 - 11s - loss: 0.4101 - accuracy: 0.8934 - 11s/epoch - 57ms/step\n",
      "Epoch 32/50\n",
      "200/200 - 11s - loss: 0.3907 - accuracy: 0.8988 - 11s/epoch - 57ms/step\n",
      "Epoch 33/50\n",
      "200/200 - 11s - loss: 0.3830 - accuracy: 0.8975 - 11s/epoch - 57ms/step\n",
      "Epoch 34/50\n",
      "200/200 - 11s - loss: 0.3557 - accuracy: 0.9070 - 11s/epoch - 57ms/step\n",
      "Epoch 35/50\n",
      "200/200 - 11s - loss: 0.3303 - accuracy: 0.9125 - 11s/epoch - 57ms/step\n",
      "Epoch 36/50\n",
      "200/200 - 11s - loss: 0.3239 - accuracy: 0.9142 - 11s/epoch - 57ms/step\n",
      "Epoch 37/50\n",
      "200/200 - 11s - loss: 0.3102 - accuracy: 0.9202 - 11s/epoch - 57ms/step\n",
      "Epoch 38/50\n",
      "200/200 - 11s - loss: 0.2832 - accuracy: 0.9231 - 11s/epoch - 57ms/step\n",
      "Epoch 39/50\n",
      "200/200 - 11s - loss: 0.2781 - accuracy: 0.9234 - 11s/epoch - 57ms/step\n",
      "Epoch 40/50\n",
      "200/200 - 11s - loss: 0.2617 - accuracy: 0.9309 - 11s/epoch - 57ms/step\n",
      "Epoch 41/50\n",
      "200/200 - 11s - loss: 0.2410 - accuracy: 0.9317 - 11s/epoch - 57ms/step\n",
      "Epoch 42/50\n",
      "200/200 - 11s - loss: 0.2540 - accuracy: 0.9323 - 11s/epoch - 57ms/step\n",
      "Epoch 43/50\n",
      "200/200 - 11s - loss: 0.2286 - accuracy: 0.9402 - 11s/epoch - 57ms/step\n",
      "Epoch 44/50\n",
      "200/200 - 11s - loss: 0.2258 - accuracy: 0.9411 - 11s/epoch - 57ms/step\n",
      "Epoch 45/50\n",
      "200/200 - 11s - loss: 0.2142 - accuracy: 0.9452 - 11s/epoch - 57ms/step\n",
      "Epoch 46/50\n",
      "200/200 - 11s - loss: 0.2131 - accuracy: 0.9417 - 11s/epoch - 57ms/step\n",
      "Epoch 47/50\n",
      "200/200 - 11s - loss: 0.1854 - accuracy: 0.9508 - 11s/epoch - 57ms/step\n",
      "Epoch 48/50\n",
      "200/200 - 11s - loss: 0.1868 - accuracy: 0.9481 - 11s/epoch - 57ms/step\n",
      "Epoch 49/50\n",
      "200/200 - 11s - loss: 0.1830 - accuracy: 0.9516 - 11s/epoch - 57ms/step\n",
      "Epoch 50/50\n",
      "200/200 - 11s - loss: 0.1730 - accuracy: 0.9519 - 11s/epoch - 57ms/step\n",
      "   First_task training accuracy: 0.9519\n",
      "Epoch 1/10\n",
      "250/250 - 17s - loss: 2.2470 - accuracy: 0.7280 - 17s/epoch - 68ms/step\n",
      "Epoch 2/10\n",
      "250/250 - 14s - loss: 1.3125 - accuracy: 0.7380 - 14s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "250/250 - 14s - loss: 1.0904 - accuracy: 0.7558 - 14s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "250/250 - 14s - loss: 0.9339 - accuracy: 0.7710 - 14s/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "250/250 - 14s - loss: 0.7788 - accuracy: 0.7899 - 14s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "250/250 - 14s - loss: 0.7114 - accuracy: 0.8050 - 14s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "250/250 - 14s - loss: 0.6108 - accuracy: 0.8298 - 14s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "250/250 - 14s - loss: 0.5713 - accuracy: 0.8484 - 14s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "250/250 - 14s - loss: 0.4917 - accuracy: 0.8742 - 14s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "250/250 - 14s - loss: 0.4428 - accuracy: 0.8878 - 14s/epoch - 57ms/step\n",
      "   1_task training accuracy: 0.8878\n",
      "Task 1 accuracy after training on Task ~0: 0.8913\n",
      "Epoch 1/10\n",
      "300/300 - 19s - loss: 2.5752 - accuracy: 0.6994 - 19s/epoch - 65ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 17s - loss: 1.6301 - accuracy: 0.7252 - 17s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "300/300 - 17s - loss: 1.4048 - accuracy: 0.7327 - 17s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "300/300 - 17s - loss: 1.2340 - accuracy: 0.7428 - 17s/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "300/300 - 17s - loss: 1.1146 - accuracy: 0.7511 - 17s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "300/300 - 17s - loss: 0.9654 - accuracy: 0.7610 - 17s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "300/300 - 17s - loss: 0.8718 - accuracy: 0.7821 - 17s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "300/300 - 17s - loss: 0.8059 - accuracy: 0.7875 - 17s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "300/300 - 17s - loss: 0.7555 - accuracy: 0.8032 - 17s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "300/300 - 17s - loss: 0.6915 - accuracy: 0.8176 - 17s/epoch - 57ms/step\n",
      "   2_task training accuracy: 0.8176\n",
      "Task 2 accuracy after training on Task ~1: 0.8910\n",
      "Epoch 1/10\n",
      "350/350 - 22s - loss: 2.5223 - accuracy: 0.6523 - 22s/epoch - 63ms/step\n",
      "Epoch 2/10\n",
      "350/350 - 20s - loss: 1.7601 - accuracy: 0.6801 - 20s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "350/350 - 20s - loss: 1.6245 - accuracy: 0.6907 - 20s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "350/350 - 20s - loss: 1.5063 - accuracy: 0.6978 - 20s/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "350/350 - 20s - loss: 1.4343 - accuracy: 0.7066 - 20s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "350/350 - 20s - loss: 1.3308 - accuracy: 0.7182 - 20s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "350/350 - 20s - loss: 1.2618 - accuracy: 0.7291 - 20s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "350/350 - 20s - loss: 1.2170 - accuracy: 0.7284 - 20s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "350/350 - 20s - loss: 1.1018 - accuracy: 0.7446 - 20s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "350/350 - 20s - loss: 1.0066 - accuracy: 0.7562 - 20s/epoch - 57ms/step\n",
      "   3_task training accuracy: 0.7562\n",
      "Task 3 accuracy after training on Task ~2: 0.8737\n",
      "Epoch 1/10\n",
      "400/400 - 25s - loss: 2.5343 - accuracy: 0.6284 - 25s/epoch - 63ms/step\n",
      "Epoch 2/10\n",
      "400/400 - 23s - loss: 1.9492 - accuracy: 0.6474 - 23s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "400/400 - 23s - loss: 1.8645 - accuracy: 0.6563 - 23s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "400/400 - 23s - loss: 1.7668 - accuracy: 0.6608 - 23s/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "400/400 - 23s - loss: 1.6653 - accuracy: 0.6723 - 23s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "400/400 - 23s - loss: 1.6236 - accuracy: 0.6762 - 23s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "400/400 - 23s - loss: 1.5587 - accuracy: 0.6795 - 23s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "400/400 - 23s - loss: 1.5289 - accuracy: 0.6842 - 23s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "400/400 - 23s - loss: 1.4717 - accuracy: 0.6895 - 23s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "400/400 - 23s - loss: 1.4204 - accuracy: 0.6979 - 23s/epoch - 57ms/step\n",
      "   4_task training accuracy: 0.6979\n",
      "Task 4 accuracy after training on Task ~3: 0.8104\n",
      "Epoch 1/10\n",
      "450/450 - 28s - loss: 2.8248 - accuracy: 0.5773 - 28s/epoch - 62ms/step\n",
      "Epoch 2/10\n",
      "450/450 - 26s - loss: 2.3673 - accuracy: 0.6047 - 26s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "450/450 - 26s - loss: 2.3122 - accuracy: 0.6089 - 26s/epoch - 58ms/step\n",
      "Epoch 4/10\n",
      "450/450 - 26s - loss: 2.1869 - accuracy: 0.6202 - 26s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "450/450 - 26s - loss: 2.1562 - accuracy: 0.6248 - 26s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "450/450 - 26s - loss: 2.1021 - accuracy: 0.6294 - 26s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "450/450 - 26s - loss: 2.0799 - accuracy: 0.6297 - 26s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "450/450 - 26s - loss: 2.0304 - accuracy: 0.6350 - 26s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "450/450 - 26s - loss: 1.9906 - accuracy: 0.6390 - 26s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "450/450 - 26s - loss: 1.9278 - accuracy: 0.6481 - 26s/epoch - 57ms/step\n",
      "   5_task training accuracy: 0.6481\n",
      "Task 5 accuracy after training on Task ~4: 0.6841\n"
     ]
    }
   ],
   "source": [
    "# Joint\n",
    "# ëª¨ë¸ ë¹Œë“œ \n",
    "model = DFNet.build(input_shape=(10000, 1), classes=MAX_LABEL)\n",
    "# ì˜µí‹°ë§ˆì´ì € ì„¤ì • \n",
    "OPTIMIZER = Adamax(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "train_loop_joint(model, OPTIMIZER, data, test_size=0.2, first_task = 39, inc_task = 10, first_epochs = 50, inc_epochs = 10, lamb=0, num_sample=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 58ms/step - loss: 3.1144 - accuracy: 0.1500\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 2.4537 - accuracy: 0.2622\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 2.1794 - accuracy: 0.3431\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 1.9178 - accuracy: 0.4003\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 1.6950 - accuracy: 0.4816\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 1.5168 - accuracy: 0.5216\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 1.3262 - accuracy: 0.6019\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 1.1825 - accuracy: 0.6425\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 1.0818 - accuracy: 0.6672\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.9789 - accuracy: 0.7063\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.8352 - accuracy: 0.7544\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.7431 - accuracy: 0.7831\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.7137 - accuracy: 0.7862\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.6536 - accuracy: 0.8072\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.6032 - accuracy: 0.8294\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.5403 - accuracy: 0.8413\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.5498 - accuracy: 0.8416\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.4620 - accuracy: 0.8719\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.4280 - accuracy: 0.8734\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.4394 - accuracy: 0.8669\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.4211 - accuracy: 0.8822\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.3692 - accuracy: 0.8922\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.3679 - accuracy: 0.8944\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.3113 - accuracy: 0.9134\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.3180 - accuracy: 0.9097\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.3296 - accuracy: 0.9047\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.3032 - accuracy: 0.9128\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2797 - accuracy: 0.9222\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2539 - accuracy: 0.9291\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2619 - accuracy: 0.9269\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2227 - accuracy: 0.9344\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2345 - accuracy: 0.9341\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2058 - accuracy: 0.9406\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1873 - accuracy: 0.9450\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2135 - accuracy: 0.9353\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2024 - accuracy: 0.9419\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 6s 57ms/step - loss: 0.1667 - accuracy: 0.9563\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1999 - accuracy: 0.9438\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1622 - accuracy: 0.9556\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1514 - accuracy: 0.9566\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.1654 - accuracy: 0.9516\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1718 - accuracy: 0.9484\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1585 - accuracy: 0.9509\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1455 - accuracy: 0.9578\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1622 - accuracy: 0.9531\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1657 - accuracy: 0.9534\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1270 - accuracy: 0.9622\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1324 - accuracy: 0.9575\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1256 - accuracy: 0.9609\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1319 - accuracy: 0.9606\n",
      "   Task_0 training accuracy: 0.9606\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 6s 59ms/step - loss: 7.9631 - accuracy: 0.3050\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6450 - accuracy: 0.7575\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.4883 - accuracy: 0.8087\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.4212 - accuracy: 0.8475\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.4029 - accuracy: 0.8475\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.3592 - accuracy: 0.8737\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.3188 - accuracy: 0.8900\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.2845 - accuracy: 0.8888\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 0.2418 - accuracy: 0.9150\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.2010 - accuracy: 0.9100\n",
      "   Task_1 training accuracy: 0.9100\n",
      "Task ~0 accuracy after training on Task_1: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 8.5513 - accuracy: 0.0650\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 1.5166 - accuracy: 0.3988\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.1595 - accuracy: 0.5450\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.9502 - accuracy: 0.5975\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.8085 - accuracy: 0.6650\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6086 - accuracy: 0.7325\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.5739 - accuracy: 0.7550\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.5772 - accuracy: 0.7487\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.5110 - accuracy: 0.7725\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.4678 - accuracy: 0.7912\n",
      "   Task_2 training accuracy: 0.7912\n",
      "Task ~1 accuracy after training on Task_2: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 60ms/step - loss: 12.0864 - accuracy: 0.0075\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.6394 - accuracy: 0.2288\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.5808 - accuracy: 0.3400\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.3982 - accuracy: 0.4013\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.2593 - accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.0104 - accuracy: 0.6737\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.9078 - accuracy: 0.7138\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.7378 - accuracy: 0.7462\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6492 - accuracy: 0.7850\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.5379 - accuracy: 0.8225\n",
      "   Task_3 training accuracy: 0.8225\n",
      "Task ~2 accuracy after training on Task_3: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 12.6038 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 3.6952 - accuracy: 0.0637\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.3042 - accuracy: 0.3225\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.6399 - accuracy: 0.3938\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.3707 - accuracy: 0.4412\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.2623 - accuracy: 0.5113\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.1272 - accuracy: 0.5800\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.9964 - accuracy: 0.6400\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.8133 - accuracy: 0.7225\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6686 - accuracy: 0.7763\n",
      "   Task_4 training accuracy: 0.7763\n",
      "Task ~3 accuracy after training on Task_4: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 11.0780 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 4.9708 - accuracy: 0.0100\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 3.5025 - accuracy: 0.0413\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 2.6534 - accuracy: 0.2000\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 1.9245 - accuracy: 0.3237\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 1.6785 - accuracy: 0.3413\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 1.3912 - accuracy: 0.4800\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 1.1243 - accuracy: 0.6025\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 0.8327 - accuracy: 0.7000\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 0.6860 - accuracy: 0.7588\n",
      "   Task_5 training accuracy: 0.7588\n",
      "Task ~4 accuracy after training on Task_5: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 12.6796 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 6.3131 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 4.5204 - accuracy: 0.0063\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 3.5670 - accuracy: 0.0312\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.7489 - accuracy: 0.1813\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 2.2469 - accuracy: 0.2537\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 1.9238 - accuracy: 0.2475\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.7929 - accuracy: 0.2700\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.6925 - accuracy: 0.2937\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.6431 - accuracy: 0.2837\n",
      "   Task_6 training accuracy: 0.2837\n",
      "Task ~5 accuracy after training on Task_6: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 12.0689 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 7.1209 - accuracy: 0.0012\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.2190 - accuracy: 0.0162\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 4.2792 - accuracy: 0.0812\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 3.6329 - accuracy: 0.1150\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 3.0252 - accuracy: 0.2463\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.4897 - accuracy: 0.3050\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.0421 - accuracy: 0.3187\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.8062 - accuracy: 0.3275\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.5998 - accuracy: 0.3462\n",
      "   Task_7 training accuracy: 0.3462\n",
      "Task ~6 accuracy after training on Task_7: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 10.5861 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.9036 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.5779 - accuracy: 0.0012\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 4.7358 - accuracy: 0.0025\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 4.2673 - accuracy: 0.0213\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 3.6616 - accuracy: 0.0550\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 3.2710 - accuracy: 0.1238\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.6745 - accuracy: 0.2275\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.3761 - accuracy: 0.2537\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.0477 - accuracy: 0.2812\n",
      "   Task_8 training accuracy: 0.2812\n",
      "Task ~7 accuracy after training on Task_8: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 10.7290 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 7.8548 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.2776 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.5828 - accuracy: 0.0025\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.0261 - accuracy: 0.0075\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 4.5730 - accuracy: 0.0125\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 4.2032 - accuracy: 0.0288\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 3.9134 - accuracy: 0.0725\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 3.6184 - accuracy: 0.1200\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 3.3520 - accuracy: 0.1625\n",
      "   Task_9 training accuracy: 0.1625\n",
      "Task ~8 accuracy after training on Task_9: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 7.8505 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 6.7574 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 6.0001 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 5.5802 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 5.2954 - accuracy: 0.0025\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 5.0433 - accuracy: 0.0137\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 4.8101 - accuracy: 0.0262\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 4.6824 - accuracy: 0.0250\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 4.5682 - accuracy: 0.0400\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 4.4179 - accuracy: 0.0475\n",
      "   Task_10 training accuracy: 0.0475\n",
      "Task ~9 accuracy after training on Task_10: 0.0112\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 6.6857 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.0643 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.7286 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.4728 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.2977 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.1222 - accuracy: 0.0025\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 4.9455 - accuracy: 0.0213\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 4.8286 - accuracy: 0.0325\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 4.7030 - accuracy: 0.0487\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 4.6156 - accuracy: 0.0587\n",
      "   Task_11 training accuracy: 0.0587\n",
      "Task ~10 accuracy after training on Task_11: 0.0157\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 6.4180 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 6.1403 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.9152 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.7429 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.6089 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.4924 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.3892 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.3085 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.2220 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.1508 - accuracy: 0.0000e+00\n",
      "   Task_12 training accuracy: 0.0000\n",
      "Task ~11 accuracy after training on Task_12: 0.0237\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 6.4178 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.1583 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.0056 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.8838 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.7660 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.6696 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.5895 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.5129 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.4390 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.3741 - accuracy: 0.0000e+00\n",
      "   Task_13 training accuracy: 0.0000\n",
      "Task ~12 accuracy after training on Task_13: 0.0147\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 6.3300 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.1735 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 6.0455 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.9434 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.8529 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.7713 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 5.6962 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.6255 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.5604 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.4949 - accuracy: 0.0000e+00\n",
      "   Task_14 training accuracy: 0.0000\n",
      "Task ~13 accuracy after training on Task_14: 0.0121\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 6.4541 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.3079 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.1913 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 6.0914 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.0086 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.9248 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.8510 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 5.7809 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.7147 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 5.6510 - accuracy: 0.0000e+00\n",
      "   Task_15 training accuracy: 0.0000\n",
      "Task ~14 accuracy after training on Task_15: 0.0122\n"
     ]
    }
   ],
   "source": [
    "# Nonbase\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "# ëª¨ë¸ ë¹Œë“œ \n",
    "model = DFNet.build(input_shape=(10000, 1), classes=MAX_LABEL)\n",
    "# ì˜µí‹°ë§ˆì´ì € ì„¤ì • \n",
    "OPTIMIZER = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "train_loop(model, OPTIMIZER, data, test_size=0.2, first_task = 19, inc_task = 5, first_epochs = 50, inc_epochs = 10, lamb=0, num_sample=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 - 8s - loss: 3.1071 - accuracy: 0.1534 - 8s/epoch - 81ms/step\n",
      "Epoch 2/50\n",
      "100/100 - 6s - loss: 2.4469 - accuracy: 0.2609 - 6s/epoch - 56ms/step\n",
      "Epoch 3/50\n",
      "100/100 - 6s - loss: 2.1326 - accuracy: 0.3375 - 6s/epoch - 55ms/step\n",
      "Epoch 4/50\n",
      "100/100 - 6s - loss: 1.8926 - accuracy: 0.4131 - 6s/epoch - 55ms/step\n",
      "Epoch 5/50\n",
      "100/100 - 6s - loss: 1.7309 - accuracy: 0.4731 - 6s/epoch - 56ms/step\n",
      "Epoch 6/50\n",
      "100/100 - 6s - loss: 1.5253 - accuracy: 0.5272 - 6s/epoch - 56ms/step\n",
      "Epoch 7/50\n",
      "100/100 - 6s - loss: 1.3574 - accuracy: 0.5791 - 6s/epoch - 56ms/step\n",
      "Epoch 8/50\n",
      "100/100 - 6s - loss: 1.2562 - accuracy: 0.6072 - 6s/epoch - 56ms/step\n",
      "Epoch 9/50\n",
      "100/100 - 6s - loss: 1.1152 - accuracy: 0.6594 - 6s/epoch - 56ms/step\n",
      "Epoch 10/50\n",
      "100/100 - 6s - loss: 1.0259 - accuracy: 0.6869 - 6s/epoch - 56ms/step\n",
      "Epoch 11/50\n",
      "100/100 - 6s - loss: 0.9367 - accuracy: 0.7081 - 6s/epoch - 56ms/step\n",
      "Epoch 12/50\n",
      "100/100 - 6s - loss: 0.8603 - accuracy: 0.7350 - 6s/epoch - 56ms/step\n",
      "Epoch 13/50\n",
      "100/100 - 6s - loss: 0.7834 - accuracy: 0.7638 - 6s/epoch - 55ms/step\n",
      "Epoch 14/50\n",
      "100/100 - 6s - loss: 0.7277 - accuracy: 0.7872 - 6s/epoch - 56ms/step\n",
      "Epoch 15/50\n",
      "100/100 - 6s - loss: 0.6752 - accuracy: 0.7987 - 6s/epoch - 56ms/step\n",
      "Epoch 16/50\n",
      "100/100 - 6s - loss: 0.6147 - accuracy: 0.8191 - 6s/epoch - 56ms/step\n",
      "Epoch 17/50\n",
      "100/100 - 6s - loss: 0.5750 - accuracy: 0.8356 - 6s/epoch - 56ms/step\n",
      "Epoch 18/50\n",
      "100/100 - 6s - loss: 0.5367 - accuracy: 0.8450 - 6s/epoch - 56ms/step\n",
      "Epoch 19/50\n",
      "100/100 - 6s - loss: 0.5194 - accuracy: 0.8534 - 6s/epoch - 56ms/step\n",
      "Epoch 20/50\n",
      "100/100 - 6s - loss: 0.4888 - accuracy: 0.8584 - 6s/epoch - 56ms/step\n",
      "Epoch 21/50\n",
      "100/100 - 6s - loss: 0.4468 - accuracy: 0.8747 - 6s/epoch - 56ms/step\n",
      "Epoch 22/50\n",
      "100/100 - 6s - loss: 0.4706 - accuracy: 0.8666 - 6s/epoch - 56ms/step\n",
      "Epoch 23/50\n",
      "100/100 - 6s - loss: 0.3791 - accuracy: 0.8925 - 6s/epoch - 56ms/step\n",
      "Epoch 24/50\n",
      "100/100 - 6s - loss: 0.3426 - accuracy: 0.8975 - 6s/epoch - 56ms/step\n",
      "Epoch 25/50\n",
      "100/100 - 6s - loss: 0.3403 - accuracy: 0.9006 - 6s/epoch - 56ms/step\n",
      "Epoch 26/50\n",
      "100/100 - 6s - loss: 0.3177 - accuracy: 0.9066 - 6s/epoch - 56ms/step\n",
      "Epoch 27/50\n",
      "100/100 - 6s - loss: 0.3008 - accuracy: 0.9109 - 6s/epoch - 56ms/step\n",
      "Epoch 28/50\n",
      "100/100 - 6s - loss: 0.2976 - accuracy: 0.9119 - 6s/epoch - 56ms/step\n",
      "Epoch 29/50\n",
      "100/100 - 6s - loss: 0.2747 - accuracy: 0.9209 - 6s/epoch - 56ms/step\n",
      "Epoch 30/50\n",
      "100/100 - 6s - loss: 0.2715 - accuracy: 0.9222 - 6s/epoch - 56ms/step\n",
      "Epoch 31/50\n",
      "100/100 - 6s - loss: 0.2341 - accuracy: 0.9312 - 6s/epoch - 56ms/step\n",
      "Epoch 32/50\n",
      "100/100 - 6s - loss: 0.2605 - accuracy: 0.9228 - 6s/epoch - 56ms/step\n",
      "Epoch 33/50\n",
      "100/100 - 6s - loss: 0.2298 - accuracy: 0.9300 - 6s/epoch - 56ms/step\n",
      "Epoch 34/50\n",
      "100/100 - 6s - loss: 0.2557 - accuracy: 0.9231 - 6s/epoch - 56ms/step\n",
      "Epoch 35/50\n",
      "100/100 - 6s - loss: 0.1871 - accuracy: 0.9466 - 6s/epoch - 56ms/step\n",
      "Epoch 36/50\n",
      "100/100 - 6s - loss: 0.1946 - accuracy: 0.9428 - 6s/epoch - 56ms/step\n",
      "Epoch 37/50\n",
      "100/100 - 6s - loss: 0.1995 - accuracy: 0.9394 - 6s/epoch - 56ms/step\n",
      "Epoch 38/50\n",
      "100/100 - 6s - loss: 0.1778 - accuracy: 0.9509 - 6s/epoch - 56ms/step\n",
      "Epoch 39/50\n",
      "100/100 - 6s - loss: 0.1873 - accuracy: 0.9484 - 6s/epoch - 56ms/step\n",
      "Epoch 40/50\n",
      "100/100 - 6s - loss: 0.1765 - accuracy: 0.9503 - 6s/epoch - 56ms/step\n",
      "Epoch 41/50\n",
      "100/100 - 6s - loss: 0.1860 - accuracy: 0.9422 - 6s/epoch - 56ms/step\n",
      "Epoch 42/50\n",
      "100/100 - 6s - loss: 0.1535 - accuracy: 0.9509 - 6s/epoch - 56ms/step\n",
      "Epoch 43/50\n",
      "100/100 - 6s - loss: 0.1444 - accuracy: 0.9584 - 6s/epoch - 56ms/step\n",
      "Epoch 44/50\n",
      "100/100 - 6s - loss: 0.1414 - accuracy: 0.9575 - 6s/epoch - 56ms/step\n",
      "Epoch 45/50\n",
      "100/100 - 6s - loss: 0.1374 - accuracy: 0.9575 - 6s/epoch - 56ms/step\n",
      "Epoch 46/50\n",
      "100/100 - 6s - loss: 0.1226 - accuracy: 0.9597 - 6s/epoch - 56ms/step\n",
      "Epoch 47/50\n",
      "100/100 - 6s - loss: 0.1396 - accuracy: 0.9572 - 6s/epoch - 56ms/step\n",
      "Epoch 48/50\n",
      "100/100 - 6s - loss: 0.1157 - accuracy: 0.9659 - 6s/epoch - 56ms/step\n",
      "Epoch 49/50\n",
      "100/100 - 6s - loss: 0.1214 - accuracy: 0.9634 - 6s/epoch - 56ms/step\n",
      "Epoch 50/50\n",
      "100/100 - 6s - loss: 0.1020 - accuracy: 0.9675 - 6s/epoch - 56ms/step\n",
      "   First_task training accuracy: 0.9675\n",
      "Epoch 1/10\n",
      "125/125 - 9s - loss: 0.9584 - accuracy: 0.8043 - 9s/epoch - 74ms/step\n",
      "Epoch 2/10\n",
      "125/125 - 7s - loss: 0.3727 - accuracy: 0.8860 - 7s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "125/125 - 7s - loss: 0.3012 - accuracy: 0.9035 - 7s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "125/125 - 7s - loss: 0.3138 - accuracy: 0.9068 - 7s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "125/125 - 7s - loss: 0.2573 - accuracy: 0.9202 - 7s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "125/125 - 7s - loss: 0.2432 - accuracy: 0.9277 - 7s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "125/125 - 7s - loss: 0.2380 - accuracy: 0.9285 - 7s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "125/125 - 7s - loss: 0.2104 - accuracy: 0.9377 - 7s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "125/125 - 7s - loss: 0.1952 - accuracy: 0.9402 - 7s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "125/125 - 7s - loss: 0.2032 - accuracy: 0.9402 - 7s/epoch - 56ms/step\n",
      "   1_task training accuracy: 0.9402\n",
      "Task 1 accuracy after training on Task ~0: 0.9225\n",
      "Epoch 1/10\n",
      "150/150 - 11s - loss: 0.8975 - accuracy: 0.8125 - 11s/epoch - 72ms/step\n",
      "Epoch 2/10\n",
      "150/150 - 9s - loss: 0.3963 - accuracy: 0.8815 - 9s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "150/150 - 8s - loss: 0.3280 - accuracy: 0.9029 - 8s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "150/150 - 8s - loss: 0.2936 - accuracy: 0.9121 - 8s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "150/150 - 8s - loss: 0.2752 - accuracy: 0.9208 - 8s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "150/150 - 8s - loss: 0.2492 - accuracy: 0.9287 - 8s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "150/150 - 8s - loss: 0.2211 - accuracy: 0.9375 - 8s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "150/150 - 8s - loss: 0.2163 - accuracy: 0.9348 - 8s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "150/150 - 8s - loss: 0.2213 - accuracy: 0.9358 - 8s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "150/150 - 8s - loss: 0.1910 - accuracy: 0.9433 - 8s/epoch - 56ms/step\n",
      "   2_task training accuracy: 0.9433\n",
      "Task 2 accuracy after training on Task ~1: 0.9220\n",
      "Epoch 1/10\n",
      "175/175 - 13s - loss: 0.8571 - accuracy: 0.8277 - 13s/epoch - 75ms/step\n",
      "Epoch 2/10\n",
      "175/175 - 10s - loss: 0.3761 - accuracy: 0.8995 - 10s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "175/175 - 10s - loss: 0.3189 - accuracy: 0.9098 - 10s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "175/175 - 10s - loss: 0.2598 - accuracy: 0.9282 - 10s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "175/175 - 10s - loss: 0.2408 - accuracy: 0.9309 - 10s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "175/175 - 10s - loss: 0.2264 - accuracy: 0.9375 - 10s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "175/175 - 10s - loss: 0.2109 - accuracy: 0.9425 - 10s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "175/175 - 10s - loss: 0.2041 - accuracy: 0.9445 - 10s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "175/175 - 10s - loss: 0.1979 - accuracy: 0.9418 - 10s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "175/175 - 10s - loss: 0.1610 - accuracy: 0.9532 - 10s/epoch - 56ms/step\n",
      "   3_task training accuracy: 0.9532\n",
      "Task 3 accuracy after training on Task ~2: 0.9258\n",
      "Epoch 1/10\n",
      "200/200 - 14s - loss: 0.8614 - accuracy: 0.8442 - 14s/epoch - 68ms/step\n",
      "Epoch 2/10\n",
      "200/200 - 11s - loss: 0.3476 - accuracy: 0.8991 - 11s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "200/200 - 11s - loss: 0.2818 - accuracy: 0.9223 - 11s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "200/200 - 11s - loss: 0.2127 - accuracy: 0.9386 - 11s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "200/200 - 11s - loss: 0.2247 - accuracy: 0.9350 - 11s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "200/200 - 11s - loss: 0.2246 - accuracy: 0.9378 - 11s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "200/200 - 11s - loss: 0.1639 - accuracy: 0.9519 - 11s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "200/200 - 11s - loss: 0.1747 - accuracy: 0.9491 - 11s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "200/200 - 11s - loss: 0.1751 - accuracy: 0.9520 - 11s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "200/200 - 11s - loss: 0.1563 - accuracy: 0.9588 - 11s/epoch - 56ms/step\n",
      "   4_task training accuracy: 0.9588\n",
      "Task 4 accuracy after training on Task ~3: 0.9321\n",
      "Epoch 1/10\n",
      "225/225 - 15s - loss: 0.7568 - accuracy: 0.8539 - 15s/epoch - 68ms/step\n",
      "Epoch 2/10\n",
      "225/225 - 13s - loss: 0.3353 - accuracy: 0.9110 - 13s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "225/225 - 13s - loss: 0.2623 - accuracy: 0.9244 - 13s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "225/225 - 13s - loss: 0.2141 - accuracy: 0.9397 - 13s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "225/225 - 13s - loss: 0.2083 - accuracy: 0.9425 - 13s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "225/225 - 13s - loss: 0.1865 - accuracy: 0.9483 - 13s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "225/225 - 13s - loss: 0.1897 - accuracy: 0.9471 - 13s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "225/225 - 13s - loss: 0.1602 - accuracy: 0.9544 - 13s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "225/225 - 13s - loss: 0.1655 - accuracy: 0.9525 - 13s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "225/225 - 13s - loss: 0.1475 - accuracy: 0.9592 - 13s/epoch - 56ms/step\n",
      "   5_task training accuracy: 0.9592\n",
      "Task 5 accuracy after training on Task ~4: 0.5894\n",
      "Epoch 1/10\n",
      "250/250 - 16s - loss: 0.9150 - accuracy: 0.8459 - 16s/epoch - 65ms/step\n",
      "Epoch 2/10\n",
      "250/250 - 14s - loss: 0.3265 - accuracy: 0.9119 - 14s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "250/250 - 14s - loss: 0.2445 - accuracy: 0.9349 - 14s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "250/250 - 14s - loss: 0.2168 - accuracy: 0.9391 - 14s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "250/250 - 14s - loss: 0.2049 - accuracy: 0.9440 - 14s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "250/250 - 14s - loss: 0.1791 - accuracy: 0.9484 - 14s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "250/250 - 14s - loss: 0.1725 - accuracy: 0.9517 - 14s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "250/250 - 14s - loss: 0.1520 - accuracy: 0.9595 - 14s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "250/250 - 14s - loss: 0.1628 - accuracy: 0.9534 - 14s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "250/250 - 14s - loss: 0.1665 - accuracy: 0.9540 - 14s/epoch - 56ms/step\n",
      "   6_task training accuracy: 0.9540\n",
      "Task 6 accuracy after training on Task ~5: 0.9222\n",
      "Epoch 1/10\n",
      "275/275 - 18s - loss: 0.9239 - accuracy: 0.8527 - 18s/epoch - 65ms/step\n",
      "Epoch 2/10\n",
      "275/275 - 15s - loss: 0.3968 - accuracy: 0.8906 - 15s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "275/275 - 16s - loss: 0.3237 - accuracy: 0.9093 - 16s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "275/275 - 16s - loss: 0.2463 - accuracy: 0.9281 - 16s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "275/275 - 16s - loss: 0.2319 - accuracy: 0.9339 - 16s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "275/275 - 16s - loss: 0.2144 - accuracy: 0.9406 - 16s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "275/275 - 16s - loss: 0.1958 - accuracy: 0.9469 - 16s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "275/275 - 16s - loss: 0.1740 - accuracy: 0.9533 - 16s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "275/275 - 16s - loss: 0.1583 - accuracy: 0.9568 - 16s/epoch - 58ms/step\n",
      "Epoch 10/10\n",
      "275/275 - 16s - loss: 0.1555 - accuracy: 0.9575 - 16s/epoch - 58ms/step\n",
      "   7_task training accuracy: 0.9575\n",
      "Task 7 accuracy after training on Task ~6: 0.9330\n",
      "Epoch 1/10\n",
      "300/300 - 19s - loss: 0.9534 - accuracy: 0.8520 - 19s/epoch - 65ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 17s - loss: 0.4348 - accuracy: 0.8763 - 17s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "300/300 - 17s - loss: 0.3299 - accuracy: 0.9074 - 17s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "300/300 - 17s - loss: 0.2611 - accuracy: 0.9280 - 17s/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "300/300 - 17s - loss: 0.2332 - accuracy: 0.9388 - 17s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "300/300 - 17s - loss: 0.2021 - accuracy: 0.9474 - 17s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "300/300 - 17s - loss: 0.2009 - accuracy: 0.9479 - 17s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "300/300 - 21s - loss: 0.1934 - accuracy: 0.9497 - 21s/epoch - 72ms/step\n",
      "Epoch 9/10\n",
      "300/300 - 22s - loss: 0.1649 - accuracy: 0.9536 - 22s/epoch - 72ms/step\n",
      "Epoch 10/10\n",
      "300/300 - 17s - loss: 0.1655 - accuracy: 0.9549 - 17s/epoch - 58ms/step\n",
      "   8_task training accuracy: 0.9549\n",
      "Task 8 accuracy after training on Task ~7: 0.9400\n",
      "Epoch 1/10\n",
      "325/325 - 22s - loss: 1.1267 - accuracy: 0.8435 - 22s/epoch - 67ms/step\n",
      "Epoch 2/10\n",
      "325/325 - 19s - loss: 0.4580 - accuracy: 0.8770 - 19s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "325/325 - 19s - loss: 0.3905 - accuracy: 0.8912 - 19s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "325/325 - 19s - loss: 0.3182 - accuracy: 0.9112 - 19s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "325/325 - 19s - loss: 0.3025 - accuracy: 0.9127 - 19s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "325/325 - 19s - loss: 0.2598 - accuracy: 0.9287 - 19s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "325/325 - 19s - loss: 0.2366 - accuracy: 0.9356 - 19s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "325/325 - 19s - loss: 0.2129 - accuracy: 0.9412 - 19s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "325/325 - 19s - loss: 0.1779 - accuracy: 0.9504 - 19s/epoch - 58ms/step\n",
      "Epoch 10/10\n",
      "325/325 - 19s - loss: 0.1904 - accuracy: 0.9504 - 19s/epoch - 58ms/step\n",
      "   9_task training accuracy: 0.9504\n",
      "Task 9 accuracy after training on Task ~8: 0.9317\n",
      "Epoch 1/10\n",
      "350/350 - 23s - loss: 1.0078 - accuracy: 0.8554 - 23s/epoch - 66ms/step\n",
      "Epoch 2/10\n",
      "350/350 - 20s - loss: 0.4807 - accuracy: 0.8763 - 20s/epoch - 58ms/step\n",
      "Epoch 3/10\n",
      "350/350 - 20s - loss: 0.3949 - accuracy: 0.8938 - 20s/epoch - 58ms/step\n",
      "Epoch 4/10\n",
      "350/350 - 20s - loss: 0.3358 - accuracy: 0.9086 - 20s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "350/350 - 20s - loss: 0.2966 - accuracy: 0.9211 - 20s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "350/350 - 20s - loss: 0.2689 - accuracy: 0.9274 - 20s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "350/350 - 20s - loss: 0.2424 - accuracy: 0.9364 - 20s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "350/350 - 20s - loss: 0.2181 - accuracy: 0.9442 - 20s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "350/350 - 20s - loss: 0.2083 - accuracy: 0.9470 - 20s/epoch - 58ms/step\n",
      "Epoch 10/10\n",
      "350/350 - 20s - loss: 0.1951 - accuracy: 0.9496 - 20s/epoch - 58ms/step\n",
      "   10_task training accuracy: 0.9496\n",
      "Task 10 accuracy after training on Task ~9: 0.9431\n",
      "Epoch 1/10\n",
      "375/375 - 25s - loss: 1.0144 - accuracy: 0.8586 - 25s/epoch - 66ms/step\n",
      "Epoch 2/10\n",
      "375/375 - 22s - loss: 0.5682 - accuracy: 0.8770 - 22s/epoch - 58ms/step\n",
      "Epoch 3/10\n",
      "375/375 - 22s - loss: 0.4286 - accuracy: 0.8921 - 22s/epoch - 59ms/step\n",
      "Epoch 4/10\n",
      "375/375 - 22s - loss: 0.3521 - accuracy: 0.9046 - 22s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "375/375 - 22s - loss: 0.3391 - accuracy: 0.9073 - 22s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "375/375 - 22s - loss: 0.2969 - accuracy: 0.9226 - 22s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "375/375 - 22s - loss: 0.2850 - accuracy: 0.9273 - 22s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "375/375 - 22s - loss: 0.2445 - accuracy: 0.9398 - 22s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "375/375 - 22s - loss: 0.2242 - accuracy: 0.9417 - 22s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "375/375 - 22s - loss: 0.2195 - accuracy: 0.9431 - 22s/epoch - 57ms/step\n",
      "   11_task training accuracy: 0.9431\n",
      "Task 11 accuracy after training on Task ~10: 0.9386\n",
      "Epoch 1/10\n",
      "400/400 - 26s - loss: 1.1704 - accuracy: 0.8512 - 26s/epoch - 65ms/step\n",
      "Epoch 2/10\n",
      "400/400 - 23s - loss: 0.5958 - accuracy: 0.8792 - 23s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "400/400 - 23s - loss: 0.4462 - accuracy: 0.8887 - 23s/epoch - 58ms/step\n",
      "Epoch 4/10\n",
      "400/400 - 23s - loss: 0.3872 - accuracy: 0.8985 - 23s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "400/400 - 23s - loss: 0.3378 - accuracy: 0.9105 - 23s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "400/400 - 23s - loss: 0.3364 - accuracy: 0.9131 - 23s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "400/400 - 23s - loss: 0.2988 - accuracy: 0.9208 - 23s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "400/400 - 23s - loss: 0.2806 - accuracy: 0.9284 - 23s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "400/400 - 23s - loss: 0.2593 - accuracy: 0.9339 - 23s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "400/400 - 23s - loss: 0.2281 - accuracy: 0.9427 - 23s/epoch - 58ms/step\n",
      "   12_task training accuracy: 0.9427\n",
      "Task 12 accuracy after training on Task ~11: 0.8207\n",
      "Epoch 1/10\n",
      "425/425 - 27s - loss: 1.1532 - accuracy: 0.8543 - 27s/epoch - 64ms/step\n",
      "Epoch 2/10\n",
      "425/425 - 24s - loss: 0.6049 - accuracy: 0.8735 - 24s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "425/425 - 24s - loss: 0.4570 - accuracy: 0.8892 - 24s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "425/425 - 25s - loss: 0.4055 - accuracy: 0.8943 - 25s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "425/425 - 25s - loss: 0.3737 - accuracy: 0.9043 - 25s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "425/425 - 25s - loss: 0.3493 - accuracy: 0.9089 - 25s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "425/425 - 25s - loss: 0.3398 - accuracy: 0.9108 - 25s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "425/425 - 25s - loss: 0.3114 - accuracy: 0.9204 - 25s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "425/425 - 25s - loss: 0.2992 - accuracy: 0.9238 - 25s/epoch - 58ms/step\n",
      "Epoch 10/10\n",
      "425/425 - 25s - loss: 0.3043 - accuracy: 0.9258 - 25s/epoch - 58ms/step\n",
      "   13_task training accuracy: 0.9258\n",
      "Task 13 accuracy after training on Task ~12: 0.9250\n",
      "Epoch 1/10\n",
      "450/450 - 29s - loss: 1.2445 - accuracy: 0.8420 - 29s/epoch - 64ms/step\n",
      "Epoch 2/10\n",
      "450/450 - 26s - loss: 0.6432 - accuracy: 0.8674 - 26s/epoch - 58ms/step\n",
      "Epoch 3/10\n",
      "450/450 - 26s - loss: 0.4876 - accuracy: 0.8804 - 26s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "450/450 - 26s - loss: 0.4529 - accuracy: 0.8886 - 26s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "450/450 - 26s - loss: 0.4016 - accuracy: 0.8988 - 26s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "450/450 - 26s - loss: 0.3753 - accuracy: 0.9044 - 26s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "450/450 - 26s - loss: 0.3678 - accuracy: 0.9105 - 26s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "450/450 - 26s - loss: 0.3241 - accuracy: 0.9222 - 26s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "450/450 - 26s - loss: 0.2983 - accuracy: 0.9277 - 26s/epoch - 58ms/step\n",
      "Epoch 10/10\n",
      "450/450 - 26s - loss: 0.2918 - accuracy: 0.9319 - 26s/epoch - 58ms/step\n",
      "   14_task training accuracy: 0.9319\n",
      "Task 14 accuracy after training on Task ~13: 0.9297\n",
      "Epoch 1/10\n",
      "475/475 - 30s - loss: 1.1821 - accuracy: 0.8551 - 30s/epoch - 64ms/step\n",
      "Epoch 2/10\n",
      "475/475 - 28s - loss: 0.7793 - accuracy: 0.8761 - 28s/epoch - 58ms/step\n",
      "Epoch 3/10\n",
      "475/475 - 27s - loss: 0.5537 - accuracy: 0.8857 - 27s/epoch - 58ms/step\n",
      "Epoch 4/10\n",
      "475/475 - 28s - loss: 0.4636 - accuracy: 0.8889 - 28s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "475/475 - 28s - loss: 0.4022 - accuracy: 0.8977 - 28s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "475/475 - 28s - loss: 0.3744 - accuracy: 0.9035 - 28s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "475/475 - 27s - loss: 0.3379 - accuracy: 0.9119 - 27s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "475/475 - 27s - loss: 0.3427 - accuracy: 0.9132 - 27s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "475/475 - 27s - loss: 0.2995 - accuracy: 0.9222 - 27s/epoch - 58ms/step\n",
      "Epoch 10/10\n",
      "475/475 - 28s - loss: 0.2930 - accuracy: 0.9237 - 28s/epoch - 58ms/step\n",
      "   15_task training accuracy: 0.9237\n",
      "Task 15 accuracy after training on Task ~14: 0.9378\n"
     ]
    }
   ],
   "source": [
    "# Joint\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "# ëª¨ë¸ ë¹Œë“œ \n",
    "model = DFNet.build(input_shape=(10000, 1), classes=MAX_LABEL)\n",
    "# ì˜µí‹°ë§ˆì´ì € ì„¤ì • \n",
    "OPTIMIZER = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "train_loop_joint(model, OPTIMIZER, data, test_size=0.2, first_task = 19, inc_task = 5, first_epochs = 50, inc_epochs = 10, lamb=0, num_sample=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nAIvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
