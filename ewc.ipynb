{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.legacy import Adamax\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model \n",
    "from Model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ewc_penalty(model, fisher_matrix, optimal_weights, lamb):   \n",
    "    loss = 0\n",
    "    current = model.trainable_weights \n",
    "    \n",
    "    for F, c, o in zip(fisher_matrix, current, optimal_weights):\n",
    "        loss += tf.reduce_sum(F * ((c - o) ** 2))\n",
    "\n",
    "\n",
    "    return loss * (lamb / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewc_loss(model, fisher_matrix, lamb):\n",
    "    optimal_weights = deepcopy(model.trainable_weights)\n",
    "\n",
    "    def loss_fn(y_true, y_pred):\n",
    "\n",
    "        ce_loss = CategoricalCrossentropy(from_logits=False)(y_true, y_pred)\n",
    "        ewc_loss = compute_ewc_penalty(model, fisher_matrix, optimal_weights, lamb=lamb)\n",
    "\n",
    "        return ce_loss + ewc_loss\n",
    "    \n",
    "    return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fisher_matrix(model, data, num_sample=10):\n",
    "\n",
    "    weights = model.trainable_weights\n",
    "    variance = [tf.zeros_like(tensor) for tensor in weights]\n",
    "\n",
    "\n",
    "\n",
    "    # [디버깅 추가]\n",
    "    print(\"🔍 [DEBUG] Initial weights shape:\")\n",
    "    for i, w in enumerate(weights):\n",
    "        print(f\" - Weight {i}: {w.shape}\")\n",
    "    '''\n",
    "    for i, (x, y) in enumerate(data):\n",
    "        if i >= num_sample:\n",
    "            break\n",
    "\n",
    "        print(f\"\\n📦 [DEBUG] Sample {i} input shape: x={x.shape}, y={y.shape}\")\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    # num_sample 개의 데이터 랜덤샘플링 \n",
    "    indices = np.random.choice(len(data), size=num_sample, replace=False)\n",
    "\n",
    "    for i in indices:\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(weights)\n",
    "            x = tf.expand_dims(data[i], axis=0)\n",
    "            output = model(x, training=False) # (수정) 메모리 문제, 모든 데이터를 한번에 넣으면 오류 생김. 여기서는 하나씩 열개의 데이터를 사용 \n",
    "            log_likelihood = tf.math.log(output)\n",
    "\n",
    "        gradients = tape.gradient(log_likelihood, weights)\n",
    "        variance = [var + (grad ** 2) for var, grad in zip(variance, gradients)]\n",
    "\n",
    "    fisher_matrix = [tensor / num_sample for tensor in variance]\n",
    "\n",
    "\n",
    "    # [디버깅 추가]\n",
    "    print(\"\\n✅ [DEBUG] Fisher matrix shapes:\")\n",
    "    for i, f in enumerate(fisher_matrix):\n",
    "        print(f\" - Fisher {i}: {f.shape}, mean={tf.reduce_mean(f):.4f}, std={tf.math.reduce_std(f):.4f}\")\n",
    "\n",
    "\n",
    "    \n",
    "    return fisher_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (수정) 배치를 사용하지 않음 \n",
    "def evaluate(model, test_set):\n",
    "  acc = tf.keras.metrics.CategoricalAccuracy(name='accuracy')\n",
    "  for i, (seq, labels) in enumerate(test_set):\n",
    "    preds = model.predict_on_batch(seq)\n",
    "    acc.update_state(labels, preds)\n",
    "  return acc.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(model, OPTIMIZER, data, test_size,\n",
    "                first_task = 44, inc_task = 5, first_epochs = 30, inc_epochs = 5,\n",
    "                  lamb=0, num_sample=10):\n",
    "    \n",
    "    first_part = split_by_label(data, 0, first_task)\n",
    "    train, test = split_train_test(first_part, test_size=test_size, random_state=11)\n",
    "    \n",
    "\n",
    "    # OPTIMIZER -> param\n",
    "    i = 0\n",
    "    while(1):\n",
    "\n",
    "        if ( first_task + i * inc_task ) < MAX_LABEL:\n",
    "            \n",
    "            if i == 0:\n",
    "                model.compile(loss=CategoricalCrossentropy(from_logits=False), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "                # 3D ndarray 로 변환 \n",
    "                train_seq, train_label = split_data_label(train)\n",
    "\n",
    "                train_seq = np.stack(train_seq.values)\n",
    "                train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "                train_label = train_label.values\n",
    "                train_label = to_categorical(train_label, num_classes=MAX_LABEL)\n",
    "                \n",
    "\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=first_epochs, verbose=1)\n",
    "                print(f\"   Task_0 training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "                # Fisher matrix 계산 \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "            else:\n",
    "                # 데이터 준비 \n",
    "                inc_part = split_by_label(data, first_task + (i-1) * inc_task + 1, first_task + i * inc_task )\n",
    "                train, inc_test = split_train_test(inc_part, test_size=test_size, random_state=11)\n",
    "\n",
    "                # [디버깅 코드 추가]\n",
    "                optimal_weights = deepcopy(model.trainable_weights)\n",
    "\n",
    "                print(\"🧠 [DEBUG] Optimal weights (after task):\")\n",
    "                for index, w in enumerate(optimal_weights):\n",
    "                    print(f\" - Weight {index}: {w.shape}, mean={tf.reduce_mean(w):.4f}, std={tf.math.reduce_std(w):.4f}\")\n",
    "\n",
    "\n",
    "                model.compile(loss=ewc_loss(model, fisher_matrix, lamb=lamb), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "                \n",
    "                # 3D ndarray 로 변환 (이부분 함수로 바꾸기)\n",
    "                train_seq, train_label = split_data_label(train)\n",
    "\n",
    "                train_seq = np.stack(train_seq.values)\n",
    "                train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "                train_label = train_label.values\n",
    "                train_label = to_categorical(train_label, num_classes=MAX_LABEL)\n",
    "\n",
    "\n",
    "\n",
    "                # train\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=inc_epochs, verbose=1)\n",
    "                print(f\"   Task_{i} training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "                # (수정) 일종의 전처리이므로 preprocessing 또는 utils에 함수 작성 \n",
    "                # 축적된 test로 정확도 측정 (중요, EWC 성능)\n",
    "                test_seq, test_label = split_data_label(test)\n",
    "                test_seq = np.stack(test_seq.values)\n",
    "                test_seq = test_seq[..., np.newaxis]\n",
    "\n",
    "                test_label = test_label.values\n",
    "                test_label = to_categorical(test_label, num_classes=MAX_LABEL)\n",
    "\n",
    "                test_ = tf.data.Dataset.from_tensor_slices((test_seq, test_label))\n",
    "                test_ = test_.batch(32) #(수정) 모델 자체 배치 존재? - 학습시 fit 디폴트값도 32\n",
    "\n",
    "                inc_accuracy = evaluate(model, test_)\n",
    "                print(f\"Task ~{i-1} accuracy after training on Task_{i}: {inc_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # test 업데이트 \n",
    "                test = accumulate_data(test, inc_test)\n",
    "\n",
    "                # Fisher matrix 계산 \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "        else:\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop_nonbase(model, OPTIMIZER, data, test_size,\n",
    "                first_task = 44, inc_task = 5, first_epochs = 30, inc_epochs = 5,\n",
    "                  lamb=0, num_sample=10):\n",
    "    \n",
    "    first_part = split_by_label(data, 0, first_task)\n",
    "    train, test = split_train_test(first_part, test_size=test_size, random_state=11)\n",
    "    \n",
    "\n",
    "    # OPTIMIZER -> param\n",
    "    i = 0\n",
    "    while(1):\n",
    "\n",
    "        if ( first_task + i * inc_task ) < MAX_LABEL:\n",
    "            \n",
    "            if i == 0:\n",
    "                model.compile(loss=CategoricalCrossentropy(from_logits=False), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "                # 3D ndarray 로 변환 \n",
    "                train_seq, train_label = split_data_label(train)\n",
    "\n",
    "                train_seq = np.stack(train_seq.values)\n",
    "                train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "                train_label = train_label.values\n",
    "                train_label = to_categorical(train_label, num_classes=MAX_LABEL)\n",
    "                \n",
    "\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=first_epochs, verbose=1)\n",
    "                print(f\"   Task_0 training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "                # Fisher matrix 계산 \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "            else:\n",
    "                # 데이터 준비 \n",
    "                inc_part = split_by_label(data, first_task + (i-1) * inc_task + 1, first_task + i * inc_task )\n",
    "                train, inc_test = split_train_test(inc_part, test_size=test_size, random_state=11)\n",
    "\n",
    "                model.compile(loss=CategoricalCrossentropy(from_logits=False), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "                \n",
    "                # 3D ndarray 로 변환 (이부분 함수로 바꾸기)\n",
    "                train_seq, train_label = split_data_label(train)\n",
    "\n",
    "                train_seq = np.stack(train_seq.values)\n",
    "                train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "                train_label = train_label.values\n",
    "                train_label = to_categorical(train_label, num_classes=MAX_LABEL)\n",
    "\n",
    "\n",
    "\n",
    "                # train\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=inc_epochs, verbose=1)\n",
    "                print(f\"   Task_{i} training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "                # (수정) 일종의 전처리이므로 preprocessing 또는 utils에 함수 작성 \n",
    "                # 축적된 test로 정확도 측정 (중요, EWC 성능)\n",
    "                test_seq, test_label = split_data_label(test)\n",
    "                test_seq = np.stack(test_seq.values)\n",
    "                test_seq = test_seq[..., np.newaxis]\n",
    "\n",
    "                test_label = test_label.values\n",
    "                test_label = to_categorical(test_label, num_classes=MAX_LABEL)\n",
    "\n",
    "                test_ = tf.data.Dataset.from_tensor_slices((test_seq, test_label))\n",
    "                test_ = test_.batch(32) #(수정) 모델 자체 배치 존재? - 학습시 fit 디폴트값도 32\n",
    "\n",
    "                inc_accuracy = evaluate(model, test_)\n",
    "                print(f\"Task ~{i-1} accuracy after training on Task_{i}: {inc_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # test 업데이트 \n",
    "                test = accumulate_data(test, inc_test)\n",
    "\n",
    "                # Fisher matrix 계산 \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "        else:\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_joint(model, OPTIMIZER, data, test_size,\n",
    "                first_task = 44, inc_task = 5, first_epochs = 30, inc_epochs = 5,\n",
    "                  lamb=0, num_sample=10):\n",
    "    \n",
    "    first_part = split_by_label(data, 0, first_task)\n",
    "    train, test = split_train_test(first_part, test_size=test_size, random_state=11)\n",
    "    \n",
    "\n",
    "    # OPTIMIZER -> param\n",
    "    i = 0\n",
    "    while(1):\n",
    "\n",
    "        if ( first_task + i * inc_task ) <= MAX_LABEL:\n",
    "            \n",
    "            if i == 0:\n",
    "                model.compile(loss=CategoricalCrossentropy(from_logits=False), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "                # 3D ndarray 로 변환 \n",
    "                train_seq, train_label = split_data_label(train)\n",
    "\n",
    "                train_seq = np.stack(train_seq.values)\n",
    "                train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "                train_label = train_label.values\n",
    "                train_label = to_categorical(train_label, num_classes=MAX_LABEL)\n",
    "                \n",
    "\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=first_epochs, verbose=2)\n",
    "                print(f\"   First_task training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "                # Fisher matrix 계산 \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "            else:\n",
    "                # 데이터 준비 \n",
    "                inc_part = split_by_label(data, first_task + (i-1) * inc_task + 1, first_task + i * inc_task )\n",
    "                inc_train, inc_test = split_train_test(inc_part, test_size=test_size, random_state=11)\n",
    "                train = accumulate_data(train, inc_train)\n",
    "\n",
    "                model.compile(loss=CategoricalCrossentropy(from_logits=False), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "                \n",
    "                # 3D ndarray 로 변환 (이부분 함수로 바꾸기)\n",
    "                train_seq, train_label = split_data_label(train)\n",
    "\n",
    "                train_seq = np.stack(train_seq.values)\n",
    "                train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "                train_label = train_label.values\n",
    "                train_label = to_categorical(train_label, num_classes=MAX_LABEL)\n",
    "\n",
    "\n",
    "\n",
    "                # train\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=inc_epochs, verbose=2)\n",
    "                print(f\"   {i}_task training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "                # (수정) 일종의 전처리이므로 preprocessing 또는 utils에 함수 작성 \n",
    "                # 축적된 test로 정확도 측정 (중요, EWC 성능)\n",
    "                test_seq, test_label = split_data_label(test)\n",
    "                test_seq = np.stack(test_seq.values)\n",
    "                test_seq = test_seq[..., np.newaxis]\n",
    "\n",
    "                test_label = test_label.values\n",
    "                test_label = to_categorical(test_label, num_classes=MAX_LABEL)\n",
    "\n",
    "                test_ = tf.data.Dataset.from_tensor_slices((test_seq, test_label))\n",
    "                test_ = test_.batch(32) #(수정) 모델 자체 배치 존재? - 학습시 fit 디폴트값도 32\n",
    "\n",
    "                inc_accuracy = evaluate(model, test_)\n",
    "                print(f\"Task {i} accuracy after training on Task ~{i-1}: {inc_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # test 업데이트 \n",
    "                test = accumulate_data(test, inc_test)\n",
    "\n",
    "                # Fisher matrix 계산 \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "        else:\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 2)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_pickle('mon_data.pkl')\n",
    "print(data.shape)\n",
    "MAX_LABEL = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adamax.py:99: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 13s 57ms/step - loss: 3.8646 - accuracy: 0.0772\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 3.3313 - accuracy: 0.1394\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 3.0455 - accuracy: 0.1859\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 2.8916 - accuracy: 0.2166\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 2.7104 - accuracy: 0.2558\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 2.5178 - accuracy: 0.3028\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 2.3857 - accuracy: 0.3227\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 2.2510 - accuracy: 0.3620\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 2.1197 - accuracy: 0.4017\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 2.0074 - accuracy: 0.4392\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.8763 - accuracy: 0.4700\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.7468 - accuracy: 0.5153\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.6315 - accuracy: 0.5461\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 1.5322 - accuracy: 0.5745\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.4329 - accuracy: 0.6078\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.3102 - accuracy: 0.6383\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.2249 - accuracy: 0.6631\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.1263 - accuracy: 0.6919\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.0475 - accuracy: 0.7159\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.9791 - accuracy: 0.7384\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.9031 - accuracy: 0.7567\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.8294 - accuracy: 0.7809\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.7822 - accuracy: 0.7867\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.7165 - accuracy: 0.8081\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.7061 - accuracy: 0.8148\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 0.6288 - accuracy: 0.8314\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.6076 - accuracy: 0.8350\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.5538 - accuracy: 0.8483\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.5318 - accuracy: 0.8603\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.4976 - accuracy: 0.8708\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.4710 - accuracy: 0.8791\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.4428 - accuracy: 0.8841\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.4044 - accuracy: 0.8963\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.3813 - accuracy: 0.8980\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.3749 - accuracy: 0.8997\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.3463 - accuracy: 0.9086\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.3353 - accuracy: 0.9086\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 12s 58ms/step - loss: 0.3094 - accuracy: 0.9222\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.2966 - accuracy: 0.9191\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.2777 - accuracy: 0.9266\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.2733 - accuracy: 0.9283\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.2626 - accuracy: 0.9292\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 0.2497 - accuracy: 0.9337\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 0.2362 - accuracy: 0.9366\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.2313 - accuracy: 0.9397\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.2177 - accuracy: 0.9425\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.2136 - accuracy: 0.9402\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.1999 - accuracy: 0.9445\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.1899 - accuracy: 0.9455\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.1803 - accuracy: 0.9505\n",
      "   Task_0 training accuracy: 0.9505\n",
      "🔍 [DEBUG] Initial weights shape:\n",
      " - Weight 0: (8, 1, 32)\n",
      " - Weight 1: (32,)\n",
      " - Weight 2: (32,)\n",
      " - Weight 3: (32,)\n",
      " - Weight 4: (8, 32, 32)\n",
      " - Weight 5: (32,)\n",
      " - Weight 6: (32,)\n",
      " - Weight 7: (32,)\n",
      " - Weight 8: (8, 32, 64)\n",
      " - Weight 9: (64,)\n",
      " - Weight 10: (64,)\n",
      " - Weight 11: (64,)\n",
      " - Weight 12: (8, 64, 64)\n",
      " - Weight 13: (64,)\n",
      " - Weight 14: (64,)\n",
      " - Weight 15: (64,)\n",
      " - Weight 16: (8, 64, 128)\n",
      " - Weight 17: (128,)\n",
      " - Weight 18: (128,)\n",
      " - Weight 19: (128,)\n",
      " - Weight 20: (8, 128, 128)\n",
      " - Weight 21: (128,)\n",
      " - Weight 22: (128,)\n",
      " - Weight 23: (128,)\n",
      " - Weight 24: (8, 128, 256)\n",
      " - Weight 25: (256,)\n",
      " - Weight 26: (256,)\n",
      " - Weight 27: (256,)\n",
      " - Weight 28: (8, 256, 256)\n",
      " - Weight 29: (256,)\n",
      " - Weight 30: (256,)\n",
      " - Weight 31: (256,)\n",
      " - Weight 32: (8, 256, 512)\n",
      " - Weight 33: (512,)\n",
      " - Weight 34: (512,)\n",
      " - Weight 35: (512,)\n",
      " - Weight 36: (8, 512, 512)\n",
      " - Weight 37: (512,)\n",
      " - Weight 38: (512,)\n",
      " - Weight 39: (512,)\n",
      " - Weight 40: (5120, 512)\n",
      " - Weight 41: (512,)\n",
      " - Weight 42: (512,)\n",
      " - Weight 43: (512,)\n",
      " - Weight 44: (512, 512)\n",
      " - Weight 45: (512,)\n",
      " - Weight 46: (512,)\n",
      " - Weight 47: (512,)\n",
      " - Weight 48: (512, 95)\n",
      " - Weight 49: (95,)\n",
      "\n",
      "✅ [DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32), mean=1027521.7500, std=1344378.6250\n",
      " - Fisher 1: (32,), mean=1299270.7500, std=1728823.5000\n",
      " - Fisher 2: (32,), mean=6379.7021, std=5744.0273\n",
      " - Fisher 3: (32,), mean=10108.4512, std=13169.1133\n",
      " - Fisher 4: (8, 32, 32), mean=1816.5234, std=3814.0369\n",
      " - Fisher 5: (32,), mean=3580.8872, std=3367.3875\n",
      " - Fisher 6: (32,), mean=5518.2173, std=3489.5220\n",
      " - Fisher 7: (32,), mean=3556.0251, std=2607.4172\n",
      " - Fisher 8: (8, 32, 64), mean=565.8602, std=1051.2842\n",
      " - Fisher 9: (64,), mean=279.7173, std=255.9401\n",
      " - Fisher 10: (64,), mean=2387.0637, std=2843.6467\n",
      " - Fisher 11: (64,), mean=706.1138, std=838.2516\n",
      " - Fisher 12: (8, 64, 64), mean=167.4892, std=311.3207\n",
      " - Fisher 13: (64,), mean=184.2620, std=265.3351\n",
      " - Fisher 14: (64,), mean=1242.9086, std=1135.6129\n",
      " - Fisher 15: (64,), mean=414.6882, std=561.0551\n",
      " - Fisher 16: (8, 64, 128), mean=49.5978, std=76.1448\n",
      " - Fisher 17: (128,), mean=24.2409, std=26.9284\n",
      " - Fisher 18: (128,), mean=524.2930, std=546.2769\n",
      " - Fisher 19: (128,), mean=255.0061, std=272.7822\n",
      " - Fisher 20: (8, 128, 128), mean=20.8003, std=32.9883\n",
      " - Fisher 21: (128,), mean=33.7275, std=33.9004\n",
      " - Fisher 22: (128,), mean=385.5802, std=287.5267\n",
      " - Fisher 23: (128,), mean=125.9669, std=87.6010\n",
      " - Fisher 24: (8, 128, 256), mean=8.2437, std=9.9218\n",
      " - Fisher 25: (256,), mean=9.9004, std=9.5023\n",
      " - Fisher 26: (256,), mean=156.5785, std=127.4685\n",
      " - Fisher 27: (256,), mean=124.9580, std=136.9466\n",
      " - Fisher 28: (8, 256, 256), mean=6.5715, std=8.3345\n",
      " - Fisher 29: (256,), mean=18.4905, std=11.5634\n",
      " - Fisher 30: (256,), mean=248.8014, std=144.7010\n",
      " - Fisher 31: (256,), mean=186.7288, std=83.9546\n",
      " - Fisher 32: (8, 256, 512), mean=6.7025, std=7.5814\n",
      " - Fisher 33: (512,), mean=12.2839, std=8.1046\n",
      " - Fisher 34: (512,), mean=141.8371, std=123.4064\n",
      " - Fisher 35: (512,), mean=112.1916, std=75.9952\n",
      " - Fisher 36: (8, 512, 512), mean=3.7993, std=5.1249\n",
      " - Fisher 37: (512,), mean=15.6766, std=8.7037\n",
      " - Fisher 38: (512,), mean=203.9655, std=132.0582\n",
      " - Fisher 39: (512,), mean=77.1461, std=28.8747\n",
      " - Fisher 40: (5120, 512), mean=3.5095, std=4.4855\n",
      " - Fisher 41: (512,), mean=4.6573, std=2.4420\n",
      " - Fisher 42: (512,), mean=103.1690, std=65.8723\n",
      " - Fisher 43: (512,), mean=44.3185, std=21.9893\n",
      " - Fisher 44: (512, 512), mean=7.2816, std=6.0001\n",
      " - Fisher 45: (512,), mean=14.5808, std=5.1263\n",
      " - Fisher 46: (512,), mean=61.8260, std=28.2151\n",
      " - Fisher 47: (512,), mean=46.5808, std=16.6206\n",
      " - Fisher 48: (512, 95), mean=45.4637, std=171.1890\n",
      " - Fisher 49: (95,), mean=89.5129, std=133.3248\n",
      "🧠 [DEBUG] Optimal weights (after task):\n",
      " - Weight 0: (8, 1, 32), mean=0.0016, std=0.0929\n",
      " - Weight 1: (32,), mean=-0.0010, std=0.0190\n",
      " - Weight 2: (32,), mean=1.0139, std=0.0518\n",
      " - Weight 3: (32,), mean=-0.0253, std=0.0461\n",
      " - Weight 4: (8, 32, 32), mean=0.0016, std=0.0685\n",
      " - Weight 5: (32,), mean=-0.0063, std=0.0208\n",
      " - Weight 6: (32,), mean=0.9960, std=0.0467\n",
      " - Weight 7: (32,), mean=-0.1865, std=0.0614\n",
      " - Weight 8: (8, 32, 64), mean=0.0023, std=0.0582\n",
      " - Weight 9: (64,), mean=0.0010, std=0.0091\n",
      " - Weight 10: (64,), mean=1.0007, std=0.0400\n",
      " - Weight 11: (64,), mean=-0.0309, std=0.0584\n",
      " - Weight 12: (8, 64, 64), mean=0.0015, std=0.0508\n",
      " - Weight 13: (64,), mean=0.0007, std=0.0076\n",
      " - Weight 14: (64,), mean=1.0058, std=0.0420\n",
      " - Weight 15: (64,), mean=-0.0788, std=0.0460\n",
      " - Weight 16: (8, 64, 128), mean=-0.0014, std=0.0449\n",
      " - Weight 17: (128,), mean=-0.0006, std=0.0052\n",
      " - Weight 18: (128,), mean=1.0026, std=0.0491\n",
      " - Weight 19: (128,), mean=-0.0222, std=0.0353\n",
      " - Weight 20: (8, 128, 128), mean=-0.0014, std=0.0394\n",
      " - Weight 21: (128,), mean=-0.0004, std=0.0059\n",
      " - Weight 22: (128,), mean=1.0030, std=0.0445\n",
      " - Weight 23: (128,), mean=-0.0754, std=0.0420\n",
      " - Weight 24: (8, 128, 256), mean=-0.0007, std=0.0357\n",
      " - Weight 25: (256,), mean=0.0001, std=0.0031\n",
      " - Weight 26: (256,), mean=0.9999, std=0.0686\n",
      " - Weight 27: (256,), mean=-0.0742, std=0.0570\n",
      " - Weight 28: (8, 256, 256), mean=-0.0032, std=0.0320\n",
      " - Weight 29: (256,), mean=0.0004, std=0.0034\n",
      " - Weight 30: (256,), mean=1.0012, std=0.0472\n",
      " - Weight 31: (256,), mean=-0.1244, std=0.0464\n",
      " - Weight 32: (8, 256, 512), mean=-0.0025, std=0.0303\n",
      " - Weight 33: (512,), mean=0.0004, std=0.0022\n",
      " - Weight 34: (512,), mean=0.9896, std=0.0541\n",
      " - Weight 35: (512,), mean=-0.1595, std=0.0468\n",
      " - Weight 36: (8, 512, 512), mean=-0.0020, std=0.0277\n",
      " - Weight 37: (512,), mean=0.0007, std=0.0031\n",
      " - Weight 38: (512,), mean=0.9899, std=0.0513\n",
      " - Weight 39: (512,), mean=-0.1840, std=0.0337\n",
      " - Weight 40: (5120, 512), mean=0.0002, std=0.0255\n",
      " - Weight 41: (512,), mean=-0.0000, std=0.0022\n",
      " - Weight 42: (512,), mean=1.0012, std=0.0230\n",
      " - Weight 43: (512,), mean=-0.0701, std=0.0285\n",
      " - Weight 44: (512, 512), mean=-0.0009, std=0.0479\n",
      " - Weight 45: (512,), mean=0.0001, std=0.0036\n",
      " - Weight 46: (512,), mean=1.0918, std=0.0439\n",
      " - Weight 47: (512,), mean=0.0645, std=0.0422\n",
      " - Weight 48: (512, 95), mean=-0.0564, std=0.0790\n",
      " - Weight 49: (95,), mean=-0.1141, std=0.1052\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 6s 62ms/step - loss: 25.3270 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 20.1285 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 15.9289 - accuracy: 6.2500e-04\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 12.8960 - accuracy: 0.0094\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 10.7670 - accuracy: 0.0512\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 9.2571 - accuracy: 0.1156\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 7.9193 - accuracy: 0.1981\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 7.1190 - accuracy: 0.2763\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 6.4796 - accuracy: 0.3562\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 64ms/step - loss: 5.9701 - accuracy: 0.3950\n",
      "   Task_1 training accuracy: 0.3950\n",
      "Task ~0 accuracy after training on Task_1: 0.4706\n",
      "🔍 [DEBUG] Initial weights shape:\n",
      " - Weight 0: (8, 1, 32)\n",
      " - Weight 1: (32,)\n",
      " - Weight 2: (32,)\n",
      " - Weight 3: (32,)\n",
      " - Weight 4: (8, 32, 32)\n",
      " - Weight 5: (32,)\n",
      " - Weight 6: (32,)\n",
      " - Weight 7: (32,)\n",
      " - Weight 8: (8, 32, 64)\n",
      " - Weight 9: (64,)\n",
      " - Weight 10: (64,)\n",
      " - Weight 11: (64,)\n",
      " - Weight 12: (8, 64, 64)\n",
      " - Weight 13: (64,)\n",
      " - Weight 14: (64,)\n",
      " - Weight 15: (64,)\n",
      " - Weight 16: (8, 64, 128)\n",
      " - Weight 17: (128,)\n",
      " - Weight 18: (128,)\n",
      " - Weight 19: (128,)\n",
      " - Weight 20: (8, 128, 128)\n",
      " - Weight 21: (128,)\n",
      " - Weight 22: (128,)\n",
      " - Weight 23: (128,)\n",
      " - Weight 24: (8, 128, 256)\n",
      " - Weight 25: (256,)\n",
      " - Weight 26: (256,)\n",
      " - Weight 27: (256,)\n",
      " - Weight 28: (8, 256, 256)\n",
      " - Weight 29: (256,)\n",
      " - Weight 30: (256,)\n",
      " - Weight 31: (256,)\n",
      " - Weight 32: (8, 256, 512)\n",
      " - Weight 33: (512,)\n",
      " - Weight 34: (512,)\n",
      " - Weight 35: (512,)\n",
      " - Weight 36: (8, 512, 512)\n",
      " - Weight 37: (512,)\n",
      " - Weight 38: (512,)\n",
      " - Weight 39: (512,)\n",
      " - Weight 40: (5120, 512)\n",
      " - Weight 41: (512,)\n",
      " - Weight 42: (512,)\n",
      " - Weight 43: (512,)\n",
      " - Weight 44: (512, 512)\n",
      " - Weight 45: (512,)\n",
      " - Weight 46: (512,)\n",
      " - Weight 47: (512,)\n",
      " - Weight 48: (512, 95)\n",
      " - Weight 49: (95,)\n",
      "\n",
      "✅ [DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32), mean=396418.2188, std=522302.0625\n",
      " - Fisher 1: (32,), mean=438810.4375, std=610997.4375\n",
      " - Fisher 2: (32,), mean=4316.5107, std=4764.3999\n",
      " - Fisher 3: (32,), mean=3724.3069, std=5206.7754\n",
      " - Fisher 4: (8, 32, 32), mean=787.1761, std=1389.2849\n",
      " - Fisher 5: (32,), mean=1325.8038, std=997.5740\n",
      " - Fisher 6: (32,), mean=4126.9106, std=4448.2363\n",
      " - Fisher 7: (32,), mean=1335.4390, std=843.1104\n",
      " - Fisher 8: (8, 32, 64), mean=372.7743, std=1076.6714\n",
      " - Fisher 9: (64,), mean=133.1672, std=139.7024\n",
      " - Fisher 10: (64,), mean=1407.1947, std=1824.6625\n",
      " - Fisher 11: (64,), mean=302.5692, std=341.4183\n",
      " - Fisher 12: (8, 64, 64), mean=95.3382, std=169.2841\n",
      " - Fisher 13: (64,), mean=95.9492, std=169.9675\n",
      " - Fisher 14: (64,), mean=809.4595, std=841.5888\n",
      " - Fisher 15: (64,), mean=202.9597, std=293.2457\n",
      " - Fisher 16: (8, 64, 128), mean=25.3592, std=52.7071\n",
      " - Fisher 17: (128,), mean=16.6959, std=26.8125\n",
      " - Fisher 18: (128,), mean=277.9347, std=362.1648\n",
      " - Fisher 19: (128,), mean=151.1439, std=230.4799\n",
      " - Fisher 20: (8, 128, 128), mean=13.0816, std=35.5181\n",
      " - Fisher 21: (128,), mean=27.1388, std=46.1102\n",
      " - Fisher 22: (128,), mean=281.3294, std=453.7488\n",
      " - Fisher 23: (128,), mean=101.8409, std=147.2203\n",
      " - Fisher 24: (8, 128, 256), mean=7.8493, std=22.2264\n",
      " - Fisher 25: (256,), mean=5.5908, std=10.4122\n",
      " - Fisher 26: (256,), mean=143.8440, std=303.0275\n",
      " - Fisher 27: (256,), mean=77.2265, std=201.5021\n",
      " - Fisher 28: (8, 256, 256), mean=3.7215, std=9.7903\n",
      " - Fisher 29: (256,), mean=7.9750, std=12.3147\n",
      " - Fisher 30: (256,), mean=179.1089, std=337.9027\n",
      " - Fisher 31: (256,), mean=53.3350, std=68.3439\n",
      " - Fisher 32: (8, 256, 512), mean=3.6460, std=27.6029\n",
      " - Fisher 33: (512,), mean=2.5535, std=12.0010\n",
      " - Fisher 34: (512,), mean=66.5689, std=344.5571\n",
      " - Fisher 35: (512,), mean=24.9503, std=93.1028\n",
      " - Fisher 36: (8, 512, 512), mean=0.7417, std=2.0097\n",
      " - Fisher 37: (512,), mean=2.6452, std=3.1480\n",
      " - Fisher 38: (512,), mean=48.2026, std=87.4062\n",
      " - Fisher 39: (512,), mean=13.5142, std=12.6272\n",
      " - Fisher 40: (5120, 512), mean=0.9764, std=1.7891\n",
      " - Fisher 41: (512,), mean=0.9760, std=0.9443\n",
      " - Fisher 42: (512,), mean=17.1883, std=16.2598\n",
      " - Fisher 43: (512,), mean=10.2356, std=6.8214\n",
      " - Fisher 44: (512, 512), mean=3.8736, std=5.2971\n",
      " - Fisher 45: (512,), mean=8.0525, std=5.3426\n",
      " - Fisher 46: (512,), mean=11.9056, std=11.4145\n",
      " - Fisher 47: (512,), mean=23.1190, std=16.8280\n",
      " - Fisher 48: (512, 95), mean=11.6487, std=95.8680\n",
      " - Fisher 49: (95,), mean=34.7174, std=104.8708\n",
      "🧠 [DEBUG] Optimal weights (after task):\n",
      " - Weight 0: (8, 1, 32), mean=0.0016, std=0.0929\n",
      " - Weight 1: (32,), mean=-0.0010, std=0.0190\n",
      " - Weight 2: (32,), mean=1.0139, std=0.0518\n",
      " - Weight 3: (32,), mean=-0.0253, std=0.0461\n",
      " - Weight 4: (8, 32, 32), mean=0.0016, std=0.0685\n",
      " - Weight 5: (32,), mean=-0.0063, std=0.0208\n",
      " - Weight 6: (32,), mean=0.9960, std=0.0467\n",
      " - Weight 7: (32,), mean=-0.1865, std=0.0614\n",
      " - Weight 8: (8, 32, 64), mean=0.0022, std=0.0582\n",
      " - Weight 9: (64,), mean=0.0010, std=0.0091\n",
      " - Weight 10: (64,), mean=1.0008, std=0.0401\n",
      " - Weight 11: (64,), mean=-0.0308, std=0.0585\n",
      " - Weight 12: (8, 64, 64), mean=0.0021, std=0.0512\n",
      " - Weight 13: (64,), mean=0.0007, std=0.0076\n",
      " - Weight 14: (64,), mean=1.0058, std=0.0420\n",
      " - Weight 15: (64,), mean=-0.0787, std=0.0460\n",
      " - Weight 16: (8, 64, 128), mean=-0.0012, std=0.0448\n",
      " - Weight 17: (128,), mean=-0.0006, std=0.0052\n",
      " - Weight 18: (128,), mean=1.0028, std=0.0491\n",
      " - Weight 19: (128,), mean=-0.0221, std=0.0353\n",
      " - Weight 20: (8, 128, 128), mean=-0.0007, std=0.0400\n",
      " - Weight 21: (128,), mean=-0.0004, std=0.0059\n",
      " - Weight 22: (128,), mean=1.0030, std=0.0445\n",
      " - Weight 23: (128,), mean=-0.0754, std=0.0419\n",
      " - Weight 24: (8, 128, 256), mean=-0.0006, std=0.0358\n",
      " - Weight 25: (256,), mean=0.0001, std=0.0031\n",
      " - Weight 26: (256,), mean=0.9999, std=0.0686\n",
      " - Weight 27: (256,), mean=-0.0741, std=0.0569\n",
      " - Weight 28: (8, 256, 256), mean=-0.0029, std=0.0321\n",
      " - Weight 29: (256,), mean=0.0004, std=0.0034\n",
      " - Weight 30: (256,), mean=1.0012, std=0.0472\n",
      " - Weight 31: (256,), mean=-0.1244, std=0.0464\n",
      " - Weight 32: (8, 256, 512), mean=-0.0023, std=0.0303\n",
      " - Weight 33: (512,), mean=0.0004, std=0.0022\n",
      " - Weight 34: (512,), mean=0.9897, std=0.0541\n",
      " - Weight 35: (512,), mean=-0.1595, std=0.0468\n",
      " - Weight 36: (8, 512, 512), mean=-0.0017, std=0.0277\n",
      " - Weight 37: (512,), mean=0.0007, std=0.0031\n",
      " - Weight 38: (512,), mean=0.9899, std=0.0512\n",
      " - Weight 39: (512,), mean=-0.1840, std=0.0337\n",
      " - Weight 40: (5120, 512), mean=0.0006, std=0.0256\n",
      " - Weight 41: (512,), mean=-0.0000, std=0.0022\n",
      " - Weight 42: (512,), mean=1.0013, std=0.0230\n",
      " - Weight 43: (512,), mean=-0.0703, std=0.0284\n",
      " - Weight 44: (512, 512), mean=-0.0004, std=0.0478\n",
      " - Weight 45: (512,), mean=0.0001, std=0.0036\n",
      " - Weight 46: (512,), mean=1.0917, std=0.0438\n",
      " - Weight 47: (512,), mean=0.0647, std=0.0420\n",
      " - Weight 48: (512, 95), mean=-0.0567, std=0.0809\n",
      " - Weight 49: (95,), mean=-0.0985, std=0.1037\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 6s 63ms/step - loss: 17.2205 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 12.9295 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 10.2924 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 65ms/step - loss: 8.1011 - accuracy: 0.0069\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 65ms/step - loss: 6.2647 - accuracy: 0.0519\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 64ms/step - loss: 5.3202 - accuracy: 0.1437\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 64ms/step - loss: 4.7882 - accuracy: 0.2431\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 64ms/step - loss: 4.2043 - accuracy: 0.3006\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 65ms/step - loss: 3.7779 - accuracy: 0.3988\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 64ms/step - loss: 3.4417 - accuracy: 0.4725\n",
      "   Task_2 training accuracy: 0.4725\n",
      "Task ~1 accuracy after training on Task_2: 0.0170\n",
      "🔍 [DEBUG] Initial weights shape:\n",
      " - Weight 0: (8, 1, 32)\n",
      " - Weight 1: (32,)\n",
      " - Weight 2: (32,)\n",
      " - Weight 3: (32,)\n",
      " - Weight 4: (8, 32, 32)\n",
      " - Weight 5: (32,)\n",
      " - Weight 6: (32,)\n",
      " - Weight 7: (32,)\n",
      " - Weight 8: (8, 32, 64)\n",
      " - Weight 9: (64,)\n",
      " - Weight 10: (64,)\n",
      " - Weight 11: (64,)\n",
      " - Weight 12: (8, 64, 64)\n",
      " - Weight 13: (64,)\n",
      " - Weight 14: (64,)\n",
      " - Weight 15: (64,)\n",
      " - Weight 16: (8, 64, 128)\n",
      " - Weight 17: (128,)\n",
      " - Weight 18: (128,)\n",
      " - Weight 19: (128,)\n",
      " - Weight 20: (8, 128, 128)\n",
      " - Weight 21: (128,)\n",
      " - Weight 22: (128,)\n",
      " - Weight 23: (128,)\n",
      " - Weight 24: (8, 128, 256)\n",
      " - Weight 25: (256,)\n",
      " - Weight 26: (256,)\n",
      " - Weight 27: (256,)\n",
      " - Weight 28: (8, 256, 256)\n",
      " - Weight 29: (256,)\n",
      " - Weight 30: (256,)\n",
      " - Weight 31: (256,)\n",
      " - Weight 32: (8, 256, 512)\n",
      " - Weight 33: (512,)\n",
      " - Weight 34: (512,)\n",
      " - Weight 35: (512,)\n",
      " - Weight 36: (8, 512, 512)\n",
      " - Weight 37: (512,)\n",
      " - Weight 38: (512,)\n",
      " - Weight 39: (512,)\n",
      " - Weight 40: (5120, 512)\n",
      " - Weight 41: (512,)\n",
      " - Weight 42: (512,)\n",
      " - Weight 43: (512,)\n",
      " - Weight 44: (512, 512)\n",
      " - Weight 45: (512,)\n",
      " - Weight 46: (512,)\n",
      " - Weight 47: (512,)\n",
      " - Weight 48: (512, 95)\n",
      " - Weight 49: (95,)\n",
      "\n",
      "✅ [DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32), mean=416226.5312, std=504179.2500\n",
      " - Fisher 1: (32,), mean=767746.0000, std=819533.9375\n",
      " - Fisher 2: (32,), mean=11091.8457, std=11087.1514\n",
      " - Fisher 3: (32,), mean=6271.6528, std=6312.6372\n",
      " - Fisher 4: (8, 32, 32), mean=4716.7583, std=9690.4023\n",
      " - Fisher 5: (32,), mean=4936.4912, std=4618.0415\n",
      " - Fisher 6: (32,), mean=11727.4922, std=12227.9668\n",
      " - Fisher 7: (32,), mean=5506.2705, std=5294.2876\n",
      " - Fisher 8: (8, 32, 64), mean=2638.5039, std=8435.4385\n",
      " - Fisher 9: (64,), mean=548.1153, std=973.2491\n",
      " - Fisher 10: (64,), mean=8009.5615, std=14316.5459\n",
      " - Fisher 11: (64,), mean=1060.3804, std=1501.0111\n",
      " - Fisher 12: (8, 64, 64), mean=722.0432, std=1988.2842\n",
      " - Fisher 13: (64,), mean=224.7554, std=328.0130\n",
      " - Fisher 14: (64,), mean=4672.2490, std=8341.3418\n",
      " - Fisher 15: (64,), mean=445.2405, std=523.9510\n",
      " - Fisher 16: (8, 64, 128), mean=163.9411, std=507.2091\n",
      " - Fisher 17: (128,), mean=27.1531, std=47.7629\n",
      " - Fisher 18: (128,), mean=1172.6936, std=2637.5640\n",
      " - Fisher 19: (128,), mean=233.9262, std=311.6405\n",
      " - Fisher 20: (8, 128, 128), mean=37.8469, std=125.6228\n",
      " - Fisher 21: (128,), mean=26.0379, std=41.0773\n",
      " - Fisher 22: (128,), mean=1017.9341, std=2479.3826\n",
      " - Fisher 23: (128,), mean=98.4028, std=112.6933\n",
      " - Fisher 24: (8, 128, 256), mean=22.4784, std=94.5464\n",
      " - Fisher 25: (256,), mean=8.5001, std=17.8691\n",
      " - Fisher 26: (256,), mean=352.8786, std=928.5693\n",
      " - Fisher 27: (256,), mean=85.2517, std=198.0641\n",
      " - Fisher 28: (8, 256, 256), mean=11.0787, std=46.4244\n",
      " - Fisher 29: (256,), mean=13.6524, std=30.8553\n",
      " - Fisher 30: (256,), mean=410.9330, std=839.8445\n",
      " - Fisher 31: (256,), mean=72.5222, std=109.4277\n",
      " - Fisher 32: (8, 256, 512), mean=5.8180, std=36.5966\n",
      " - Fisher 33: (512,), mean=2.5198, std=9.2326\n",
      " - Fisher 34: (512,), mean=96.8611, std=414.4922\n",
      " - Fisher 35: (512,), mean=25.1540, std=84.7822\n",
      " - Fisher 36: (8, 512, 512), mean=0.7339, std=2.7579\n",
      " - Fisher 37: (512,), mean=1.7522, std=3.2158\n",
      " - Fisher 38: (512,), mean=39.3424, std=81.9559\n",
      " - Fisher 39: (512,), mean=9.2498, std=13.6920\n",
      " - Fisher 40: (5120, 512), mean=0.5520, std=1.8432\n",
      " - Fisher 41: (512,), mean=0.4843, std=0.5390\n",
      " - Fisher 42: (512,), mean=12.8989, std=17.2457\n",
      " - Fisher 43: (512,), mean=5.2529, std=4.2493\n",
      " - Fisher 44: (512, 512), mean=3.0004, std=4.8742\n",
      " - Fisher 45: (512,), mean=4.0199, std=3.4492\n",
      " - Fisher 46: (512,), mean=9.8272, std=13.1277\n",
      " - Fisher 47: (512,), mean=15.2832, std=15.0620\n",
      " - Fisher 48: (512, 95), mean=13.6316, std=150.2273\n",
      " - Fisher 49: (95,), mean=20.4495, std=86.2527\n",
      "🧠 [DEBUG] Optimal weights (after task):\n",
      " - Weight 0: (8, 1, 32), mean=0.0016, std=0.0929\n",
      " - Weight 1: (32,), mean=-0.0010, std=0.0190\n",
      " - Weight 2: (32,), mean=1.0139, std=0.0519\n",
      " - Weight 3: (32,), mean=-0.0253, std=0.0461\n",
      " - Weight 4: (8, 32, 32), mean=0.0015, std=0.0685\n",
      " - Weight 5: (32,), mean=-0.0063, std=0.0208\n",
      " - Weight 6: (32,), mean=0.9960, std=0.0467\n",
      " - Weight 7: (32,), mean=-0.1865, std=0.0614\n",
      " - Weight 8: (8, 32, 64), mean=0.0021, std=0.0583\n",
      " - Weight 9: (64,), mean=0.0010, std=0.0091\n",
      " - Weight 10: (64,), mean=1.0010, std=0.0401\n",
      " - Weight 11: (64,), mean=-0.0307, std=0.0586\n",
      " - Weight 12: (8, 64, 64), mean=0.0023, std=0.0515\n",
      " - Weight 13: (64,), mean=0.0007, std=0.0076\n",
      " - Weight 14: (64,), mean=1.0058, std=0.0420\n",
      " - Weight 15: (64,), mean=-0.0787, std=0.0461\n",
      " - Weight 16: (8, 64, 128), mean=-0.0007, std=0.0447\n",
      " - Weight 17: (128,), mean=-0.0006, std=0.0052\n",
      " - Weight 18: (128,), mean=1.0035, std=0.0490\n",
      " - Weight 19: (128,), mean=-0.0218, std=0.0355\n",
      " - Weight 20: (8, 128, 128), mean=0.0004, std=0.0405\n",
      " - Weight 21: (128,), mean=-0.0004, std=0.0059\n",
      " - Weight 22: (128,), mean=1.0031, std=0.0444\n",
      " - Weight 23: (128,), mean=-0.0754, std=0.0420\n",
      " - Weight 24: (8, 128, 256), mean=-0.0006, std=0.0358\n",
      " - Weight 25: (256,), mean=0.0001, std=0.0031\n",
      " - Weight 26: (256,), mean=1.0001, std=0.0685\n",
      " - Weight 27: (256,), mean=-0.0741, std=0.0569\n",
      " - Weight 28: (8, 256, 256), mean=-0.0028, std=0.0322\n",
      " - Weight 29: (256,), mean=0.0004, std=0.0034\n",
      " - Weight 30: (256,), mean=1.0014, std=0.0471\n",
      " - Weight 31: (256,), mean=-0.1245, std=0.0463\n",
      " - Weight 32: (8, 256, 512), mean=-0.0023, std=0.0304\n",
      " - Weight 33: (512,), mean=0.0004, std=0.0022\n",
      " - Weight 34: (512,), mean=0.9900, std=0.0538\n",
      " - Weight 35: (512,), mean=-0.1595, std=0.0468\n",
      " - Weight 36: (8, 512, 512), mean=-0.0015, std=0.0278\n",
      " - Weight 37: (512,), mean=0.0007, std=0.0031\n",
      " - Weight 38: (512,), mean=0.9901, std=0.0510\n",
      " - Weight 39: (512,), mean=-0.1842, std=0.0336\n",
      " - Weight 40: (5120, 512), mean=0.0008, std=0.0256\n",
      " - Weight 41: (512,), mean=-0.0000, std=0.0022\n",
      " - Weight 42: (512,), mean=1.0014, std=0.0230\n",
      " - Weight 43: (512,), mean=-0.0708, std=0.0284\n",
      " - Weight 44: (512, 512), mean=0.0006, std=0.0478\n",
      " - Weight 45: (512,), mean=0.0001, std=0.0036\n",
      " - Weight 46: (512,), mean=1.0903, std=0.0448\n",
      " - Weight 47: (512,), mean=0.0650, std=0.0415\n",
      " - Weight 48: (512, 95), mean=-0.0583, std=0.0808\n",
      " - Weight 49: (95,), mean=-0.1098, std=0.0776\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 6s 64ms/step - loss: 15.3905 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 12.3644 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 10.3417 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 8.5230 - accuracy: 0.0094\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 6.6140 - accuracy: 0.0806\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 5.6477 - accuracy: 0.1800\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 4.7570 - accuracy: 0.3069\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 4.2021 - accuracy: 0.3738\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 3.3831 - accuracy: 0.5094\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 3.0010 - accuracy: 0.5663\n",
      "   Task_3 training accuracy: 0.5663\n",
      "Task ~2 accuracy after training on Task_3: 0.0021\n",
      "🔍 [DEBUG] Initial weights shape:\n",
      " - Weight 0: (8, 1, 32)\n",
      " - Weight 1: (32,)\n",
      " - Weight 2: (32,)\n",
      " - Weight 3: (32,)\n",
      " - Weight 4: (8, 32, 32)\n",
      " - Weight 5: (32,)\n",
      " - Weight 6: (32,)\n",
      " - Weight 7: (32,)\n",
      " - Weight 8: (8, 32, 64)\n",
      " - Weight 9: (64,)\n",
      " - Weight 10: (64,)\n",
      " - Weight 11: (64,)\n",
      " - Weight 12: (8, 64, 64)\n",
      " - Weight 13: (64,)\n",
      " - Weight 14: (64,)\n",
      " - Weight 15: (64,)\n",
      " - Weight 16: (8, 64, 128)\n",
      " - Weight 17: (128,)\n",
      " - Weight 18: (128,)\n",
      " - Weight 19: (128,)\n",
      " - Weight 20: (8, 128, 128)\n",
      " - Weight 21: (128,)\n",
      " - Weight 22: (128,)\n",
      " - Weight 23: (128,)\n",
      " - Weight 24: (8, 128, 256)\n",
      " - Weight 25: (256,)\n",
      " - Weight 26: (256,)\n",
      " - Weight 27: (256,)\n",
      " - Weight 28: (8, 256, 256)\n",
      " - Weight 29: (256,)\n",
      " - Weight 30: (256,)\n",
      " - Weight 31: (256,)\n",
      " - Weight 32: (8, 256, 512)\n",
      " - Weight 33: (512,)\n",
      " - Weight 34: (512,)\n",
      " - Weight 35: (512,)\n",
      " - Weight 36: (8, 512, 512)\n",
      " - Weight 37: (512,)\n",
      " - Weight 38: (512,)\n",
      " - Weight 39: (512,)\n",
      " - Weight 40: (5120, 512)\n",
      " - Weight 41: (512,)\n",
      " - Weight 42: (512,)\n",
      " - Weight 43: (512,)\n",
      " - Weight 44: (512, 512)\n",
      " - Weight 45: (512,)\n",
      " - Weight 46: (512,)\n",
      " - Weight 47: (512,)\n",
      " - Weight 48: (512, 95)\n",
      " - Weight 49: (95,)\n",
      "\n",
      "✅ [DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32), mean=200403.3750, std=253761.2812\n",
      " - Fisher 1: (32,), mean=405259.3750, std=471820.2500\n",
      " - Fisher 2: (32,), mean=5495.3760, std=5987.5059\n",
      " - Fisher 3: (32,), mean=4521.7036, std=4422.2939\n",
      " - Fisher 4: (8, 32, 32), mean=2877.6650, std=6684.1499\n",
      " - Fisher 5: (32,), mean=3773.2786, std=3983.6433\n",
      " - Fisher 6: (32,), mean=6679.1133, std=7501.8750\n",
      " - Fisher 7: (32,), mean=4703.2529, std=4902.9761\n",
      " - Fisher 8: (8, 32, 64), mean=1387.2371, std=3889.2595\n",
      " - Fisher 9: (64,), mean=427.0306, std=672.7786\n",
      " - Fisher 10: (64,), mean=4180.3281, std=7314.9800\n",
      " - Fisher 11: (64,), mean=757.5400, std=1016.7995\n",
      " - Fisher 12: (8, 64, 64), mean=403.5164, std=1167.1407\n",
      " - Fisher 13: (64,), mean=172.4650, std=255.7278\n",
      " - Fisher 14: (64,), mean=2655.0525, std=5096.0117\n",
      " - Fisher 15: (64,), mean=327.3127, std=393.7025\n",
      " - Fisher 16: (8, 64, 128), mean=91.4469, std=294.9269\n",
      " - Fisher 17: (128,), mean=20.2076, std=35.2532\n",
      " - Fisher 18: (128,), mean=502.1920, std=1448.7930\n",
      " - Fisher 19: (128,), mean=135.9954, std=171.0284\n",
      " - Fisher 20: (8, 128, 128), mean=19.2778, std=66.4354\n",
      " - Fisher 21: (128,), mean=17.8000, std=27.1371\n",
      " - Fisher 22: (128,), mean=373.4532, std=810.8988\n",
      " - Fisher 23: (128,), mean=70.0453, std=70.7022\n",
      " - Fisher 24: (8, 128, 256), mean=10.6730, std=35.1969\n",
      " - Fisher 25: (256,), mean=5.8675, std=9.4354\n",
      " - Fisher 26: (256,), mean=137.6752, std=335.7624\n",
      " - Fisher 27: (256,), mean=53.2696, std=73.5326\n",
      " - Fisher 28: (8, 256, 256), mean=7.4331, std=26.0543\n",
      " - Fisher 29: (256,), mean=12.7800, std=23.5044\n",
      " - Fisher 30: (256,), mean=241.3384, std=465.2713\n",
      " - Fisher 31: (256,), mean=66.9680, std=86.9405\n",
      " - Fisher 32: (8, 256, 512), mean=3.8856, std=16.3236\n",
      " - Fisher 33: (512,), mean=2.4294, std=4.9222\n",
      " - Fisher 34: (512,), mean=62.7846, std=202.7978\n",
      " - Fisher 35: (512,), mean=28.0523, std=53.8922\n",
      " - Fisher 36: (8, 512, 512), mean=0.4667, std=1.3050\n",
      " - Fisher 37: (512,), mean=1.6057, std=1.9387\n",
      " - Fisher 38: (512,), mean=25.2347, std=40.5029\n",
      " - Fisher 39: (512,), mean=9.6829, std=8.3124\n",
      " - Fisher 40: (5120, 512), mean=0.4942, std=0.9809\n",
      " - Fisher 41: (512,), mean=0.6290, std=0.7051\n",
      " - Fisher 42: (512,), mean=11.4024, std=21.9602\n",
      " - Fisher 43: (512,), mean=6.7281, std=7.3121\n",
      " - Fisher 44: (512, 512), mean=2.1166, std=3.3333\n",
      " - Fisher 45: (512,), mean=5.5741, std=5.2412\n",
      " - Fisher 46: (512,), mean=7.3178, std=7.7397\n",
      " - Fisher 47: (512,), mean=15.4617, std=15.3155\n",
      " - Fisher 48: (512, 95), mean=10.0681, std=86.3488\n",
      " - Fisher 49: (95,), mean=33.8351, std=126.1726\n",
      "🧠 [DEBUG] Optimal weights (after task):\n",
      " - Weight 0: (8, 1, 32), mean=0.0016, std=0.0929\n",
      " - Weight 1: (32,), mean=-0.0010, std=0.0190\n",
      " - Weight 2: (32,), mean=1.0139, std=0.0519\n",
      " - Weight 3: (32,), mean=-0.0253, std=0.0461\n",
      " - Weight 4: (8, 32, 32), mean=0.0015, std=0.0685\n",
      " - Weight 5: (32,), mean=-0.0063, std=0.0208\n",
      " - Weight 6: (32,), mean=0.9960, std=0.0467\n",
      " - Weight 7: (32,), mean=-0.1865, std=0.0614\n",
      " - Weight 8: (8, 32, 64), mean=0.0021, std=0.0583\n",
      " - Weight 9: (64,), mean=0.0010, std=0.0091\n",
      " - Weight 10: (64,), mean=1.0012, std=0.0404\n",
      " - Weight 11: (64,), mean=-0.0307, std=0.0587\n",
      " - Weight 12: (8, 64, 64), mean=0.0024, std=0.0519\n",
      " - Weight 13: (64,), mean=0.0007, std=0.0076\n",
      " - Weight 14: (64,), mean=1.0059, std=0.0420\n",
      " - Weight 15: (64,), mean=-0.0786, std=0.0461\n",
      " - Weight 16: (8, 64, 128), mean=-0.0007, std=0.0447\n",
      " - Weight 17: (128,), mean=-0.0006, std=0.0052\n",
      " - Weight 18: (128,), mean=1.0039, std=0.0490\n",
      " - Weight 19: (128,), mean=-0.0216, std=0.0355\n",
      " - Weight 20: (8, 128, 128), mean=0.0008, std=0.0409\n",
      " - Weight 21: (128,), mean=-0.0004, std=0.0059\n",
      " - Weight 22: (128,), mean=1.0033, std=0.0444\n",
      " - Weight 23: (128,), mean=-0.0752, std=0.0420\n",
      " - Weight 24: (8, 128, 256), mean=-0.0005, std=0.0359\n",
      " - Weight 25: (256,), mean=0.0001, std=0.0031\n",
      " - Weight 26: (256,), mean=1.0004, std=0.0686\n",
      " - Weight 27: (256,), mean=-0.0740, std=0.0571\n",
      " - Weight 28: (8, 256, 256), mean=-0.0024, std=0.0323\n",
      " - Weight 29: (256,), mean=0.0004, std=0.0034\n",
      " - Weight 30: (256,), mean=1.0019, std=0.0472\n",
      " - Weight 31: (256,), mean=-0.1245, std=0.0463\n",
      " - Weight 32: (8, 256, 512), mean=-0.0021, std=0.0306\n",
      " - Weight 33: (512,), mean=0.0004, std=0.0022\n",
      " - Weight 34: (512,), mean=0.9906, std=0.0536\n",
      " - Weight 35: (512,), mean=-0.1595, std=0.0468\n",
      " - Weight 36: (8, 512, 512), mean=-0.0014, std=0.0280\n",
      " - Weight 37: (512,), mean=0.0007, std=0.0031\n",
      " - Weight 38: (512,), mean=0.9905, std=0.0510\n",
      " - Weight 39: (512,), mean=-0.1851, std=0.0335\n",
      " - Weight 40: (5120, 512), mean=0.0011, std=0.0258\n",
      " - Weight 41: (512,), mean=-0.0000, std=0.0022\n",
      " - Weight 42: (512,), mean=1.0018, std=0.0228\n",
      " - Weight 43: (512,), mean=-0.0724, std=0.0286\n",
      " - Weight 44: (512, 512), mean=0.0015, std=0.0478\n",
      " - Weight 45: (512,), mean=0.0001, std=0.0036\n",
      " - Weight 46: (512,), mean=1.0867, std=0.0479\n",
      " - Weight 47: (512,), mean=0.0628, std=0.0431\n",
      " - Weight 48: (512, 95), mean=-0.0610, std=0.0808\n",
      " - Weight 49: (95,), mean=-0.1272, std=0.0592\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 6s 62ms/step - loss: 13.2260 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 10.1583 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 7.9683 - accuracy: 6.2500e-04\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 5.9676 - accuracy: 0.0344\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 5.2015 - accuracy: 0.0938\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 4.4086 - accuracy: 0.2644\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 3.4303 - accuracy: 0.4444\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 2.9900 - accuracy: 0.5694\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 2.4379 - accuracy: 0.6706\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 2.0697 - accuracy: 0.7294\n",
      "   Task_4 training accuracy: 0.7294\n",
      "Task ~3 accuracy after training on Task_4: 0.0186\n",
      "🔍 [DEBUG] Initial weights shape:\n",
      " - Weight 0: (8, 1, 32)\n",
      " - Weight 1: (32,)\n",
      " - Weight 2: (32,)\n",
      " - Weight 3: (32,)\n",
      " - Weight 4: (8, 32, 32)\n",
      " - Weight 5: (32,)\n",
      " - Weight 6: (32,)\n",
      " - Weight 7: (32,)\n",
      " - Weight 8: (8, 32, 64)\n",
      " - Weight 9: (64,)\n",
      " - Weight 10: (64,)\n",
      " - Weight 11: (64,)\n",
      " - Weight 12: (8, 64, 64)\n",
      " - Weight 13: (64,)\n",
      " - Weight 14: (64,)\n",
      " - Weight 15: (64,)\n",
      " - Weight 16: (8, 64, 128)\n",
      " - Weight 17: (128,)\n",
      " - Weight 18: (128,)\n",
      " - Weight 19: (128,)\n",
      " - Weight 20: (8, 128, 128)\n",
      " - Weight 21: (128,)\n",
      " - Weight 22: (128,)\n",
      " - Weight 23: (128,)\n",
      " - Weight 24: (8, 128, 256)\n",
      " - Weight 25: (256,)\n",
      " - Weight 26: (256,)\n",
      " - Weight 27: (256,)\n",
      " - Weight 28: (8, 256, 256)\n",
      " - Weight 29: (256,)\n",
      " - Weight 30: (256,)\n",
      " - Weight 31: (256,)\n",
      " - Weight 32: (8, 256, 512)\n",
      " - Weight 33: (512,)\n",
      " - Weight 34: (512,)\n",
      " - Weight 35: (512,)\n",
      " - Weight 36: (8, 512, 512)\n",
      " - Weight 37: (512,)\n",
      " - Weight 38: (512,)\n",
      " - Weight 39: (512,)\n",
      " - Weight 40: (5120, 512)\n",
      " - Weight 41: (512,)\n",
      " - Weight 42: (512,)\n",
      " - Weight 43: (512,)\n",
      " - Weight 44: (512, 512)\n",
      " - Weight 45: (512,)\n",
      " - Weight 46: (512,)\n",
      " - Weight 47: (512,)\n",
      " - Weight 48: (512, 95)\n",
      " - Weight 49: (95,)\n",
      "\n",
      "✅ [DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32), mean=200144.4375, std=213843.8125\n",
      " - Fisher 1: (32,), mean=296820.0000, std=293269.4062\n",
      " - Fisher 2: (32,), mean=2764.8918, std=2749.3499\n",
      " - Fisher 3: (32,), mean=2746.3884, std=2432.3870\n",
      " - Fisher 4: (8, 32, 32), mean=1150.5341, std=2388.1013\n",
      " - Fisher 5: (32,), mean=1447.0360, std=1292.9736\n",
      " - Fisher 6: (32,), mean=2919.0835, std=3030.0173\n",
      " - Fisher 7: (32,), mean=1571.9072, std=1290.6805\n",
      " - Fisher 8: (8, 32, 64), mean=693.2600, std=2322.6458\n",
      " - Fisher 9: (64,), mean=158.4534, std=251.8087\n",
      " - Fisher 10: (64,), mean=2034.9396, std=3475.0840\n",
      " - Fisher 11: (64,), mean=304.9271, std=383.6945\n",
      " - Fisher 12: (8, 64, 64), mean=195.9928, std=566.1052\n",
      " - Fisher 13: (64,), mean=75.7963, std=103.8462\n",
      " - Fisher 14: (64,), mean=1223.8179, std=2060.0225\n",
      " - Fisher 15: (64,), mean=160.5123, std=174.4667\n",
      " - Fisher 16: (8, 64, 128), mean=49.6819, std=155.5745\n",
      " - Fisher 17: (128,), mean=12.2971, std=20.5510\n",
      " - Fisher 18: (128,), mean=327.0767, std=601.0049\n",
      " - Fisher 19: (128,), mean=95.3565, std=110.7501\n",
      " - Fisher 20: (8, 128, 128), mean=13.6399, std=37.6395\n",
      " - Fisher 21: (128,), mean=11.6746, std=12.7398\n",
      " - Fisher 22: (128,), mean=303.2122, std=659.8686\n",
      " - Fisher 23: (128,), mean=48.5061, std=37.9037\n",
      " - Fisher 24: (8, 128, 256), mean=9.8585, std=30.3910\n",
      " - Fisher 25: (256,), mean=4.9857, std=7.9008\n",
      " - Fisher 26: (256,), mean=118.2933, std=193.7071\n",
      " - Fisher 27: (256,), mean=45.2005, std=66.9826\n",
      " - Fisher 28: (8, 256, 256), mean=7.2465, std=27.6948\n",
      " - Fisher 29: (256,), mean=11.4466, std=19.4901\n",
      " - Fisher 30: (256,), mean=242.4464, std=472.1112\n",
      " - Fisher 31: (256,), mean=65.6352, std=83.1924\n",
      " - Fisher 32: (8, 256, 512), mean=3.5672, std=14.5833\n",
      " - Fisher 33: (512,), mean=2.8332, std=5.7944\n",
      " - Fisher 34: (512,), mean=53.7491, std=158.4409\n",
      " - Fisher 35: (512,), mean=33.3456, std=63.6150\n",
      " - Fisher 36: (8, 512, 512), mean=0.4874, std=1.1756\n",
      " - Fisher 37: (512,), mean=1.7505, std=1.9217\n",
      " - Fisher 38: (512,), mean=27.5509, std=40.6642\n",
      " - Fisher 39: (512,), mean=13.8272, std=11.7341\n",
      " - Fisher 40: (5120, 512), mean=0.4961, std=1.1975\n",
      " - Fisher 41: (512,), mean=0.8799, std=1.0152\n",
      " - Fisher 42: (512,), mean=11.8798, std=19.6722\n",
      " - Fisher 43: (512,), mean=8.2605, std=8.7311\n",
      " - Fisher 44: (512, 512), mean=2.0834, std=3.6123\n",
      " - Fisher 45: (512,), mean=7.0461, std=6.8833\n",
      " - Fisher 46: (512,), mean=8.0464, std=8.5136\n",
      " - Fisher 47: (512,), mean=18.2484, std=17.1058\n",
      " - Fisher 48: (512, 95), mean=11.2458, std=97.9138\n",
      " - Fisher 49: (95,), mean=49.3524, std=175.1270\n",
      "🧠 [DEBUG] Optimal weights (after task):\n",
      " - Weight 0: (8, 1, 32), mean=0.0016, std=0.0929\n",
      " - Weight 1: (32,), mean=-0.0010, std=0.0190\n",
      " - Weight 2: (32,), mean=1.0139, std=0.0518\n",
      " - Weight 3: (32,), mean=-0.0253, std=0.0461\n",
      " - Weight 4: (8, 32, 32), mean=0.0016, std=0.0685\n",
      " - Weight 5: (32,), mean=-0.0063, std=0.0208\n",
      " - Weight 6: (32,), mean=0.9960, std=0.0467\n",
      " - Weight 7: (32,), mean=-0.1865, std=0.0614\n",
      " - Weight 8: (8, 32, 64), mean=0.0021, std=0.0583\n",
      " - Weight 9: (64,), mean=0.0010, std=0.0091\n",
      " - Weight 10: (64,), mean=1.0013, std=0.0404\n",
      " - Weight 11: (64,), mean=-0.0306, std=0.0587\n",
      " - Weight 12: (8, 64, 64), mean=0.0023, std=0.0520\n",
      " - Weight 13: (64,), mean=0.0007, std=0.0076\n",
      " - Weight 14: (64,), mean=1.0059, std=0.0421\n",
      " - Weight 15: (64,), mean=-0.0786, std=0.0460\n",
      " - Weight 16: (8, 64, 128), mean=-0.0007, std=0.0447\n",
      " - Weight 17: (128,), mean=-0.0006, std=0.0052\n",
      " - Weight 18: (128,), mean=1.0039, std=0.0490\n",
      " - Weight 19: (128,), mean=-0.0215, std=0.0355\n",
      " - Weight 20: (8, 128, 128), mean=0.0009, std=0.0410\n",
      " - Weight 21: (128,), mean=-0.0004, std=0.0059\n",
      " - Weight 22: (128,), mean=1.0034, std=0.0444\n",
      " - Weight 23: (128,), mean=-0.0752, std=0.0420\n",
      " - Weight 24: (8, 128, 256), mean=-0.0004, std=0.0359\n",
      " - Weight 25: (256,), mean=0.0001, std=0.0031\n",
      " - Weight 26: (256,), mean=1.0006, std=0.0686\n",
      " - Weight 27: (256,), mean=-0.0739, std=0.0571\n",
      " - Weight 28: (8, 256, 256), mean=-0.0023, std=0.0323\n",
      " - Weight 29: (256,), mean=0.0004, std=0.0034\n",
      " - Weight 30: (256,), mean=1.0020, std=0.0473\n",
      " - Weight 31: (256,), mean=-0.1246, std=0.0464\n",
      " - Weight 32: (8, 256, 512), mean=-0.0020, std=0.0306\n",
      " - Weight 33: (512,), mean=0.0004, std=0.0022\n",
      " - Weight 34: (512,), mean=0.9910, std=0.0537\n",
      " - Weight 35: (512,), mean=-0.1594, std=0.0468\n",
      " - Weight 36: (8, 512, 512), mean=-0.0013, std=0.0282\n",
      " - Weight 37: (512,), mean=0.0007, std=0.0031\n",
      " - Weight 38: (512,), mean=0.9907, std=0.0509\n",
      " - Weight 39: (512,), mean=-0.1855, std=0.0335\n",
      " - Weight 40: (5120, 512), mean=0.0013, std=0.0259\n",
      " - Weight 41: (512,), mean=-0.0000, std=0.0022\n",
      " - Weight 42: (512,), mean=1.0022, std=0.0226\n",
      " - Weight 43: (512,), mean=-0.0730, std=0.0288\n",
      " - Weight 44: (512, 512), mean=0.0019, std=0.0478\n",
      " - Weight 45: (512,), mean=0.0001, std=0.0036\n",
      " - Weight 46: (512,), mean=1.0857, std=0.0505\n",
      " - Weight 47: (512,), mean=0.0631, std=0.0439\n",
      " - Weight 48: (512, 95), mean=-0.0624, std=0.0812\n",
      " - Weight 49: (95,), mean=-0.1370, std=0.0566\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 6s 62ms/step - loss: 12.3920 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 8.7851 - accuracy: 6.2500e-04\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 6.1528 - accuracy: 0.0381\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 5.0237 - accuracy: 0.0975\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 4.0359 - accuracy: 0.2438\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 3.2953 - accuracy: 0.4100\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 2.6788 - accuracy: 0.5437\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 2.2835 - accuracy: 0.6550\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 1.9802 - accuracy: 0.7125\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 1.7147 - accuracy: 0.7556\n",
      "   Task_5 training accuracy: 0.7556\n",
      "Task ~4 accuracy after training on Task_5: 0.0066\n",
      "🔍 [DEBUG] Initial weights shape:\n",
      " - Weight 0: (8, 1, 32)\n",
      " - Weight 1: (32,)\n",
      " - Weight 2: (32,)\n",
      " - Weight 3: (32,)\n",
      " - Weight 4: (8, 32, 32)\n",
      " - Weight 5: (32,)\n",
      " - Weight 6: (32,)\n",
      " - Weight 7: (32,)\n",
      " - Weight 8: (8, 32, 64)\n",
      " - Weight 9: (64,)\n",
      " - Weight 10: (64,)\n",
      " - Weight 11: (64,)\n",
      " - Weight 12: (8, 64, 64)\n",
      " - Weight 13: (64,)\n",
      " - Weight 14: (64,)\n",
      " - Weight 15: (64,)\n",
      " - Weight 16: (8, 64, 128)\n",
      " - Weight 17: (128,)\n",
      " - Weight 18: (128,)\n",
      " - Weight 19: (128,)\n",
      " - Weight 20: (8, 128, 128)\n",
      " - Weight 21: (128,)\n",
      " - Weight 22: (128,)\n",
      " - Weight 23: (128,)\n",
      " - Weight 24: (8, 128, 256)\n",
      " - Weight 25: (256,)\n",
      " - Weight 26: (256,)\n",
      " - Weight 27: (256,)\n",
      " - Weight 28: (8, 256, 256)\n",
      " - Weight 29: (256,)\n",
      " - Weight 30: (256,)\n",
      " - Weight 31: (256,)\n",
      " - Weight 32: (8, 256, 512)\n",
      " - Weight 33: (512,)\n",
      " - Weight 34: (512,)\n",
      " - Weight 35: (512,)\n",
      " - Weight 36: (8, 512, 512)\n",
      " - Weight 37: (512,)\n",
      " - Weight 38: (512,)\n",
      " - Weight 39: (512,)\n",
      " - Weight 40: (5120, 512)\n",
      " - Weight 41: (512,)\n",
      " - Weight 42: (512,)\n",
      " - Weight 43: (512,)\n",
      " - Weight 44: (512, 512)\n",
      " - Weight 45: (512,)\n",
      " - Weight 46: (512,)\n",
      " - Weight 47: (512,)\n",
      " - Weight 48: (512, 95)\n",
      " - Weight 49: (95,)\n",
      "\n",
      "✅ [DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32), mean=233692.6719, std=254730.5469\n",
      " - Fisher 1: (32,), mean=425065.5625, std=521630.9375\n",
      " - Fisher 2: (32,), mean=5340.6372, std=6965.6655\n",
      " - Fisher 3: (32,), mean=3366.1489, std=3438.0967\n",
      " - Fisher 4: (8, 32, 32), mean=1903.8202, std=4237.3989\n",
      " - Fisher 5: (32,), mean=1732.6793, std=1952.3843\n",
      " - Fisher 6: (32,), mean=4223.0771, std=4875.9102\n",
      " - Fisher 7: (32,), mean=1882.3334, std=2232.4580\n",
      " - Fisher 8: (8, 32, 64), mean=1257.5203, std=4440.3618\n",
      " - Fisher 9: (64,), mean=231.9958, std=402.5499\n",
      " - Fisher 10: (64,), mean=3283.0068, std=5912.3525\n",
      " - Fisher 11: (64,), mean=442.1195, std=560.2357\n",
      " - Fisher 12: (8, 64, 64), mean=353.3482, std=801.8009\n",
      " - Fisher 13: (64,), mean=105.7260, std=124.6169\n",
      " - Fisher 14: (64,), mean=1863.2311, std=2867.0488\n",
      " - Fisher 15: (64,), mean=204.9931, std=198.4168\n",
      " - Fisher 16: (8, 64, 128), mean=83.1543, std=225.5968\n",
      " - Fisher 17: (128,), mean=17.1109, std=26.0672\n",
      " - Fisher 18: (128,), mean=579.2159, std=1168.6747\n",
      " - Fisher 19: (128,), mean=145.7111, std=170.6993\n",
      " - Fisher 20: (8, 128, 128), mean=22.4697, std=65.8904\n",
      " - Fisher 21: (128,), mean=12.6725, std=17.5111\n",
      " - Fisher 22: (128,), mean=427.6107, std=894.3062\n",
      " - Fisher 23: (128,), mean=42.3477, std=44.9661\n",
      " - Fisher 24: (8, 128, 256), mean=11.3586, std=37.7868\n",
      " - Fisher 25: (256,), mean=4.0420, std=5.9358\n",
      " - Fisher 26: (256,), mean=143.0603, std=341.7725\n",
      " - Fisher 27: (256,), mean=42.0897, std=58.7266\n",
      " - Fisher 28: (8, 256, 256), mean=6.8149, std=19.9372\n",
      " - Fisher 29: (256,), mean=11.2249, std=15.9617\n",
      " - Fisher 30: (256,), mean=204.7928, std=371.4680\n",
      " - Fisher 31: (256,), mean=74.1757, std=97.8969\n",
      " - Fisher 32: (8, 256, 512), mean=3.0765, std=11.9756\n",
      " - Fisher 33: (512,), mean=3.1915, std=7.2381\n",
      " - Fisher 34: (512,), mean=58.1128, std=177.2500\n",
      " - Fisher 35: (512,), mean=39.0548, std=73.1316\n",
      " - Fisher 36: (8, 512, 512), mean=0.5873, std=1.4247\n",
      " - Fisher 37: (512,), mean=2.1474, std=2.4793\n",
      " - Fisher 38: (512,), mean=31.0663, std=45.3825\n",
      " - Fisher 39: (512,), mean=16.6472, std=14.8435\n",
      " - Fisher 40: (5120, 512), mean=0.6355, std=1.8910\n",
      " - Fisher 41: (512,), mean=1.1396, std=1.2845\n",
      " - Fisher 42: (512,), mean=12.7961, std=18.2325\n",
      " - Fisher 43: (512,), mean=8.3026, std=7.9934\n",
      " - Fisher 44: (512, 512), mean=2.3103, std=3.7718\n",
      " - Fisher 45: (512,), mean=6.8278, std=6.2632\n",
      " - Fisher 46: (512,), mean=9.3584, std=9.3539\n",
      " - Fisher 47: (512,), mean=18.0501, std=16.7423\n",
      " - Fisher 48: (512, 95), mean=12.6376, std=105.0343\n",
      " - Fisher 49: (95,), mean=46.7802, std=157.7654\n"
     ]
    }
   ],
   "source": [
    "# 모델 빌드 \n",
    "model = DFNet.build(input_shape=(10000, 1), classes=MAX_LABEL)\n",
    "# 옵티마이저 설정 \n",
    "OPTIMIZER = Adamax(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "train_loop(model, OPTIMIZER, data, test_size=0.2, first_task = 39, inc_task = 10, first_epochs = 50, inc_epochs = 10, lamb=0.1, num_sample=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adamax.py:99: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 14s 59ms/step - loss: 4.5246 - accuracy: 0.0392\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.9980 - accuracy: 0.0636\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.7535 - accuracy: 0.0817\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.5757 - accuracy: 0.1031\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.4411 - accuracy: 0.1169\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.3163 - accuracy: 0.1411\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.2185 - accuracy: 0.1517\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.1344 - accuracy: 0.1758\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.0746 - accuracy: 0.1866\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.9964 - accuracy: 0.1984\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.9197 - accuracy: 0.2091\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.8177 - accuracy: 0.2314\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.7838 - accuracy: 0.2461\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 2.6761 - accuracy: 0.2639\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 2.6237 - accuracy: 0.2798\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.5377 - accuracy: 0.3020\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 2.4732 - accuracy: 0.3175\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.4031 - accuracy: 0.3344\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.3591 - accuracy: 0.3438\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.2677 - accuracy: 0.3747\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.2091 - accuracy: 0.3850\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.1694 - accuracy: 0.3917\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.1207 - accuracy: 0.4159\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.0375 - accuracy: 0.4402\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.0040 - accuracy: 0.4417\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.9262 - accuracy: 0.4691\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.8874 - accuracy: 0.4794\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.8149 - accuracy: 0.4998\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.7539 - accuracy: 0.5167\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.7013 - accuracy: 0.5258\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 12s 62ms/step - loss: 1.6714 - accuracy: 0.5423\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.6206 - accuracy: 0.5575\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.5444 - accuracy: 0.5767\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.4998 - accuracy: 0.5938\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 12s 61ms/step - loss: 1.4487 - accuracy: 0.6067\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.4063 - accuracy: 0.6263\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.3628 - accuracy: 0.6264\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.3454 - accuracy: 0.6400\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.2728 - accuracy: 0.6619\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.2496 - accuracy: 0.6705\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.2062 - accuracy: 0.6789\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.1676 - accuracy: 0.6898\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.1269 - accuracy: 0.7048\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.0940 - accuracy: 0.7083\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.0368 - accuracy: 0.7272\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.0205 - accuracy: 0.7339\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.9957 - accuracy: 0.7423\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.9487 - accuracy: 0.7598\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.9152 - accuracy: 0.7642\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.8957 - accuracy: 0.7664\n",
      "   Task_0 training accuracy: 0.7664\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 6s 59ms/step - loss: 19.0733 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 15.4566 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 12.6425 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 11.5945 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.2294 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.6212 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.2436 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.9745 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.6455 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.3246 - accuracy: 0.0000e+00\n",
      "   Task_1 training accuracy: 0.0000\n",
      "Task ~0 accuracy after training on Task_1: 0.0456\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 5s 59ms/step - loss: 12.9699 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 12.4554 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 12.2216 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.8958 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.4278 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.0144 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.1763 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.6828 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.4158 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.9798 - accuracy: 0.0000e+00\n",
      "   Task_2 training accuracy: 0.0000\n",
      "Task ~1 accuracy after training on Task_2: 0.0195\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 5s 59ms/step - loss: 12.9692 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 12.3616 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.9394 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.7081 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.2376 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.1134 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.8034 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.4639 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.5045 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.9315 - accuracy: 0.0000e+00\n",
      "   Task_3 training accuracy: 0.0000\n",
      "Task ~2 accuracy after training on Task_3: 0.0167\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 5s 59ms/step - loss: 12.3363 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.7804 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.5398 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 11.0839 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.5408 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.2734 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.1743 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.5608 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.4279 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.2957 - accuracy: 0.0000e+00\n",
      "   Task_4 training accuracy: 0.0000\n",
      "Task ~3 accuracy after training on Task_4: 0.0189\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 5s 59ms/step - loss: 11.5175 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.7031 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.2423 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 10.1666 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 9.7457 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.4408 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.2005 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 8.7827 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 8.6980 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 8.3323 - accuracy: 0.0000e+00\n",
      "   Task_5 training accuracy: 0.0000\n",
      "Task ~4 accuracy after training on Task_5: 0.0153\n"
     ]
    }
   ],
   "source": [
    "# 모델 빌드 \n",
    "model = DFNet.build(input_shape=(10000, 1), classes=MAX_LABEL)\n",
    "# 옵티마이저 설정 \n",
    "OPTIMIZER = Adamax(lr=0.0002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "train_loop_nonbase(model, OPTIMIZER, data, test_size=0.2, first_task = 39, inc_task = 10, first_epochs = 50, inc_epochs = 10, lamb=0, num_sample=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adamax.py:99: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 - 14s - loss: 3.8412 - accuracy: 0.0864 - 14s/epoch - 71ms/step\n",
      "Epoch 2/50\n",
      "200/200 - 12s - loss: 3.2819 - accuracy: 0.1431 - 12s/epoch - 58ms/step\n",
      "Epoch 3/50\n",
      "200/200 - 11s - loss: 3.0243 - accuracy: 0.1838 - 11s/epoch - 57ms/step\n",
      "Epoch 4/50\n",
      "200/200 - 11s - loss: 2.7955 - accuracy: 0.2414 - 11s/epoch - 57ms/step\n",
      "Epoch 5/50\n",
      "200/200 - 11s - loss: 2.6375 - accuracy: 0.2722 - 11s/epoch - 57ms/step\n",
      "Epoch 6/50\n",
      "200/200 - 11s - loss: 2.4461 - accuracy: 0.3209 - 11s/epoch - 57ms/step\n",
      "Epoch 7/50\n",
      "200/200 - 11s - loss: 2.2863 - accuracy: 0.3636 - 11s/epoch - 57ms/step\n",
      "Epoch 8/50\n",
      "200/200 - 11s - loss: 2.1523 - accuracy: 0.4011 - 11s/epoch - 57ms/step\n",
      "Epoch 9/50\n",
      "200/200 - 11s - loss: 2.0190 - accuracy: 0.4259 - 11s/epoch - 57ms/step\n",
      "Epoch 10/50\n",
      "200/200 - 11s - loss: 1.8516 - accuracy: 0.4811 - 11s/epoch - 57ms/step\n",
      "Epoch 11/50\n",
      "200/200 - 11s - loss: 1.7139 - accuracy: 0.5219 - 11s/epoch - 57ms/step\n",
      "Epoch 12/50\n",
      "200/200 - 11s - loss: 1.5980 - accuracy: 0.5545 - 11s/epoch - 57ms/step\n",
      "Epoch 13/50\n",
      "200/200 - 11s - loss: 1.4840 - accuracy: 0.5898 - 11s/epoch - 57ms/step\n",
      "Epoch 14/50\n",
      "200/200 - 11s - loss: 1.3798 - accuracy: 0.6186 - 11s/epoch - 57ms/step\n",
      "Epoch 15/50\n",
      "200/200 - 11s - loss: 1.2968 - accuracy: 0.6425 - 11s/epoch - 57ms/step\n",
      "Epoch 16/50\n",
      "200/200 - 11s - loss: 1.2107 - accuracy: 0.6703 - 11s/epoch - 57ms/step\n",
      "Epoch 17/50\n",
      "200/200 - 11s - loss: 1.0965 - accuracy: 0.7014 - 11s/epoch - 57ms/step\n",
      "Epoch 18/50\n",
      "200/200 - 11s - loss: 0.9998 - accuracy: 0.7269 - 11s/epoch - 57ms/step\n",
      "Epoch 19/50\n",
      "200/200 - 11s - loss: 0.9531 - accuracy: 0.7397 - 11s/epoch - 57ms/step\n",
      "Epoch 20/50\n",
      "200/200 - 11s - loss: 0.8827 - accuracy: 0.7595 - 11s/epoch - 57ms/step\n",
      "Epoch 21/50\n",
      "200/200 - 11s - loss: 0.8186 - accuracy: 0.7825 - 11s/epoch - 57ms/step\n",
      "Epoch 22/50\n",
      "200/200 - 11s - loss: 0.7648 - accuracy: 0.7961 - 11s/epoch - 57ms/step\n",
      "Epoch 23/50\n",
      "200/200 - 11s - loss: 0.6962 - accuracy: 0.8133 - 11s/epoch - 57ms/step\n",
      "Epoch 24/50\n",
      "200/200 - 11s - loss: 0.6537 - accuracy: 0.8253 - 11s/epoch - 57ms/step\n",
      "Epoch 25/50\n",
      "200/200 - 11s - loss: 0.5985 - accuracy: 0.8423 - 11s/epoch - 57ms/step\n",
      "Epoch 26/50\n",
      "200/200 - 11s - loss: 0.5798 - accuracy: 0.8484 - 11s/epoch - 57ms/step\n",
      "Epoch 27/50\n",
      "200/200 - 11s - loss: 0.5368 - accuracy: 0.8570 - 11s/epoch - 57ms/step\n",
      "Epoch 28/50\n",
      "200/200 - 11s - loss: 0.5219 - accuracy: 0.8600 - 11s/epoch - 57ms/step\n",
      "Epoch 29/50\n",
      "200/200 - 11s - loss: 0.4817 - accuracy: 0.8750 - 11s/epoch - 57ms/step\n",
      "Epoch 30/50\n",
      "200/200 - 11s - loss: 0.4431 - accuracy: 0.8808 - 11s/epoch - 57ms/step\n",
      "Epoch 31/50\n",
      "200/200 - 11s - loss: 0.4101 - accuracy: 0.8934 - 11s/epoch - 57ms/step\n",
      "Epoch 32/50\n",
      "200/200 - 11s - loss: 0.3907 - accuracy: 0.8988 - 11s/epoch - 57ms/step\n",
      "Epoch 33/50\n",
      "200/200 - 11s - loss: 0.3830 - accuracy: 0.8975 - 11s/epoch - 57ms/step\n",
      "Epoch 34/50\n",
      "200/200 - 11s - loss: 0.3557 - accuracy: 0.9070 - 11s/epoch - 57ms/step\n",
      "Epoch 35/50\n",
      "200/200 - 11s - loss: 0.3303 - accuracy: 0.9125 - 11s/epoch - 57ms/step\n",
      "Epoch 36/50\n",
      "200/200 - 11s - loss: 0.3239 - accuracy: 0.9142 - 11s/epoch - 57ms/step\n",
      "Epoch 37/50\n",
      "200/200 - 11s - loss: 0.3102 - accuracy: 0.9202 - 11s/epoch - 57ms/step\n",
      "Epoch 38/50\n",
      "200/200 - 11s - loss: 0.2832 - accuracy: 0.9231 - 11s/epoch - 57ms/step\n",
      "Epoch 39/50\n",
      "200/200 - 11s - loss: 0.2781 - accuracy: 0.9234 - 11s/epoch - 57ms/step\n",
      "Epoch 40/50\n",
      "200/200 - 11s - loss: 0.2617 - accuracy: 0.9309 - 11s/epoch - 57ms/step\n",
      "Epoch 41/50\n",
      "200/200 - 11s - loss: 0.2410 - accuracy: 0.9317 - 11s/epoch - 57ms/step\n",
      "Epoch 42/50\n",
      "200/200 - 11s - loss: 0.2540 - accuracy: 0.9323 - 11s/epoch - 57ms/step\n",
      "Epoch 43/50\n",
      "200/200 - 11s - loss: 0.2286 - accuracy: 0.9402 - 11s/epoch - 57ms/step\n",
      "Epoch 44/50\n",
      "200/200 - 11s - loss: 0.2258 - accuracy: 0.9411 - 11s/epoch - 57ms/step\n",
      "Epoch 45/50\n",
      "200/200 - 11s - loss: 0.2142 - accuracy: 0.9452 - 11s/epoch - 57ms/step\n",
      "Epoch 46/50\n",
      "200/200 - 11s - loss: 0.2131 - accuracy: 0.9417 - 11s/epoch - 57ms/step\n",
      "Epoch 47/50\n",
      "200/200 - 11s - loss: 0.1854 - accuracy: 0.9508 - 11s/epoch - 57ms/step\n",
      "Epoch 48/50\n",
      "200/200 - 11s - loss: 0.1868 - accuracy: 0.9481 - 11s/epoch - 57ms/step\n",
      "Epoch 49/50\n",
      "200/200 - 11s - loss: 0.1830 - accuracy: 0.9516 - 11s/epoch - 57ms/step\n",
      "Epoch 50/50\n",
      "200/200 - 11s - loss: 0.1730 - accuracy: 0.9519 - 11s/epoch - 57ms/step\n",
      "   First_task training accuracy: 0.9519\n",
      "Epoch 1/10\n",
      "250/250 - 17s - loss: 2.2470 - accuracy: 0.7280 - 17s/epoch - 68ms/step\n",
      "Epoch 2/10\n",
      "250/250 - 14s - loss: 1.3125 - accuracy: 0.7380 - 14s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "250/250 - 14s - loss: 1.0904 - accuracy: 0.7558 - 14s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "250/250 - 14s - loss: 0.9339 - accuracy: 0.7710 - 14s/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "250/250 - 14s - loss: 0.7788 - accuracy: 0.7899 - 14s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "250/250 - 14s - loss: 0.7114 - accuracy: 0.8050 - 14s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "250/250 - 14s - loss: 0.6108 - accuracy: 0.8298 - 14s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "250/250 - 14s - loss: 0.5713 - accuracy: 0.8484 - 14s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "250/250 - 14s - loss: 0.4917 - accuracy: 0.8742 - 14s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "250/250 - 14s - loss: 0.4428 - accuracy: 0.8878 - 14s/epoch - 57ms/step\n",
      "   1_task training accuracy: 0.8878\n",
      "Task 1 accuracy after training on Task ~0: 0.8913\n",
      "Epoch 1/10\n",
      "300/300 - 19s - loss: 2.5752 - accuracy: 0.6994 - 19s/epoch - 65ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 17s - loss: 1.6301 - accuracy: 0.7252 - 17s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "300/300 - 17s - loss: 1.4048 - accuracy: 0.7327 - 17s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "300/300 - 17s - loss: 1.2340 - accuracy: 0.7428 - 17s/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "300/300 - 17s - loss: 1.1146 - accuracy: 0.7511 - 17s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "300/300 - 17s - loss: 0.9654 - accuracy: 0.7610 - 17s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "300/300 - 17s - loss: 0.8718 - accuracy: 0.7821 - 17s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "300/300 - 17s - loss: 0.8059 - accuracy: 0.7875 - 17s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "300/300 - 17s - loss: 0.7555 - accuracy: 0.8032 - 17s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "300/300 - 17s - loss: 0.6915 - accuracy: 0.8176 - 17s/epoch - 57ms/step\n",
      "   2_task training accuracy: 0.8176\n",
      "Task 2 accuracy after training on Task ~1: 0.8910\n",
      "Epoch 1/10\n",
      "350/350 - 22s - loss: 2.5223 - accuracy: 0.6523 - 22s/epoch - 63ms/step\n",
      "Epoch 2/10\n",
      "350/350 - 20s - loss: 1.7601 - accuracy: 0.6801 - 20s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "350/350 - 20s - loss: 1.6245 - accuracy: 0.6907 - 20s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "350/350 - 20s - loss: 1.5063 - accuracy: 0.6978 - 20s/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "350/350 - 20s - loss: 1.4343 - accuracy: 0.7066 - 20s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "350/350 - 20s - loss: 1.3308 - accuracy: 0.7182 - 20s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "350/350 - 20s - loss: 1.2618 - accuracy: 0.7291 - 20s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "350/350 - 20s - loss: 1.2170 - accuracy: 0.7284 - 20s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "350/350 - 20s - loss: 1.1018 - accuracy: 0.7446 - 20s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "350/350 - 20s - loss: 1.0066 - accuracy: 0.7562 - 20s/epoch - 57ms/step\n",
      "   3_task training accuracy: 0.7562\n",
      "Task 3 accuracy after training on Task ~2: 0.8737\n",
      "Epoch 1/10\n",
      "400/400 - 25s - loss: 2.5343 - accuracy: 0.6284 - 25s/epoch - 63ms/step\n",
      "Epoch 2/10\n",
      "400/400 - 23s - loss: 1.9492 - accuracy: 0.6474 - 23s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "400/400 - 23s - loss: 1.8645 - accuracy: 0.6563 - 23s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "400/400 - 23s - loss: 1.7668 - accuracy: 0.6608 - 23s/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "400/400 - 23s - loss: 1.6653 - accuracy: 0.6723 - 23s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "400/400 - 23s - loss: 1.6236 - accuracy: 0.6762 - 23s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "400/400 - 23s - loss: 1.5587 - accuracy: 0.6795 - 23s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "400/400 - 23s - loss: 1.5289 - accuracy: 0.6842 - 23s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "400/400 - 23s - loss: 1.4717 - accuracy: 0.6895 - 23s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "400/400 - 23s - loss: 1.4204 - accuracy: 0.6979 - 23s/epoch - 57ms/step\n",
      "   4_task training accuracy: 0.6979\n",
      "Task 4 accuracy after training on Task ~3: 0.8104\n",
      "Epoch 1/10\n",
      "450/450 - 28s - loss: 2.8248 - accuracy: 0.5773 - 28s/epoch - 62ms/step\n",
      "Epoch 2/10\n",
      "450/450 - 26s - loss: 2.3673 - accuracy: 0.6047 - 26s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "450/450 - 26s - loss: 2.3122 - accuracy: 0.6089 - 26s/epoch - 58ms/step\n",
      "Epoch 4/10\n",
      "450/450 - 26s - loss: 2.1869 - accuracy: 0.6202 - 26s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "450/450 - 26s - loss: 2.1562 - accuracy: 0.6248 - 26s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "450/450 - 26s - loss: 2.1021 - accuracy: 0.6294 - 26s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "450/450 - 26s - loss: 2.0799 - accuracy: 0.6297 - 26s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "450/450 - 26s - loss: 2.0304 - accuracy: 0.6350 - 26s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "450/450 - 26s - loss: 1.9906 - accuracy: 0.6390 - 26s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "450/450 - 26s - loss: 1.9278 - accuracy: 0.6481 - 26s/epoch - 57ms/step\n",
      "   5_task training accuracy: 0.6481\n",
      "Task 5 accuracy after training on Task ~4: 0.6841\n"
     ]
    }
   ],
   "source": [
    "# Joint\n",
    "# 모델 빌드 \n",
    "model = DFNet.build(input_shape=(10000, 1), classes=MAX_LABEL)\n",
    "# 옵티마이저 설정 \n",
    "OPTIMIZER = Adamax(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "train_loop_joint(model, OPTIMIZER, data, test_size=0.2, first_task = 39, inc_task = 10, first_epochs = 50, inc_epochs = 10, lamb=0, num_sample=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 58ms/step - loss: 3.1144 - accuracy: 0.1500\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 2.4537 - accuracy: 0.2622\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 2.1794 - accuracy: 0.3431\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 1.9178 - accuracy: 0.4003\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 1.6950 - accuracy: 0.4816\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 1.5168 - accuracy: 0.5216\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 1.3262 - accuracy: 0.6019\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 1.1825 - accuracy: 0.6425\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 1.0818 - accuracy: 0.6672\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.9789 - accuracy: 0.7063\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.8352 - accuracy: 0.7544\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.7431 - accuracy: 0.7831\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.7137 - accuracy: 0.7862\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.6536 - accuracy: 0.8072\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.6032 - accuracy: 0.8294\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.5403 - accuracy: 0.8413\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.5498 - accuracy: 0.8416\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.4620 - accuracy: 0.8719\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.4280 - accuracy: 0.8734\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.4394 - accuracy: 0.8669\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.4211 - accuracy: 0.8822\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.3692 - accuracy: 0.8922\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.3679 - accuracy: 0.8944\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.3113 - accuracy: 0.9134\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.3180 - accuracy: 0.9097\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.3296 - accuracy: 0.9047\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.3032 - accuracy: 0.9128\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2797 - accuracy: 0.9222\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2539 - accuracy: 0.9291\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2619 - accuracy: 0.9269\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2227 - accuracy: 0.9344\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2345 - accuracy: 0.9341\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2058 - accuracy: 0.9406\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1873 - accuracy: 0.9450\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2135 - accuracy: 0.9353\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2024 - accuracy: 0.9419\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 6s 57ms/step - loss: 0.1667 - accuracy: 0.9563\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1999 - accuracy: 0.9438\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1622 - accuracy: 0.9556\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1514 - accuracy: 0.9566\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.1654 - accuracy: 0.9516\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1718 - accuracy: 0.9484\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1585 - accuracy: 0.9509\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1455 - accuracy: 0.9578\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1622 - accuracy: 0.9531\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1657 - accuracy: 0.9534\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1270 - accuracy: 0.9622\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1324 - accuracy: 0.9575\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1256 - accuracy: 0.9609\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1319 - accuracy: 0.9606\n",
      "   Task_0 training accuracy: 0.9606\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 6s 59ms/step - loss: 7.9631 - accuracy: 0.3050\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6450 - accuracy: 0.7575\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.4883 - accuracy: 0.8087\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.4212 - accuracy: 0.8475\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.4029 - accuracy: 0.8475\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.3592 - accuracy: 0.8737\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.3188 - accuracy: 0.8900\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.2845 - accuracy: 0.8888\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 0.2418 - accuracy: 0.9150\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.2010 - accuracy: 0.9100\n",
      "   Task_1 training accuracy: 0.9100\n",
      "Task ~0 accuracy after training on Task_1: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 8.5513 - accuracy: 0.0650\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 1.5166 - accuracy: 0.3988\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.1595 - accuracy: 0.5450\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.9502 - accuracy: 0.5975\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.8085 - accuracy: 0.6650\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6086 - accuracy: 0.7325\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.5739 - accuracy: 0.7550\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.5772 - accuracy: 0.7487\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.5110 - accuracy: 0.7725\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.4678 - accuracy: 0.7912\n",
      "   Task_2 training accuracy: 0.7912\n",
      "Task ~1 accuracy after training on Task_2: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 60ms/step - loss: 12.0864 - accuracy: 0.0075\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.6394 - accuracy: 0.2288\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.5808 - accuracy: 0.3400\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.3982 - accuracy: 0.4013\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.2593 - accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.0104 - accuracy: 0.6737\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.9078 - accuracy: 0.7138\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.7378 - accuracy: 0.7462\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6492 - accuracy: 0.7850\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.5379 - accuracy: 0.8225\n",
      "   Task_3 training accuracy: 0.8225\n",
      "Task ~2 accuracy after training on Task_3: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 12.6038 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 3.6952 - accuracy: 0.0637\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.3042 - accuracy: 0.3225\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.6399 - accuracy: 0.3938\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.3707 - accuracy: 0.4412\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.2623 - accuracy: 0.5113\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.1272 - accuracy: 0.5800\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.9964 - accuracy: 0.6400\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.8133 - accuracy: 0.7225\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6686 - accuracy: 0.7763\n",
      "   Task_4 training accuracy: 0.7763\n",
      "Task ~3 accuracy after training on Task_4: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 11.0780 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 4.9708 - accuracy: 0.0100\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 3.5025 - accuracy: 0.0413\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 2.6534 - accuracy: 0.2000\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 1.9245 - accuracy: 0.3237\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 1.6785 - accuracy: 0.3413\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 1.3912 - accuracy: 0.4800\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 1.1243 - accuracy: 0.6025\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 0.8327 - accuracy: 0.7000\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 0.6860 - accuracy: 0.7588\n",
      "   Task_5 training accuracy: 0.7588\n",
      "Task ~4 accuracy after training on Task_5: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 12.6796 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 6.3131 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 4.5204 - accuracy: 0.0063\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 3.5670 - accuracy: 0.0312\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.7489 - accuracy: 0.1813\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 2.2469 - accuracy: 0.2537\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 1.9238 - accuracy: 0.2475\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.7929 - accuracy: 0.2700\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.6925 - accuracy: 0.2937\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.6431 - accuracy: 0.2837\n",
      "   Task_6 training accuracy: 0.2837\n",
      "Task ~5 accuracy after training on Task_6: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 12.0689 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 7.1209 - accuracy: 0.0012\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.2190 - accuracy: 0.0162\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 4.2792 - accuracy: 0.0812\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 3.6329 - accuracy: 0.1150\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 3.0252 - accuracy: 0.2463\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.4897 - accuracy: 0.3050\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.0421 - accuracy: 0.3187\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.8062 - accuracy: 0.3275\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.5998 - accuracy: 0.3462\n",
      "   Task_7 training accuracy: 0.3462\n",
      "Task ~6 accuracy after training on Task_7: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 10.5861 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.9036 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.5779 - accuracy: 0.0012\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 4.7358 - accuracy: 0.0025\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 4.2673 - accuracy: 0.0213\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 3.6616 - accuracy: 0.0550\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 3.2710 - accuracy: 0.1238\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.6745 - accuracy: 0.2275\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.3761 - accuracy: 0.2537\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.0477 - accuracy: 0.2812\n",
      "   Task_8 training accuracy: 0.2812\n",
      "Task ~7 accuracy after training on Task_8: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 10.7290 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 7.8548 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.2776 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.5828 - accuracy: 0.0025\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.0261 - accuracy: 0.0075\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 4.5730 - accuracy: 0.0125\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 4.2032 - accuracy: 0.0288\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 3.9134 - accuracy: 0.0725\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 3.6184 - accuracy: 0.1200\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 3.3520 - accuracy: 0.1625\n",
      "   Task_9 training accuracy: 0.1625\n",
      "Task ~8 accuracy after training on Task_9: 0.0000\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 7.8505 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 6.7574 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 6.0001 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 5.5802 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 5.2954 - accuracy: 0.0025\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 5.0433 - accuracy: 0.0137\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 4.8101 - accuracy: 0.0262\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 4.6824 - accuracy: 0.0250\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 4.5682 - accuracy: 0.0400\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 4.4179 - accuracy: 0.0475\n",
      "   Task_10 training accuracy: 0.0475\n",
      "Task ~9 accuracy after training on Task_10: 0.0112\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 6.6857 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.0643 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.7286 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.4728 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.2977 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.1222 - accuracy: 0.0025\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 4.9455 - accuracy: 0.0213\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 4.8286 - accuracy: 0.0325\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 4.7030 - accuracy: 0.0487\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 4.6156 - accuracy: 0.0587\n",
      "   Task_11 training accuracy: 0.0587\n",
      "Task ~10 accuracy after training on Task_11: 0.0157\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 6.4180 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 6.1403 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.9152 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.7429 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.6089 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.4924 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.3892 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.3085 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.2220 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.1508 - accuracy: 0.0000e+00\n",
      "   Task_12 training accuracy: 0.0000\n",
      "Task ~11 accuracy after training on Task_12: 0.0237\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 6.4178 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.1583 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.0056 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.8838 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.7660 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.6696 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.5895 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.5129 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.4390 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 5.3741 - accuracy: 0.0000e+00\n",
      "   Task_13 training accuracy: 0.0000\n",
      "Task ~12 accuracy after training on Task_13: 0.0147\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 6.3300 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.1735 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 6.0455 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.9434 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.8529 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.7713 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 5.6962 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.6255 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.5604 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.4949 - accuracy: 0.0000e+00\n",
      "   Task_14 training accuracy: 0.0000\n",
      "Task ~13 accuracy after training on Task_14: 0.0121\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 59ms/step - loss: 6.4541 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.3079 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.1913 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 6.0914 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 6.0086 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.9248 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.8510 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 5.7809 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 5.7147 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 5.6510 - accuracy: 0.0000e+00\n",
      "   Task_15 training accuracy: 0.0000\n",
      "Task ~14 accuracy after training on Task_15: 0.0122\n"
     ]
    }
   ],
   "source": [
    "# Nonbase\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "# 모델 빌드 \n",
    "model = DFNet.build(input_shape=(10000, 1), classes=MAX_LABEL)\n",
    "# 옵티마이저 설정 \n",
    "OPTIMIZER = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "train_loop(model, OPTIMIZER, data, test_size=0.2, first_task = 19, inc_task = 5, first_epochs = 50, inc_epochs = 10, lamb=0, num_sample=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 - 8s - loss: 3.1071 - accuracy: 0.1534 - 8s/epoch - 81ms/step\n",
      "Epoch 2/50\n",
      "100/100 - 6s - loss: 2.4469 - accuracy: 0.2609 - 6s/epoch - 56ms/step\n",
      "Epoch 3/50\n",
      "100/100 - 6s - loss: 2.1326 - accuracy: 0.3375 - 6s/epoch - 55ms/step\n",
      "Epoch 4/50\n",
      "100/100 - 6s - loss: 1.8926 - accuracy: 0.4131 - 6s/epoch - 55ms/step\n",
      "Epoch 5/50\n",
      "100/100 - 6s - loss: 1.7309 - accuracy: 0.4731 - 6s/epoch - 56ms/step\n",
      "Epoch 6/50\n",
      "100/100 - 6s - loss: 1.5253 - accuracy: 0.5272 - 6s/epoch - 56ms/step\n",
      "Epoch 7/50\n",
      "100/100 - 6s - loss: 1.3574 - accuracy: 0.5791 - 6s/epoch - 56ms/step\n",
      "Epoch 8/50\n",
      "100/100 - 6s - loss: 1.2562 - accuracy: 0.6072 - 6s/epoch - 56ms/step\n",
      "Epoch 9/50\n",
      "100/100 - 6s - loss: 1.1152 - accuracy: 0.6594 - 6s/epoch - 56ms/step\n",
      "Epoch 10/50\n",
      "100/100 - 6s - loss: 1.0259 - accuracy: 0.6869 - 6s/epoch - 56ms/step\n",
      "Epoch 11/50\n",
      "100/100 - 6s - loss: 0.9367 - accuracy: 0.7081 - 6s/epoch - 56ms/step\n",
      "Epoch 12/50\n",
      "100/100 - 6s - loss: 0.8603 - accuracy: 0.7350 - 6s/epoch - 56ms/step\n",
      "Epoch 13/50\n",
      "100/100 - 6s - loss: 0.7834 - accuracy: 0.7638 - 6s/epoch - 55ms/step\n",
      "Epoch 14/50\n",
      "100/100 - 6s - loss: 0.7277 - accuracy: 0.7872 - 6s/epoch - 56ms/step\n",
      "Epoch 15/50\n",
      "100/100 - 6s - loss: 0.6752 - accuracy: 0.7987 - 6s/epoch - 56ms/step\n",
      "Epoch 16/50\n",
      "100/100 - 6s - loss: 0.6147 - accuracy: 0.8191 - 6s/epoch - 56ms/step\n",
      "Epoch 17/50\n",
      "100/100 - 6s - loss: 0.5750 - accuracy: 0.8356 - 6s/epoch - 56ms/step\n",
      "Epoch 18/50\n",
      "100/100 - 6s - loss: 0.5367 - accuracy: 0.8450 - 6s/epoch - 56ms/step\n",
      "Epoch 19/50\n",
      "100/100 - 6s - loss: 0.5194 - accuracy: 0.8534 - 6s/epoch - 56ms/step\n",
      "Epoch 20/50\n",
      "100/100 - 6s - loss: 0.4888 - accuracy: 0.8584 - 6s/epoch - 56ms/step\n",
      "Epoch 21/50\n",
      "100/100 - 6s - loss: 0.4468 - accuracy: 0.8747 - 6s/epoch - 56ms/step\n",
      "Epoch 22/50\n",
      "100/100 - 6s - loss: 0.4706 - accuracy: 0.8666 - 6s/epoch - 56ms/step\n",
      "Epoch 23/50\n",
      "100/100 - 6s - loss: 0.3791 - accuracy: 0.8925 - 6s/epoch - 56ms/step\n",
      "Epoch 24/50\n",
      "100/100 - 6s - loss: 0.3426 - accuracy: 0.8975 - 6s/epoch - 56ms/step\n",
      "Epoch 25/50\n",
      "100/100 - 6s - loss: 0.3403 - accuracy: 0.9006 - 6s/epoch - 56ms/step\n",
      "Epoch 26/50\n",
      "100/100 - 6s - loss: 0.3177 - accuracy: 0.9066 - 6s/epoch - 56ms/step\n",
      "Epoch 27/50\n",
      "100/100 - 6s - loss: 0.3008 - accuracy: 0.9109 - 6s/epoch - 56ms/step\n",
      "Epoch 28/50\n",
      "100/100 - 6s - loss: 0.2976 - accuracy: 0.9119 - 6s/epoch - 56ms/step\n",
      "Epoch 29/50\n",
      "100/100 - 6s - loss: 0.2747 - accuracy: 0.9209 - 6s/epoch - 56ms/step\n",
      "Epoch 30/50\n",
      "100/100 - 6s - loss: 0.2715 - accuracy: 0.9222 - 6s/epoch - 56ms/step\n",
      "Epoch 31/50\n",
      "100/100 - 6s - loss: 0.2341 - accuracy: 0.9312 - 6s/epoch - 56ms/step\n",
      "Epoch 32/50\n",
      "100/100 - 6s - loss: 0.2605 - accuracy: 0.9228 - 6s/epoch - 56ms/step\n",
      "Epoch 33/50\n",
      "100/100 - 6s - loss: 0.2298 - accuracy: 0.9300 - 6s/epoch - 56ms/step\n",
      "Epoch 34/50\n",
      "100/100 - 6s - loss: 0.2557 - accuracy: 0.9231 - 6s/epoch - 56ms/step\n",
      "Epoch 35/50\n",
      "100/100 - 6s - loss: 0.1871 - accuracy: 0.9466 - 6s/epoch - 56ms/step\n",
      "Epoch 36/50\n",
      "100/100 - 6s - loss: 0.1946 - accuracy: 0.9428 - 6s/epoch - 56ms/step\n",
      "Epoch 37/50\n",
      "100/100 - 6s - loss: 0.1995 - accuracy: 0.9394 - 6s/epoch - 56ms/step\n",
      "Epoch 38/50\n",
      "100/100 - 6s - loss: 0.1778 - accuracy: 0.9509 - 6s/epoch - 56ms/step\n",
      "Epoch 39/50\n",
      "100/100 - 6s - loss: 0.1873 - accuracy: 0.9484 - 6s/epoch - 56ms/step\n",
      "Epoch 40/50\n",
      "100/100 - 6s - loss: 0.1765 - accuracy: 0.9503 - 6s/epoch - 56ms/step\n",
      "Epoch 41/50\n",
      "100/100 - 6s - loss: 0.1860 - accuracy: 0.9422 - 6s/epoch - 56ms/step\n",
      "Epoch 42/50\n",
      "100/100 - 6s - loss: 0.1535 - accuracy: 0.9509 - 6s/epoch - 56ms/step\n",
      "Epoch 43/50\n",
      "100/100 - 6s - loss: 0.1444 - accuracy: 0.9584 - 6s/epoch - 56ms/step\n",
      "Epoch 44/50\n",
      "100/100 - 6s - loss: 0.1414 - accuracy: 0.9575 - 6s/epoch - 56ms/step\n",
      "Epoch 45/50\n",
      "100/100 - 6s - loss: 0.1374 - accuracy: 0.9575 - 6s/epoch - 56ms/step\n",
      "Epoch 46/50\n",
      "100/100 - 6s - loss: 0.1226 - accuracy: 0.9597 - 6s/epoch - 56ms/step\n",
      "Epoch 47/50\n",
      "100/100 - 6s - loss: 0.1396 - accuracy: 0.9572 - 6s/epoch - 56ms/step\n",
      "Epoch 48/50\n",
      "100/100 - 6s - loss: 0.1157 - accuracy: 0.9659 - 6s/epoch - 56ms/step\n",
      "Epoch 49/50\n",
      "100/100 - 6s - loss: 0.1214 - accuracy: 0.9634 - 6s/epoch - 56ms/step\n",
      "Epoch 50/50\n",
      "100/100 - 6s - loss: 0.1020 - accuracy: 0.9675 - 6s/epoch - 56ms/step\n",
      "   First_task training accuracy: 0.9675\n",
      "Epoch 1/10\n",
      "125/125 - 9s - loss: 0.9584 - accuracy: 0.8043 - 9s/epoch - 74ms/step\n",
      "Epoch 2/10\n",
      "125/125 - 7s - loss: 0.3727 - accuracy: 0.8860 - 7s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "125/125 - 7s - loss: 0.3012 - accuracy: 0.9035 - 7s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "125/125 - 7s - loss: 0.3138 - accuracy: 0.9068 - 7s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "125/125 - 7s - loss: 0.2573 - accuracy: 0.9202 - 7s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "125/125 - 7s - loss: 0.2432 - accuracy: 0.9277 - 7s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "125/125 - 7s - loss: 0.2380 - accuracy: 0.9285 - 7s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "125/125 - 7s - loss: 0.2104 - accuracy: 0.9377 - 7s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "125/125 - 7s - loss: 0.1952 - accuracy: 0.9402 - 7s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "125/125 - 7s - loss: 0.2032 - accuracy: 0.9402 - 7s/epoch - 56ms/step\n",
      "   1_task training accuracy: 0.9402\n",
      "Task 1 accuracy after training on Task ~0: 0.9225\n",
      "Epoch 1/10\n",
      "150/150 - 11s - loss: 0.8975 - accuracy: 0.8125 - 11s/epoch - 72ms/step\n",
      "Epoch 2/10\n",
      "150/150 - 9s - loss: 0.3963 - accuracy: 0.8815 - 9s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "150/150 - 8s - loss: 0.3280 - accuracy: 0.9029 - 8s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "150/150 - 8s - loss: 0.2936 - accuracy: 0.9121 - 8s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "150/150 - 8s - loss: 0.2752 - accuracy: 0.9208 - 8s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "150/150 - 8s - loss: 0.2492 - accuracy: 0.9287 - 8s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "150/150 - 8s - loss: 0.2211 - accuracy: 0.9375 - 8s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "150/150 - 8s - loss: 0.2163 - accuracy: 0.9348 - 8s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "150/150 - 8s - loss: 0.2213 - accuracy: 0.9358 - 8s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "150/150 - 8s - loss: 0.1910 - accuracy: 0.9433 - 8s/epoch - 56ms/step\n",
      "   2_task training accuracy: 0.9433\n",
      "Task 2 accuracy after training on Task ~1: 0.9220\n",
      "Epoch 1/10\n",
      "175/175 - 13s - loss: 0.8571 - accuracy: 0.8277 - 13s/epoch - 75ms/step\n",
      "Epoch 2/10\n",
      "175/175 - 10s - loss: 0.3761 - accuracy: 0.8995 - 10s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "175/175 - 10s - loss: 0.3189 - accuracy: 0.9098 - 10s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "175/175 - 10s - loss: 0.2598 - accuracy: 0.9282 - 10s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "175/175 - 10s - loss: 0.2408 - accuracy: 0.9309 - 10s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "175/175 - 10s - loss: 0.2264 - accuracy: 0.9375 - 10s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "175/175 - 10s - loss: 0.2109 - accuracy: 0.9425 - 10s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "175/175 - 10s - loss: 0.2041 - accuracy: 0.9445 - 10s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "175/175 - 10s - loss: 0.1979 - accuracy: 0.9418 - 10s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "175/175 - 10s - loss: 0.1610 - accuracy: 0.9532 - 10s/epoch - 56ms/step\n",
      "   3_task training accuracy: 0.9532\n",
      "Task 3 accuracy after training on Task ~2: 0.9258\n",
      "Epoch 1/10\n",
      "200/200 - 14s - loss: 0.8614 - accuracy: 0.8442 - 14s/epoch - 68ms/step\n",
      "Epoch 2/10\n",
      "200/200 - 11s - loss: 0.3476 - accuracy: 0.8991 - 11s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "200/200 - 11s - loss: 0.2818 - accuracy: 0.9223 - 11s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "200/200 - 11s - loss: 0.2127 - accuracy: 0.9386 - 11s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "200/200 - 11s - loss: 0.2247 - accuracy: 0.9350 - 11s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "200/200 - 11s - loss: 0.2246 - accuracy: 0.9378 - 11s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "200/200 - 11s - loss: 0.1639 - accuracy: 0.9519 - 11s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "200/200 - 11s - loss: 0.1747 - accuracy: 0.9491 - 11s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "200/200 - 11s - loss: 0.1751 - accuracy: 0.9520 - 11s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "200/200 - 11s - loss: 0.1563 - accuracy: 0.9588 - 11s/epoch - 56ms/step\n",
      "   4_task training accuracy: 0.9588\n",
      "Task 4 accuracy after training on Task ~3: 0.9321\n",
      "Epoch 1/10\n",
      "225/225 - 15s - loss: 0.7568 - accuracy: 0.8539 - 15s/epoch - 68ms/step\n",
      "Epoch 2/10\n",
      "225/225 - 13s - loss: 0.3353 - accuracy: 0.9110 - 13s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "225/225 - 13s - loss: 0.2623 - accuracy: 0.9244 - 13s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "225/225 - 13s - loss: 0.2141 - accuracy: 0.9397 - 13s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "225/225 - 13s - loss: 0.2083 - accuracy: 0.9425 - 13s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "225/225 - 13s - loss: 0.1865 - accuracy: 0.9483 - 13s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "225/225 - 13s - loss: 0.1897 - accuracy: 0.9471 - 13s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "225/225 - 13s - loss: 0.1602 - accuracy: 0.9544 - 13s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "225/225 - 13s - loss: 0.1655 - accuracy: 0.9525 - 13s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "225/225 - 13s - loss: 0.1475 - accuracy: 0.9592 - 13s/epoch - 56ms/step\n",
      "   5_task training accuracy: 0.9592\n",
      "Task 5 accuracy after training on Task ~4: 0.5894\n",
      "Epoch 1/10\n",
      "250/250 - 16s - loss: 0.9150 - accuracy: 0.8459 - 16s/epoch - 65ms/step\n",
      "Epoch 2/10\n",
      "250/250 - 14s - loss: 0.3265 - accuracy: 0.9119 - 14s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "250/250 - 14s - loss: 0.2445 - accuracy: 0.9349 - 14s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "250/250 - 14s - loss: 0.2168 - accuracy: 0.9391 - 14s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "250/250 - 14s - loss: 0.2049 - accuracy: 0.9440 - 14s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "250/250 - 14s - loss: 0.1791 - accuracy: 0.9484 - 14s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "250/250 - 14s - loss: 0.1725 - accuracy: 0.9517 - 14s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "250/250 - 14s - loss: 0.1520 - accuracy: 0.9595 - 14s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "250/250 - 14s - loss: 0.1628 - accuracy: 0.9534 - 14s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "250/250 - 14s - loss: 0.1665 - accuracy: 0.9540 - 14s/epoch - 56ms/step\n",
      "   6_task training accuracy: 0.9540\n",
      "Task 6 accuracy after training on Task ~5: 0.9222\n",
      "Epoch 1/10\n",
      "275/275 - 18s - loss: 0.9239 - accuracy: 0.8527 - 18s/epoch - 65ms/step\n",
      "Epoch 2/10\n",
      "275/275 - 15s - loss: 0.3968 - accuracy: 0.8906 - 15s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "275/275 - 16s - loss: 0.3237 - accuracy: 0.9093 - 16s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "275/275 - 16s - loss: 0.2463 - accuracy: 0.9281 - 16s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "275/275 - 16s - loss: 0.2319 - accuracy: 0.9339 - 16s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "275/275 - 16s - loss: 0.2144 - accuracy: 0.9406 - 16s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "275/275 - 16s - loss: 0.1958 - accuracy: 0.9469 - 16s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "275/275 - 16s - loss: 0.1740 - accuracy: 0.9533 - 16s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "275/275 - 16s - loss: 0.1583 - accuracy: 0.9568 - 16s/epoch - 58ms/step\n",
      "Epoch 10/10\n",
      "275/275 - 16s - loss: 0.1555 - accuracy: 0.9575 - 16s/epoch - 58ms/step\n",
      "   7_task training accuracy: 0.9575\n",
      "Task 7 accuracy after training on Task ~6: 0.9330\n",
      "Epoch 1/10\n",
      "300/300 - 19s - loss: 0.9534 - accuracy: 0.8520 - 19s/epoch - 65ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 17s - loss: 0.4348 - accuracy: 0.8763 - 17s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "300/300 - 17s - loss: 0.3299 - accuracy: 0.9074 - 17s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "300/300 - 17s - loss: 0.2611 - accuracy: 0.9280 - 17s/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "300/300 - 17s - loss: 0.2332 - accuracy: 0.9388 - 17s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "300/300 - 17s - loss: 0.2021 - accuracy: 0.9474 - 17s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "300/300 - 17s - loss: 0.2009 - accuracy: 0.9479 - 17s/epoch - 57ms/step\n",
      "Epoch 8/10\n",
      "300/300 - 21s - loss: 0.1934 - accuracy: 0.9497 - 21s/epoch - 72ms/step\n",
      "Epoch 9/10\n",
      "300/300 - 22s - loss: 0.1649 - accuracy: 0.9536 - 22s/epoch - 72ms/step\n",
      "Epoch 10/10\n",
      "300/300 - 17s - loss: 0.1655 - accuracy: 0.9549 - 17s/epoch - 58ms/step\n",
      "   8_task training accuracy: 0.9549\n",
      "Task 8 accuracy after training on Task ~7: 0.9400\n",
      "Epoch 1/10\n",
      "325/325 - 22s - loss: 1.1267 - accuracy: 0.8435 - 22s/epoch - 67ms/step\n",
      "Epoch 2/10\n",
      "325/325 - 19s - loss: 0.4580 - accuracy: 0.8770 - 19s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "325/325 - 19s - loss: 0.3905 - accuracy: 0.8912 - 19s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "325/325 - 19s - loss: 0.3182 - accuracy: 0.9112 - 19s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "325/325 - 19s - loss: 0.3025 - accuracy: 0.9127 - 19s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "325/325 - 19s - loss: 0.2598 - accuracy: 0.9287 - 19s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "325/325 - 19s - loss: 0.2366 - accuracy: 0.9356 - 19s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "325/325 - 19s - loss: 0.2129 - accuracy: 0.9412 - 19s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "325/325 - 19s - loss: 0.1779 - accuracy: 0.9504 - 19s/epoch - 58ms/step\n",
      "Epoch 10/10\n",
      "325/325 - 19s - loss: 0.1904 - accuracy: 0.9504 - 19s/epoch - 58ms/step\n",
      "   9_task training accuracy: 0.9504\n",
      "Task 9 accuracy after training on Task ~8: 0.9317\n",
      "Epoch 1/10\n",
      "350/350 - 23s - loss: 1.0078 - accuracy: 0.8554 - 23s/epoch - 66ms/step\n",
      "Epoch 2/10\n",
      "350/350 - 20s - loss: 0.4807 - accuracy: 0.8763 - 20s/epoch - 58ms/step\n",
      "Epoch 3/10\n",
      "350/350 - 20s - loss: 0.3949 - accuracy: 0.8938 - 20s/epoch - 58ms/step\n",
      "Epoch 4/10\n",
      "350/350 - 20s - loss: 0.3358 - accuracy: 0.9086 - 20s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "350/350 - 20s - loss: 0.2966 - accuracy: 0.9211 - 20s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "350/350 - 20s - loss: 0.2689 - accuracy: 0.9274 - 20s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "350/350 - 20s - loss: 0.2424 - accuracy: 0.9364 - 20s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "350/350 - 20s - loss: 0.2181 - accuracy: 0.9442 - 20s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "350/350 - 20s - loss: 0.2083 - accuracy: 0.9470 - 20s/epoch - 58ms/step\n",
      "Epoch 10/10\n",
      "350/350 - 20s - loss: 0.1951 - accuracy: 0.9496 - 20s/epoch - 58ms/step\n",
      "   10_task training accuracy: 0.9496\n",
      "Task 10 accuracy after training on Task ~9: 0.9431\n",
      "Epoch 1/10\n",
      "375/375 - 25s - loss: 1.0144 - accuracy: 0.8586 - 25s/epoch - 66ms/step\n",
      "Epoch 2/10\n",
      "375/375 - 22s - loss: 0.5682 - accuracy: 0.8770 - 22s/epoch - 58ms/step\n",
      "Epoch 3/10\n",
      "375/375 - 22s - loss: 0.4286 - accuracy: 0.8921 - 22s/epoch - 59ms/step\n",
      "Epoch 4/10\n",
      "375/375 - 22s - loss: 0.3521 - accuracy: 0.9046 - 22s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "375/375 - 22s - loss: 0.3391 - accuracy: 0.9073 - 22s/epoch - 57ms/step\n",
      "Epoch 6/10\n",
      "375/375 - 22s - loss: 0.2969 - accuracy: 0.9226 - 22s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "375/375 - 22s - loss: 0.2850 - accuracy: 0.9273 - 22s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "375/375 - 22s - loss: 0.2445 - accuracy: 0.9398 - 22s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "375/375 - 22s - loss: 0.2242 - accuracy: 0.9417 - 22s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "375/375 - 22s - loss: 0.2195 - accuracy: 0.9431 - 22s/epoch - 57ms/step\n",
      "   11_task training accuracy: 0.9431\n",
      "Task 11 accuracy after training on Task ~10: 0.9386\n",
      "Epoch 1/10\n",
      "400/400 - 26s - loss: 1.1704 - accuracy: 0.8512 - 26s/epoch - 65ms/step\n",
      "Epoch 2/10\n",
      "400/400 - 23s - loss: 0.5958 - accuracy: 0.8792 - 23s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "400/400 - 23s - loss: 0.4462 - accuracy: 0.8887 - 23s/epoch - 58ms/step\n",
      "Epoch 4/10\n",
      "400/400 - 23s - loss: 0.3872 - accuracy: 0.8985 - 23s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "400/400 - 23s - loss: 0.3378 - accuracy: 0.9105 - 23s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "400/400 - 23s - loss: 0.3364 - accuracy: 0.9131 - 23s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "400/400 - 23s - loss: 0.2988 - accuracy: 0.9208 - 23s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "400/400 - 23s - loss: 0.2806 - accuracy: 0.9284 - 23s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "400/400 - 23s - loss: 0.2593 - accuracy: 0.9339 - 23s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "400/400 - 23s - loss: 0.2281 - accuracy: 0.9427 - 23s/epoch - 58ms/step\n",
      "   12_task training accuracy: 0.9427\n",
      "Task 12 accuracy after training on Task ~11: 0.8207\n",
      "Epoch 1/10\n",
      "425/425 - 27s - loss: 1.1532 - accuracy: 0.8543 - 27s/epoch - 64ms/step\n",
      "Epoch 2/10\n",
      "425/425 - 24s - loss: 0.6049 - accuracy: 0.8735 - 24s/epoch - 57ms/step\n",
      "Epoch 3/10\n",
      "425/425 - 24s - loss: 0.4570 - accuracy: 0.8892 - 24s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "425/425 - 25s - loss: 0.4055 - accuracy: 0.8943 - 25s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "425/425 - 25s - loss: 0.3737 - accuracy: 0.9043 - 25s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "425/425 - 25s - loss: 0.3493 - accuracy: 0.9089 - 25s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "425/425 - 25s - loss: 0.3398 - accuracy: 0.9108 - 25s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "425/425 - 25s - loss: 0.3114 - accuracy: 0.9204 - 25s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "425/425 - 25s - loss: 0.2992 - accuracy: 0.9238 - 25s/epoch - 58ms/step\n",
      "Epoch 10/10\n",
      "425/425 - 25s - loss: 0.3043 - accuracy: 0.9258 - 25s/epoch - 58ms/step\n",
      "   13_task training accuracy: 0.9258\n",
      "Task 13 accuracy after training on Task ~12: 0.9250\n",
      "Epoch 1/10\n",
      "450/450 - 29s - loss: 1.2445 - accuracy: 0.8420 - 29s/epoch - 64ms/step\n",
      "Epoch 2/10\n",
      "450/450 - 26s - loss: 0.6432 - accuracy: 0.8674 - 26s/epoch - 58ms/step\n",
      "Epoch 3/10\n",
      "450/450 - 26s - loss: 0.4876 - accuracy: 0.8804 - 26s/epoch - 57ms/step\n",
      "Epoch 4/10\n",
      "450/450 - 26s - loss: 0.4529 - accuracy: 0.8886 - 26s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "450/450 - 26s - loss: 0.4016 - accuracy: 0.8988 - 26s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "450/450 - 26s - loss: 0.3753 - accuracy: 0.9044 - 26s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "450/450 - 26s - loss: 0.3678 - accuracy: 0.9105 - 26s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "450/450 - 26s - loss: 0.3241 - accuracy: 0.9222 - 26s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "450/450 - 26s - loss: 0.2983 - accuracy: 0.9277 - 26s/epoch - 58ms/step\n",
      "Epoch 10/10\n",
      "450/450 - 26s - loss: 0.2918 - accuracy: 0.9319 - 26s/epoch - 58ms/step\n",
      "   14_task training accuracy: 0.9319\n",
      "Task 14 accuracy after training on Task ~13: 0.9297\n",
      "Epoch 1/10\n",
      "475/475 - 30s - loss: 1.1821 - accuracy: 0.8551 - 30s/epoch - 64ms/step\n",
      "Epoch 2/10\n",
      "475/475 - 28s - loss: 0.7793 - accuracy: 0.8761 - 28s/epoch - 58ms/step\n",
      "Epoch 3/10\n",
      "475/475 - 27s - loss: 0.5537 - accuracy: 0.8857 - 27s/epoch - 58ms/step\n",
      "Epoch 4/10\n",
      "475/475 - 28s - loss: 0.4636 - accuracy: 0.8889 - 28s/epoch - 58ms/step\n",
      "Epoch 5/10\n",
      "475/475 - 28s - loss: 0.4022 - accuracy: 0.8977 - 28s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "475/475 - 28s - loss: 0.3744 - accuracy: 0.9035 - 28s/epoch - 58ms/step\n",
      "Epoch 7/10\n",
      "475/475 - 27s - loss: 0.3379 - accuracy: 0.9119 - 27s/epoch - 58ms/step\n",
      "Epoch 8/10\n",
      "475/475 - 27s - loss: 0.3427 - accuracy: 0.9132 - 27s/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "475/475 - 27s - loss: 0.2995 - accuracy: 0.9222 - 27s/epoch - 58ms/step\n",
      "Epoch 10/10\n",
      "475/475 - 28s - loss: 0.2930 - accuracy: 0.9237 - 28s/epoch - 58ms/step\n",
      "   15_task training accuracy: 0.9237\n",
      "Task 15 accuracy after training on Task ~14: 0.9378\n"
     ]
    }
   ],
   "source": [
    "# Joint\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "# 모델 빌드 \n",
    "model = DFNet.build(input_shape=(10000, 1), classes=MAX_LABEL)\n",
    "# 옵티마이저 설정 \n",
    "OPTIMIZER = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "train_loop_joint(model, OPTIMIZER, data, test_size=0.2, first_task = 19, inc_task = 5, first_epochs = 50, inc_epochs = 10, lamb=0, num_sample=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nAIvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
