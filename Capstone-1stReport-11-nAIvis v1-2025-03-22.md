<!-- Template for PROJECT REPORT of CapstoneDesign 2025-2H, initially written by khyoo -->
<!-- 본 파일은 2025년도 컴공 졸업프로젝트의 <1차보고서> 작성을 위한 기본 양식입니다. -->
<!-- 아래에 "*"..."*" 표시는 italic체로 출력하기 위해서 사용한 것입니다. -->
<!-- "내용"에 해당하는 부분을 지우고, 여러분 과제의 내용을 작성해 주세요. -->

# Team-Info
| (1) 과제명 | *본인 팀에서 수행중인 프로젝트의 이름을 작성합니다*
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | *11-nAIvis* |
| (3) 팀 구성원 | 배주원 (2271031): 리더, *맡은 역할* <br><br> 이서연 (2276217): 팀원, *맡은 역할* <br><br> 신유진 (2271034) : 팀원, *맡은 역할*		<br><br>	 |
| (4) 팀 지도교수 | 오세은 교수님 |
| (5) 과제 분류 | *연구 과제* |
| (6) 과제 키워드 | *Deep Fingerprinting, Continual Learning, Network Security*  |
| (7) 과제 내용 요약 | *웹사이트 핑거프린팅(Website Fingerprinting, WF) 공격은 Tor 네트워크 사용자에 대한 패킷 메타데이터 분석을 통해 사용자가 방문한 웹사이트를 식별하는 대표적인 비인가 트래픽 분석 기법으로, 사용자 프라이버시를 심각하게 위협한다. 특히, 최근에는 Convolutional Neural Network(CNN)를 기반으로 하는 딥러닝 기반 공격 기법인 Deep Fingerprinting(DF)이 등장하면서 WF 공격의 정확도가 크게 향상되었다. Sirinam 등의 기존 연구에 따르면, ResNet 기반 DF 모델은 Closed-world 환경에서 98% 이상의 높은 분류 정확도를 달성하였다.

그러나 기존 DF 모델은 정적인 데이터셋을 기반으로 단일 시점에 학습되기 때문에, 실제 환경에서 시간이 지남에 따라 변화하는 트래픽 패턴이나 Tor 네트워크 업데이트에 적응하지 못하고 성능이 급격히 저하되는 Catastrophic Forgetting 문제를 겪는다. 이러한 한계는 실시간 대응이 요구되는 보안 분야에서 DF 모델의 활용 가능성을 제약하며, 실사용 환경에 적합한 지속 학습 기반의 WF 공격 모델이 요구된다.

본 과제에서는 이러한 문제를 해결하고자, Continual Learning(CL) 기법 중 하나인 Elastic Weight Consolidation(EWC)을 기존 DF 모델에 적용하였다. EWC는 모델이 이전 Task에서 중요하게 학습한 가중치를 보호하면서 새로운 Task를 학습할 수 있도록 손실 함수에 정규화 항을 추가하는 방식으로 Catastrophic Forgetting을 완화한다. 제안된 EWC 기반 DF 모델은 시간에 따라 수집되는 트래픽 데이터를 순차적으로 학습하면서도, 기존에 학습된 정보의 손실을 최소화하여 고정된 학습 없이도 성능을 유지할 수 있다.

실험은 Closed-world와 Open-world 환경 모두에서 수행되었으며, Task별 정확도, 평균 정확도(Average Accuracy), Catastrophic Forgetting(F) 지표, 최종 정확도(Final Accuracy) 등을 기준으로 성능을 비교하였다. 실험 결과, EWC를 적용한 모델은 기존 DF 모델에 비해 시간이 경과해도 성능 하락이 적고, 새로운 환경에서도 보다 안정적으로 작동함을 확인하였다.

본 연구는 Continual Learning의 대표적인 정규화 기반 방법인 EWC를 웹 트래픽 기반 보안 공격 모델에 적용함으로써, DF 모델의 실환경 적응성과 지속 가능성을 실험적으로 검증하였다는 점에서 의의가 크다. 더 나아가, 본 과제는 CL 기법이 보안 도메인에서 실질적으로 활용될 수 있음을 보여주는 사례로서, Tor 사용자 익명성 보호와 관련된 다양한 후속 연구에 실질적인 기초자료를 제공할 수 있다.* |

<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
| (1) 문제 정의 | *웹사이트 핑거프린팅(Website Fingerprinting, WF)은 암호화된 통신 환경에서도 트래픽의 패턴을 분석하여 사용자가 방문한 웹사이트를 식별하는 대표적인 트래픽 분석(traffic analysis) 공격 기법이다. 특히 Tor 네트워크는 사용자의 IP 주소를 숨기기 위해 트래픽을 여러 노드를 거쳐 암호화된 경로로 전송하지만, 이러한 암호화는 트래픽의 콘텐츠만 보호할 뿐, 패킷의 방향, 크기, 시퀀스, 전송 간격과 같은 메타데이터는 그대로 노출된다. 이로 인해 Tor 사용자조차도 WF 공격에 노출될 수 있으며, 실제로 다양한 연구에서 WF 공격이 높은 정확도로 작동함이 입증되었다.

기존의 WF 공격 모델 중 특히 Deep Fingerprinting(DF)은 CNN 기반의 딥러닝 모델을 활용하여 Tor 트래픽의 패턴을 자동으로 학습하고 분류 정확도를 획기적으로 향상시킨 대표적인 사례이다. Sirinam 등은 ResNet 기반 DF 모델을 통해 Closed-world 설정에서 98% 이상의 정확도를 기록하였으며, 일부 Open-world 환경에서도 높은 정밀도(precision)와 재현율(recall)을 보였다. 이처럼 DF는 기존 SVM, k-NN 등 전통적인 머신러닝 기반 WF 기법에 비해 훨씬 정교하고 실용적인 위협이 되고 있다.

그러나 기존 DF 모델은 단일 시점의 정적인 데이터셋을 기반으로 학습되어, 현실 세계의 변화하는 환경에는 잘 대응하지 못하는 구조적인 한계를 지닌다. 실제 Tor 트래픽은 시간의 흐름에 따라 웹사이트의 콘텐츠 변화, 네트워크 환경 변화, 브라우저 업데이트, Tor 프로토콜 자체의 수정 등 다양한 요인에 의해 지속적으로 변한다. 이때 DF 모델은 과거에 학습한 데이터에 기반하여 추론을 수행하기 때문에 새로운 유형의 트래픽을 처리할 수 없거나, 새로운 데이터를 추가 학습하는 과정에서 기존 지식이 소실되는 Catastrophic Forgetting 문제에 직면하게 된다.

이러한 문제는 특히 실제 공격 환경이나 장기적인 보안 연구 활용을 위한 지속 학습이 필요한 경우 큰 제약으로 작용한다. 예를 들어 보안 연구자가 장기간에 걸쳐 Tor 네트워크의 트래픽을 모니터링하며 WF 연구를 수행하거나, 자동화된 공격 시스템이 실시간으로 새로운 트래픽에 대응하고자 할 때, 기존 방식은 매 Task마다 전체 데이터셋을 다시 학습해야 하는 비효율성을 초래한다. 또한, 전체 데이터셋을 항상 유지해야 한다는 점에서 저장공간, 계산 자원 측면에서도 부담이 크며, 일부 데이터의 보안 또는 프라이버시 문제가 있을 수 있다.

따라서 본 프로젝트에서는 이러한 구조적인 한계를 해결하기 위해, Continual Learning 기법 중 하나인 Elastic Weight Consolidation(EWC)을 기존 DF 모델에 통합하여, 변화하는 환경 속에서도 과거 학습 내용을 유지하면서 새로운 정보에 적응할 수 있는 지속 학습 기반 DF 모델을 개발하고자 한다. EWC는 각 파라미터의 중요도를 고려하여 중요한 가중치가 새 학습 데이터에 의해 과도하게 변경되지 않도록 제한함으로써, 기존 정보의 손실을 최소화하는 방식이다.

본 프로젝트는 Tor 환경의 실시간 트래픽 변화에 유연하게 대응하면서도 기존 지식의 보존이 가능한 공격 모델을 구축함으로써, 현실 적용 가능성이 높은 WF 공격 시스템의 프로토타입을 구현하는 것을 목표로 한다. 최종적으로는 보안 연구자들이 실시간/장기 분석 환경에서도 지속적으로 활용 가능한 프레임워크를 제공하고, Tor 사용자 프라이버시 보호에 대한 취약점 연구를 더욱 정밀하고 장기적으로 수행할 수 있는 기반을 마련하는 데에 기여하고자 한다.

Target User는 다음과 같다:

보안 연구자: Tor 네트워크 보안성과 WF 대응 전략을 연구하는 학계 및 산업계 보안 전문가

Tor 사용자 및 개발자: 프라이버시 보호에 관심이 있는 일반 사용자 및 Tor 네트워크 개선을 위한 기술적 인사이트가 필요한 개발자/기여자

보안 정책 입안자: 보안 위협 트렌드 분석 및 익명성 기술의 정책적 적용 가능성을 모색하는 관련 기관 및 정책 연구자

기타: Continual Learning(EWC)를 통해 기존에 학습한 내용은 잊지 않고 유지하되 변경된 새로운 데이터에 대한 학습도 원활히히 이루어졌으면 하는 모든 사용자*  |
| (2) 기존연구와의 비교 | *웹사이트 핑거프린팅(Website Fingerprinting, WF) 공격 기법은 오랜 시간 동안 다양한 연구를 통해 고도화되어 왔다. 초기에는 Support Vector Machine(SVM), k-Nearest Neighbors(k-NN), Random Forest와 같은 전통적인 머신러닝 알고리즘을 활용하여 트래픽에서 추출한 수작업 기반 특성(features)을 이용해 웹사이트를 분류하였다. 그러나 이러한 접근 방식은 복잡한 특징 설계 과정과 일반화 성능의 한계로 인해 실제 Tor 네트워크의 변화무쌍한 트래픽 환경에서는 적용에 어려움이 있었다.

1. 기존 Deep Fingerprinting 기반 연구
이후 딥러닝 기술의 발전과 함께 Convolutional Neural Network(CNN), Recurrent Neural Network(RNN) 등 다양한 구조를 적용한 Deep Fingerprinting(DF) 계열의 연구가 등장하였고, 웹사이트 핑거프린팅의 정확도는 획기적으로 향상되었다. 특히 Sirinam et al.의 연구는 ResNet 구조를 기반으로 하여, Closed-world 설정에서 무려 96~98%의 정확도를 달성하며 큰 주목을 받았다. 이 모델은 패킷의 방향 시퀀스를 단순한 입력 형식으로 처리하면서도, 복잡한 트래픽 패턴을 학습할 수 있는 구조를 제안하여 기존 머신러닝 기반 접근법을 능가하는 성능을 보였다.

그러나 이들 연구의 대부분은 정적인 데이터셋을 기반으로 단일 시점에 전체 데이터를 학습하는 offline 학습 방식을 따르고 있다. 즉, 모델 학습이 완료된 이후에는 새로운 데이터를 반영하거나 환경 변화에 적응할 수 있는 메커니즘이 없으며, 시간이 지남에 따라 트래픽 패턴이나 Tor 프로토콜, 웹사이트 구성의 변화가 발생하면 성능이 급격히 저하되는 문제가 발생한다. 이처럼 기존 DF 모델은 현실에서 발생할 수 있는 도메인 변화(domain shift), 시간에 따른 트래픽 변화, 새로운 웹사이트 등장과 같은 실환경 요인에 매우 취약하다.

2. 기존 대응 시도: Fine-tuning, Transfer Learning
일부 연구에서는 이러한 문제를 완화하기 위해 Fine-tuning이나 Transfer Learning 기법을 활용하였다. 예를 들어, 이전에 학습한 모델의 일부 계층을 고정한 뒤, 새로운 데이터에 대해 특정 계층만 재학습하거나(Partial Fine-tuning), 새 도메인에 대한 전이 학습을 수행하는 방식이다. 이러한 방법은 기존 모델을 재사용할 수 있다는 장점이 있지만, 다음과 같은 실질적 한계가 존재한다:

전체 모델 또는 일부 계층을 반복적으로 재학습해야 하므로 학습 시간이 많이 소요된다.

새로운 데이터에 대한 레이블링 비용이 높다.

대부분 모든 이전 데이터에 대한 접근이 필요하거나, 일부 데이터라도 저장해두어야 하므로 프라이버시 및 저장 비용 부담이 발생한다.

Task가 순차적으로 도착하는 환경에서는 지속적인 재학습이 비효율적이며 실시간 시스템에는 부적합하다.

본 과제의 차별점: Continual Learning 기반 DF 모델
이러한 기존 연구들의 한계를 극복하기 위해, 본 프로젝트에서는 Continual Learning(CL) 기법 중 하나인 Elastic Weight Consolidation(EWC)을 적용하여 지속 학습 기반 DF 모델을 제안하였다. CL은 데이터를 순차적으로 학습하면서도 이전 Task에 대한 지식을 보존하는 능력을 갖춘 학습 패러다임으로, 딥러닝 모델이 실시간으로 환경 변화에 적응할 수 있도록 해준다.

EWC는 모델이 학습한 각 파라미터의 중요도(Fisher Information)를 정량적으로 계산하여, 중요한 파라미터가 새로운 Task에 의해 지나치게 변화하지 않도록 손실 함수에 규제 항을 추가하는 방식으로 Catastrophic Forgetting을 방지한다. 이 방식은 단일 모델 내에서 효율적으로 과거 정보를 유지하면서도 새로운 정보를 빠르게 수용할 수 있도록 한다.

결과적으로, 본 과제는 기존 DF 연구들이 제공하지 못했던 시간 기반 트래픽 변화 적응성, Catastrophic Forgetting 방지력, 재학습 없는 연속 학습 능력, 학습 시간 및 자원 절감, 그리고 무엇보다도 보안 응용 영역에서의 Continual Learning 실증이라는 측면에서 분명한 차별성과 장점을 가진다. 이는 향후 Tor 네트워크 보안 연구나 실시간 트래픽 분석 시스템 개발에도 중요한 기여를 할 수 있다.* |
| (3) 제안 내용 | *본 프로젝트는 변화하는 Tor 트래픽 환경에서도 안정적인 웹사이트 분류 성능을 유지할 수 있는 지속 학습 기반 Deep Fingerprinting(DF) 모델을 제안한다. 기존의 정적 학습 기반 DF 모델은 새로운 환경에 적응하지 못하고 성능이 저하되는 한계가 있었으며, 이를 해결하기 위해 본 과제는 Continual Learning(C.L.) 기법 중 Elastic Weight Consolidation(EWC)을 통합한 프레임워크를 구성하였다.

핵심 제안: EWC 기반 Continual Learning 프레임워크
EWC는 딥러닝 모델이 새로운 Task를 학습할 때 이전 Task의 파라미터를 유지하는 것을 돕는 정규화 기반 학습 전략이다. 이 기법은 다음과 같은 방식으로 작동한다:

이전 Task에서 학습한 각 파라미터의 중요도(Fisher Information)를 계산

중요한 파라미터의 값이 이후 학습에서 과도하게 변경되는 것을 방지하기 위해, 손실 함수에 규제 항(regularization term)을 추가

이를 통해 새로운 데이터에 적응하면서도 Catastrophic Forgetting 현상을 최소화

EWC 손실 함수는 다음과 같이 정의된다: L_total = L_task + λ∑(F_i * (θ_i - θ*_i)^2)
여기서 λ는 정규화 항의 가중치를 조절하는 하이퍼파라미터이며,
θ*_i는 이전 Task의 최적 파라미터, F_i는 해당 파라미터의 중요도이다.

시스템 구성 및 구조
본 프레임워크는 다음과 같은 주요 모듈들로 구성된다:

1D-CNN 기반 Deep Fingerprinting 기본 모델

입력: Tor 트래픽으로부터 수집된 패킷 방향 시퀀스 (e.g., +1/-1 형태)

출력: 웹사이트 클래스 분류 결과 (Softmax)

Task 분할 전략

시간 기반 (예: 주별/월별 트래픽), 또는 Tor 버전 기반으로 트래픽 데이터를 분할하여 학습 Task 시퀀스를 구성함

EWC 적용 학습 모듈

각 Task 종료 후 Fisher Information Matrix 계산

다음 Task 학습 시 손실 함수에 규제 항 추가

실험 시나리오 설계

Closed-world: 고정된 사이트 집합 내에서 Task 전이

Open-world: 이전 Task에 없던 새로운 사이트가 등장하는 시나리오

지표 기반 성능 평가 체계

Task별 정확도, 평균 정확도, Forgetting 지표(F), 최종 정확도 등 다양한 관점에서 모델 성능 비교

추가적인 고도화 요소 (추진 중 or 계획 포함)
λ 하이퍼파라미터 튜닝: EWC의 성능은 λ 값에 민감하므로, 실험을 통해 다양한 값에 대한 성능 변화를 측정하고 최적값을 탐색

마스킹 기법 도입 예정: 중요하지 않은 파라미터를 동적으로 마스킹하여 EWC의 성능을 추가 개선하는 기법을 탐색 중

모듈화된 Task 자동화 및 실험 제어 시스템: 각 Task 단위 실험을 자동 실행하고 결과를 정형화된 로그로 저장하는 시스템을 구축

본 제안의 핵심 장점
기존 DF 모델 대비 Catastrophic Forgetting 방지 능력이 우수함

지속적인 트래픽 환경 변화에 대한 실시간 적응 가능성

전체 재학습이 필요 없는 학습 효율성과 자원 절감 효과

보안 응용 분야에서 Continual Learning 기법의 실제 효과를 검증

확장 가능성 있는 구조로, 다양한 CL 기법이나 방어 기법과도 통합 가능

결론적으로, 본 프로젝트는 기존의 정적 DF 연구를 지속 학습 기반으로 확장함으로써, Tor 네트워크 트래픽과 같은 비정형적이고 비정상적(distribution shift) 환경에 적응 가능한 모델을 제시한다. 이는 WF 공격의 실환경 적용 가능성을 높이고, 보안 도메인에서의 Continual Learning 응용 가능성을 실증한다는 점에서 의의가 있다.
* |
| (4) 기대효과 및 의의 | *1. 보안 도메인에서의 Continual Learning 기술 실증
기존에는 이미지 분류, 자연어 처리 등 특정 분야에 집중되었던 Continual Learning(C.L.) 기법을 보안 공격 모델에 처음으로 적용하고 성능을 실험적으로 검증하였다. 이는 C.L. 기법의 적용 범위를 확장하고, 향후 보안 분야에서 새로운 알고리즘 연구를 촉진할 수 있다.

2. 실시간 적응형 WF 공격 모델 실현 가능성 제시
EWC 기반 모델은 변화하는 트래픽 패턴이나 환경 조건(웹사이트 구조, 브라우저/OS 업데이트 등)에도 적응할 수 있으므로, 보다 실제적인 WF 공격 시나리오를 반영할 수 있다. 이는 Tor 사용자에 대한 위협을 더 정확히 예측하고, 방어 기법 설계에도 실질적인 인사이트를 제공할 수 있다.

3. 재학습 부담 감소 및 자원 절약
전체 데이터를 재학습할 필요 없이 순차적으로 주어지는 Task만 학습하면 되므로, 학습 시간과 자원 사용량이 대폭 줄어든다. 이는 실제 시스템에서 운영 비용을 절감하고, Edge Device 기반 보안 분석 시스템에도 적용 가능성을 넓힌다.

4. 학술적 기여 및 기술적 활용도 향상
실험 결과 및 구조는 보안 학회 논문(KCC 등) 제출을 통해 학술적으로 기여할 수 있다.

제안한 프레임워크는 향후 웹사이트 방어 기법 평가, 보안 정책 수립, 또는 WF 공격 자동화 시스템의 기반 모듈로 활용될 수 있다.

트래픽 시각화 및 모델 성능 로그 자동화는 보안 데이터셋 구축 및 AI 기반 보안 연구에도 활용 가능하다.* |
| (5) 주요 기능 리스트 | *1. Deep Fingerprinting 기본 모델 (1D-CNN)
기존 Sirinam DF 모델 구조를 참고하여, 1D-CNN 기반 모델을 구현

입력된 패킷 시퀀스를 웹사이트 클래스로 분류하는 softmax 기반 출력 구조 설계

2. Task 분할 및 자동화 학습 스크립트
시간순 또는 Tor 버전 기반으로 데이터셋을 여러 Task로 분할

각 Task 학습 및 평가를 자동으로 실행하며, 학습 결과를 로그로 저장하는 스크립트 구축

3. Elastic Weight Consolidation(EWC) 통합 모듈
각 Task 학습 후, 파라미터별 Fisher Information을 계산

다음 Task 학습 시 기존 중요 파라미터를 보호하는 손실 함수 규제 항 추가

수식 구현: L_total = L_task + λ∑(F_i * (θ_i - θ*_i)^2)

4. 마스킹 기반 정규화 개선 (실험 중)
중요도가 낮은 파라미터에 대해 마스킹을 적용하여 EWC 정규화의 효율성을 높이는 기법 실험 예정

불필요한 규제 항을 줄여 CL 성능의 균형(stability-plasticity trade-off) 최적화 기대

5. 성능 분석 및 시각화 도구
Task별 Accuracy, Average Accuracy, Forgetting Measure(F), Final Accuracy 등 다양한 평가 지표 제공

matplotlib 기반 시각화 모듈로 결과 그래프 및 비교 차트 자동 생성
*|
<br>
 
# Project-Design & Implementation
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 | *
① 사용자 요구사항
- 변화하는 트래픽 환경(Tor 버전, 시간 흐름 등)에서도 높은 정확도 유지
- 모델을 반복적으로 재학습하지 않아도 지속적으로 학습된 지식을 유지

② 기능 요구사항
- Tor 트래픽 수집 및 전처리 자동화 기능
- Deep Fingerprinting 기본 모델 구현 기능
- EWC 기반 Continual Learning 학습 기능
- Closed-world 및 Open-world 실험 시나리오 구성 및 실행 기능
- 성능 지표 출력 및 시각화 기능

③ 성능 요구사항
- 평균 정확도 90% 이상 유지
- Forgetting 지표 F 최소화 (기존 모델 대비 향상된 안정성 확보)
- 학습 시간 및 GPU 사용량 최소화

④ 유스케이스
- "Tor 환경의 지속적인 변화에 노출된 상황에서, 사용자 또는 연구자는 기존 모델을 반복적으로 재학습하지 않고도 기존 분류 정확도를 유지하며 새로운 데이터를 학습할 수 있어야 한다."

* |
| (2) 전체 시스템 구성 | *
 데이터 수집 및 전처리 모듈
- Tor 브라우저와 Selenium을 활용한 웹사이트 자동 접속
- Wireshark로 패킷 캡처 후, Python 스크립트를 통해 패킷 방향 시퀀스로 전처리

② ① DF 모델 학습 모듈
- 1D-CNN 기반 구조의 DF 모델 구현
- 입력: 패킷 방향 시퀀스 (+1/-1)
- 출력: 웹사이트 클래스 분류 (Softmax)

② EWC 통합 학습 모듈
- Task 간 전환 시 Fisher Information 계산
- 손실 함수에 정규화 항 추가하여 기존 파라미터 보호

③ 실험 제어/자동화 모듈
- Closed-world 및 Open-world 실험 시나리오 구성 및 실행
- 각 Task 학습 및 평가를 자동화

④ 성능 분석 및 시각화 모듈
- Accuracy, Average Accuracy, Forgetting(F), Final Accuracy 지표 계산
- matplotlib 기반 시각화 (Task 간 성능 추이 등)

⑤ 외부 활용 모듈
- PyTorch: 딥러닝 모델 구축 및 학습
- Pandas/NumPy: 데이터 처리
* |
| (3) 주요엔진 및 기능 설계 | *
① DF 모델 모듈
- 1D-CNN 아키텍처 설계: Conv1D → ReLU → MaxPooling → Dropout → Fully Connected Layer → Softmax
- 학습 대상: 패킷 방향 시퀀스 (정규화된 길이의 배열)

② EWC 통합 모듈
- 기존 Task 학습 완료 후 파라미터의 Fisher Information Matrix(FIM) 계산
- 다음 Task 학습 시, 손실 함수에 EWC 정규화 항 추가
- 수식: L_total = L_task + λ∑(F_i * (θ_i - θ*_i)^2)
- 향후 개선 방향: 중요도가 낮은 파라미터에 마스킹 기법 적용 예정

③ 실험 시나리오 모듈
- Task 단위 학습 흐름 정의 (Closed-world: 동일 사이트 Task 분할 / Open-world: 새로운 사이트 등장)
- 각 Task별 학습 및 평가 자동 실행, 결과 로그 기록
* |
| (4) 주요 기능의 구현 | *
① EWC 적용 학습 파이프라인 구현
- 기존 모델의 학습 종료 후 각 파라미터에 대해 FIM 계산
- 새 Task 학습 시 기존 가중치와의 차이를 페널티로 반영하여 성능 하락 방지
- λ 값 실험을 통한 최적값 탐색

② 실험 자동화 및 제어 스크립트
- Python 기반 스크립트로 Task별 학습/평가 루프 구성
- 학습 시점마다 모델 저장, 평가 지표 기록, 성능 로그 자동 출력
- 실험 시나리오(Closed-world vs Open-world)를 config 파일로 설정 가능

③ 성능 분석 도구
- Accuracy, Average Accuracy, Forgetting 지표 계산
- matplotlib 기반 시각화: Task별 성능 변화 그래프, 비교 막대 그래프 출력
* |
| (5) 기타 | *
- 본 프로젝트는 GPU 환경에서 수행되며, Python 3.9 및 PyTorch 2.0을 기반으로 구현됨
- 결과 수치는 2차 보고서에 반영 예정 (정확도, Catastrophic Forgetting 완화 수치 포함)
- 실험 reproducibility를 위해 random seed 고정, log 저장 자동화, 모델 저장 경로 구조 통일
- 향후 다양한 Continual Learning 기법(e.g., MAS, SI, rehearsal)과 비교 실험 계획 중*  |

<br>
