{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.legacy import Adamax\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model \n",
    "from Model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ewc\n",
    "from ewc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(model, OPTIMIZER, MAX_LABEL, data, test_size,\n",
    "                first_task = 44, inc_task = 5, first_epochs = 30, inc_epochs = 5,\n",
    "                  lamb=0, num_sample=10):\n",
    "    \n",
    "    first_part = split_by_label(data, 0, first_task)\n",
    "    train, test = split_train_test(first_part, test_size=test_size, random_state=11)\n",
    "    \n",
    "    weights = model.trainable_weights\n",
    "    fisher_matrix = [tf.zeros_like(w) for w in weights]\n",
    "\n",
    "    output = []\n",
    "\n",
    "    # OPTIMIZER -> param\n",
    "    i = 0\n",
    "    while(1):\n",
    "\n",
    "        if ( first_task + i * inc_task ) < MAX_LABEL:\n",
    "            \n",
    "            if i == 0:\n",
    "                model.compile(loss=ewc_loss(model, fisher_matrix, lamb=lamb), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "                # 3D ndarray 로 변환 \n",
    "                train_seq, train_label = to_input(train, MAX_LABEL)\n",
    "\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=first_epochs, verbose=2)\n",
    "\n",
    "                test_seq, test_label = to_input(test, MAX_LABEL)\n",
    "                loss, accuracy = model.evaluate(test_seq, test_label, batch_size=32, verbose=1)\n",
    "                print(f\"Task_0 training accuracy: {accuracy:.4f}\")\n",
    "                output.append(f'task_{i} accuracy : {accuracy:.4f}')\n",
    "\n",
    "                # Fisher matrix 계산 \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "            else:\n",
    "                # 데이터 준비 \n",
    "                inc_part = split_by_label(data, first_task + (i-1) * inc_task + 1, first_task + i * inc_task )\n",
    "                train, inc_test = split_train_test(inc_part, test_size=test_size, random_state=11)\n",
    "                \n",
    "                train_seq, train_label = to_input(train, MAX_LABEL)\n",
    "\n",
    "                # train\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=inc_epochs, verbose=2)\n",
    "\n",
    "                inc_test_seq, inc_test_label = to_input(inc_test, MAX_LABEL)\n",
    "                loss, inc_accuracy = model.evaluate(inc_test_seq, inc_test_label, batch_size=32, verbose=1)\n",
    "\n",
    "                print(f\"Task_{i} accuracy: {inc_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "                test_seq, test_label = to_input(test, MAX_LABEL)\n",
    "\n",
    "                loss, accuracy = model.evaluate(test_seq, test_label, batch_size=32, verbose=1)\n",
    "                print(f\"Task ~{i-1} accuracy after training on Task_{i}: {accuracy:.4f}\")\n",
    "                output.append(f'task_{i-1} accuracy on task_{i}: {accuracy:.4f}')\n",
    "                \n",
    "                # test 업데이트 \n",
    "                test = accumulate_data(test, inc_test)\n",
    "\n",
    "                # Fisher matrix 계산 \n",
    "                fisher_matrix = compute_fisher_matrix(model, inc_test_seq, num_sample=len(inc_test_seq))\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "        else:\n",
    "            print(output)\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_nonbase_AB(model, OPTIMIZER, data, test_size, task_A, task_B,\n",
    "                      MAX_LABEL, epochs_A, epochs_B):\n",
    "\n",
    "    model.compile(loss=CategoricalCrossentropy(from_logits=False), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "    ###### task A\n",
    "    part_A = split_by_label(data, 0, task_A)\n",
    "    train_A, test_A = split_train_test(part_A, test_size=test_size, random_state=11)\n",
    "\n",
    "    train_A_seq, train_A_label = to_input(train_A, MAX_LABEL = MAX_LABEL)\n",
    "\n",
    "    history = model.fit(x=train_A_seq, y=train_A_label, epochs=epochs_A, verbose=2)\n",
    "\n",
    "    test_A_seq, test_A_label = to_input(test_A, MAX_LABEL = MAX_LABEL)\n",
    "    loss, accuracy = model.evaluate(test_A_seq, test_A_label, batch_size=32, verbose=1)\n",
    "\n",
    "    print(f\"\\ntask A Test Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "    ###### task B\n",
    "    part_B = split_by_label(data, task_A+1, task_A+task_B)\n",
    "    train_B, test_B = split_train_test(part_B, test_size=test_size, random_state=11)\n",
    "\n",
    "    train_B_seq, train_B_label = to_input(train_B, MAX_LABEL = MAX_LABEL)\n",
    "\n",
    "    history = model.fit(x=train_B_seq, y=train_B_label, epochs=epochs_B, verbose=2)\n",
    "\n",
    "    test_B_seq, test_B_label = to_input(test_B, MAX_LABEL = MAX_LABEL)\n",
    "    loss, accuracy = model.evaluate(test_B_seq, test_B_label, batch_size=32, verbose=1)\n",
    "\n",
    "    print(f\"\\ntask B Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_A_seq, test_A_label, batch_size=32, verbose=1)\n",
    "    print(f\"\\nforgetted Accuracy: {accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop_with_val(model, OPTIMIZER, MAX_LABEL, data, test_size, \n",
    "                first_task = 44, inc_task = 5, first_epochs = 30, inc_epochs = 5,\n",
    "                  lamb=0, num_sample=10):\n",
    "    \n",
    "    first_part = split_by_label(data, 0, first_task)\n",
    "    train, test = split_train_test(first_part, test_size=test_size, random_state=11)\n",
    "    \n",
    "    weights = model.trainable_weights\n",
    "    fisher_matrix = [tf.zeros_like(w) for w in weights]\n",
    "\n",
    "    output = []\n",
    "\n",
    "    # OPTIMIZER -> param\n",
    "    i = 0\n",
    "    while(1):\n",
    "\n",
    "        if ( first_task + i * inc_task ) < MAX_LABEL:\n",
    "            \n",
    "            if i == 0:\n",
    "                model.compile(loss=ewc_loss(model, fisher_matrix, lamb=lamb), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "                # 3D ndarray 로 변환 \n",
    "                train_seq, train_label = to_input(train, MAX_LABEL)\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=first_epochs, verbose=2)\n",
    "\n",
    "                test_seq, test_label = to_input(test, MAX_LABEL)\n",
    "                loss, accuracy = model.evaluate(test_seq, test_label, batch_size=32, verbose=1)\n",
    "\n",
    "                print(f\"Task_0 training accuracy: {accuracy:.4f}\")\n",
    "                output.append(f'task_{i} accuracy : {accuracy:.4f}')\n",
    "\n",
    "                # Fisher matrix 계산 \n",
    "                fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=num_sample)\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "            else:\n",
    "                # 데이터 준비 \n",
    "                inc_part = split_by_label(data, first_task + (i-1) * inc_task + 1, first_task + i * inc_task )\n",
    "                train, inc_test = split_train_test(inc_part, test_size=test_size, random_state=11)\n",
    "                \n",
    "                train_seq, train_label = to_input(train, MAX_LABEL)\n",
    "\n",
    "                # train\n",
    "                history = model.fit(x=train_seq, y=train_label, epochs=inc_epochs, verbose=2)\n",
    "\n",
    "                inc_test_seq, inc_test_label = to_input(inc_test, MAX_LABEL)\n",
    "                loss, inc_accuracy = model.evaluate(inc_test_seq, inc_test_label, batch_size=32, verbose=1)\n",
    "\n",
    "                print(f\"Task_{i} accuracy: {inc_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "                test_seq, test_label = to_input(test, MAX_LABEL)\n",
    "\n",
    "                loss, accuracy = model.evaluate(test_seq, test_label, batch_size=32, verbose=1)\n",
    "                print(f\"Task ~{i-1} accuracy after training on Task_{i}: {accuracy:.4f}\")\n",
    "                output.append(f'task_{i-1} accuracy on task_{i}: {accuracy:.4f}')\n",
    "                \n",
    "                # test 업데이트 \n",
    "                test = accumulate_data(test, inc_test)\n",
    "\n",
    "                # Fisher matrix 계산 \n",
    "                fisher_matrix = compute_fisher_matrix(model, inc_test_seq, num_sample=len(inc_test_seq))\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "        else:\n",
    "            print(output)\n",
    "            break "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naivis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
