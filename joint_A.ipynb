{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.legacy import Adamax, Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "\n",
    "import Model \n",
    "from Model import *\n",
    "\n",
    "import ewc\n",
    "from ewc import *\n",
    "\n",
    "import utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('mon_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 빌드 \n",
    "model = DFNet.build(input_shape=(10000, 1), classes=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adamax.py:99: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Training the DF model\n",
    "NB_EPOCH = 30   # Number of training epoch\n",
    "BATCH_SIZE = 128 # Batch size\n",
    "VERBOSE = 2 # Output display mode\n",
    "LENGTH = 10000 # Packet sequence length\n",
    "OPTIMIZER = Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) # Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "print (\"Model compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 35s 101ms/step - loss: 3.9484 - accuracy: 0.0656\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 24s 98ms/step - loss: 3.3720 - accuracy: 0.1328\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 2.9949 - accuracy: 0.2118\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 2.7150 - accuracy: 0.2673\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 2.4892 - accuracy: 0.3192\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 2.3230 - accuracy: 0.3625\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 26s 102ms/step - loss: 2.1502 - accuracy: 0.4124\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 27s 108ms/step - loss: 1.9771 - accuracy: 0.4636\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 1.8201 - accuracy: 0.5009\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 24s 98ms/step - loss: 1.6610 - accuracy: 0.5514\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 1.5202 - accuracy: 0.5859\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 24s 98ms/step - loss: 1.3733 - accuracy: 0.6261\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 1.2771 - accuracy: 0.6601\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 25s 98ms/step - loss: 1.1811 - accuracy: 0.6777\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 24s 97ms/step - loss: 1.0718 - accuracy: 0.7147\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - 24s 97ms/step - loss: 0.9798 - accuracy: 0.7396\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - 25s 98ms/step - loss: 0.8854 - accuracy: 0.7615\n",
      "Epoch 18/30\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.8393 - accuracy: 0.7784\n",
      "Epoch 19/30\n",
      "250/250 [==============================] - 24s 96ms/step - loss: 0.7784 - accuracy: 0.7908\n",
      "Epoch 20/30\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.7226 - accuracy: 0.8066\n",
      "Epoch 21/30\n",
      "250/250 [==============================] - 24s 98ms/step - loss: 0.6745 - accuracy: 0.8194\n",
      "Epoch 22/30\n",
      "250/250 [==============================] - 25s 98ms/step - loss: 0.6111 - accuracy: 0.8335\n",
      "Epoch 23/30\n",
      "250/250 [==============================] - 24s 98ms/step - loss: 0.5693 - accuracy: 0.8453\n",
      "Epoch 24/30\n",
      "250/250 [==============================] - 24s 98ms/step - loss: 0.5416 - accuracy: 0.8559\n",
      "Epoch 25/30\n",
      "250/250 [==============================] - 24s 96ms/step - loss: 0.5122 - accuracy: 0.8677\n",
      "Epoch 26/30\n",
      "250/250 [==============================] - 24s 98ms/step - loss: 0.4594 - accuracy: 0.8770\n",
      "Epoch 27/30\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 0.4466 - accuracy: 0.8764\n",
      "Epoch 28/30\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 0.4253 - accuracy: 0.8863\n",
      "Epoch 29/30\n",
      "250/250 [==============================] - 24s 96ms/step - loss: 0.3997 - accuracy: 0.8924\n",
      "Epoch 30/30\n",
      "250/250 [==============================] - 25s 98ms/step - loss: 0.3798 - accuracy: 0.8997\n",
      "\n",
      "[DEBUG] Fisher matrix shapes:\n",
      " - Fisher 0: (8, 1, 32), mean=59.95643997\n",
      " - Fisher 1: (32,), mean=1770.85131836\n",
      " - Fisher 2: (32,), mean=10.68133926\n",
      " - Fisher 3: (32,), mean=141.64134216\n",
      " - Fisher 4: (8, 32, 32), mean=0.84478772\n",
      " - Fisher 5: (32,), mean=6.01293373\n",
      " - Fisher 6: (32,), mean=9.84707642\n",
      " - Fisher 7: (32,), mean=12.91234589\n",
      " - Fisher 8: (8, 32, 64), mean=0.29403460\n",
      " - Fisher 9: (64,), mean=0.32896209\n",
      " - Fisher 10: (64,), mean=4.05485344\n",
      " - Fisher 11: (64,), mean=2.70062065\n",
      " - Fisher 12: (8, 64, 64), mean=0.09325447\n",
      " - Fisher 13: (64,), mean=0.22476304\n",
      " - Fisher 14: (64,), mean=2.53345442\n",
      " - Fisher 15: (64,), mean=1.40241480\n",
      " - Fisher 16: (8, 64, 128), mean=0.04202088\n",
      " - Fisher 17: (128,), mean=0.02580252\n",
      " - Fisher 18: (128,), mean=1.03844011\n",
      " - Fisher 19: (128,), mean=1.03355205\n",
      " - Fisher 20: (8, 128, 128), mean=0.01883314\n",
      " - Fisher 21: (128,), mean=0.04212907\n",
      " - Fisher 22: (128,), mean=1.11287165\n",
      " - Fisher 23: (128,), mean=0.39573461\n",
      " - Fisher 24: (8, 128, 256), mean=0.00971481\n",
      " - Fisher 25: (256,), mean=0.00925919\n",
      " - Fisher 26: (256,), mean=0.51105207\n",
      " - Fisher 27: (256,), mean=0.30458686\n",
      " - Fisher 28: (8, 256, 256), mean=0.00643342\n",
      " - Fisher 29: (256,), mean=0.01723637\n",
      " - Fisher 30: (256,), mean=0.78152913\n",
      " - Fisher 31: (256,), mean=0.50153780\n",
      " - Fisher 32: (8, 256, 512), mean=0.00485562\n",
      " - Fisher 33: (512,), mean=0.01015485\n",
      " - Fisher 34: (512,), mean=0.37704358\n",
      " - Fisher 35: (512,), mean=0.32888237\n",
      " - Fisher 36: (8, 512, 512), mean=0.00292616\n",
      " - Fisher 37: (512,), mean=0.01743780\n",
      " - Fisher 38: (512,), mean=0.59917116\n",
      " - Fisher 39: (512,), mean=0.38042653\n",
      " - Fisher 40: (5120, 512), mean=0.00474568\n",
      " - Fisher 41: (512,), mean=0.01074584\n",
      " - Fisher 42: (512,), mean=0.22222275\n",
      " - Fisher 43: (512,), mean=0.22986224\n",
      " - Fisher 44: (512, 512), mean=0.01298640\n",
      " - Fisher 45: (512,), mean=0.06174748\n",
      " - Fisher 46: (512,), mean=0.13159576\n",
      " - Fisher 47: (512,), mean=0.25409362\n",
      " - Fisher 48: (512, 95), mean=0.24308673\n",
      " - Fisher 49: (95,), mean=1.11835265\n",
      "Data_A training accuracy: 0.8997\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)  # 즉시 실행 모드 강제\n",
    "\n",
    "first_part = split_by_label(data, 0, 49)\n",
    "train, test = split_train_test(first_part, test_size=0.2, random_state=11)\n",
    "\n",
    "# 3D ndarray 로 변환 \n",
    "train_seq, train_label = split_data_label(train)\n",
    "\n",
    "train_seq = np.stack(train_seq.values)\n",
    "train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "train_label = train_label.values\n",
    "train_label = to_categorical(train_label, num_classes=95)\n",
    "                \n",
    "\n",
    "history = model.fit(x=train_seq, y=train_label, epochs=30, verbose=1)\n",
    "optimal_weights = [w.numpy() for w in model.trainable_weights]\n",
    "fisher_matrix = compute_fisher_matrix(model, train_seq, num_sample=1000)\n",
    "\n",
    "print(f\"Data_A training accuracy: {history.history['accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# HDF5 형식으로 저장\n",
    "save_model(model, 'joint_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\nAIvis\\lib\\site-packages\\numpy\\lib\\npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "np.save('fisher_matrix.npy', fisher_matrix)\n",
    "np.save('optimal_weights.npy', optimal_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nAIvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
