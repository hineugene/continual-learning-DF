{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.legacy import Adamax, Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "\n",
    "import Model \n",
    "from Model import *\n",
    "\n",
    "import utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('mon_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델 로드\n",
    "model = load_model('nonbase_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 출력층 제거\n",
    "model.pop()  # softmax 레이어 제거\n",
    "model.pop()  # Dense(50) 레이어 제거\n",
    "\n",
    "# 새로운 출력층 추가 (45개 뉴런)\n",
    "model.add(Dense(45, activation='softmax', name='new_output'))\n",
    "\n",
    "# 모델 재컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "225/225 [==============================] - 17s 51ms/step - loss: 2.1619 - accuracy: 0.4526\n",
      "Epoch 2/50\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.8699 - accuracy: 0.7557\n",
      "Epoch 3/50\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.5152 - accuracy: 0.8599\n",
      "Epoch 4/50\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.3834 - accuracy: 0.8944\n",
      "Epoch 5/50\n",
      "225/225 [==============================] - 12s 51ms/step - loss: 0.3106 - accuracy: 0.9108\n",
      "Epoch 6/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.2596 - accuracy: 0.9276\n",
      "Epoch 7/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.2285 - accuracy: 0.9354\n",
      "Epoch 8/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1992 - accuracy: 0.9439\n",
      "Epoch 9/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1850 - accuracy: 0.9469\n",
      "Epoch 10/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1773 - accuracy: 0.9479\n",
      "Epoch 11/50\n",
      "225/225 [==============================] - 12s 51ms/step - loss: 0.1533 - accuracy: 0.9576\n",
      "Epoch 12/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1249 - accuracy: 0.9640\n",
      "Epoch 13/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1249 - accuracy: 0.9639\n",
      "Epoch 14/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1346 - accuracy: 0.9619\n",
      "Epoch 15/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1289 - accuracy: 0.9607\n",
      "Epoch 16/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.1177 - accuracy: 0.9642\n",
      "Epoch 17/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1355 - accuracy: 0.9607\n",
      "Epoch 18/50\n",
      "225/225 [==============================] - 12s 51ms/step - loss: 0.0968 - accuracy: 0.9708\n",
      "Epoch 19/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1005 - accuracy: 0.9715\n",
      "Epoch 20/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0806 - accuracy: 0.9756\n",
      "Epoch 21/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0877 - accuracy: 0.9740\n",
      "Epoch 22/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0836 - accuracy: 0.9750\n",
      "Epoch 23/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0800 - accuracy: 0.9753\n",
      "Epoch 24/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0926 - accuracy: 0.9735\n",
      "Epoch 25/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0867 - accuracy: 0.9744\n",
      "Epoch 26/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0890 - accuracy: 0.9737\n",
      "Epoch 27/50\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0781 - accuracy: 0.9769\n",
      "Epoch 28/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0729 - accuracy: 0.9785\n",
      "Epoch 29/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0622 - accuracy: 0.9829\n",
      "Epoch 30/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0595 - accuracy: 0.9821\n",
      "Epoch 31/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0775 - accuracy: 0.9781\n",
      "Epoch 32/50\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0724 - accuracy: 0.9779\n",
      "Epoch 33/50\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0645 - accuracy: 0.9790\n",
      "Epoch 34/50\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0799 - accuracy: 0.9754\n",
      "Epoch 35/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0784 - accuracy: 0.9782\n",
      "Epoch 36/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0552 - accuracy: 0.9843\n",
      "Epoch 37/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0637 - accuracy: 0.9804\n",
      "Epoch 38/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0645 - accuracy: 0.9812\n",
      "Epoch 39/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0522 - accuracy: 0.9843\n",
      "Epoch 40/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0426 - accuracy: 0.9874\n",
      "Epoch 41/50\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0467 - accuracy: 0.9861\n",
      "Epoch 42/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0534 - accuracy: 0.9853\n",
      "Epoch 43/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0423 - accuracy: 0.9861\n",
      "Epoch 44/50\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0596 - accuracy: 0.9819\n",
      "Epoch 45/50\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0555 - accuracy: 0.9847\n",
      "Epoch 46/50\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0706 - accuracy: 0.9799\n",
      "Epoch 47/50\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0454 - accuracy: 0.9860\n",
      "Epoch 48/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0528 - accuracy: 0.9851\n",
      "Epoch 49/50\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0449 - accuracy: 0.9867\n",
      "Epoch 50/50\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0361 - accuracy: 0.9885\n",
      "Data_A training accuracy: 0.9885\n"
     ]
    }
   ],
   "source": [
    "second_part = split_by_label(data, 50, 94)\n",
    "train, test = split_train_test(second_part, test_size=0.2, random_state=11)\n",
    "\n",
    "# 3D ndarray 로 변환 \n",
    "train_seq, train_label = split_data_label(train)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 레이블을 0~44 범위로 재인덱싱\n",
    "le = LabelEncoder()\n",
    "train_label = le.fit_transform(train_label)\n",
    "\n",
    "train_seq = np.stack(train_seq.values)\n",
    "train_seq = train_seq[..., np.newaxis]\n",
    "\n",
    "# train_label = train_label.values\n",
    "train_label = to_categorical(train_label, num_classes=45)\n",
    "                \n",
    "\n",
    "history = model.fit(x=train_seq, y=train_label, epochs=50, verbose=1)\n",
    "print(f\"Data_A training accuracy: {history.history['accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 95개의 클래스로 model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 출력층 제거\n",
    "model.pop()  # softmax 레이어 제거\n",
    "model.pop()  # Dense(45) 레이어 제거\n",
    "\n",
    "# 새로운 출력층 추가\n",
    "model.add(Dense(95, activation='softmax', name='new_output'))\n",
    "\n",
    "# 모델 재컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594/594 [==============================] - 12s 19ms/step - loss: 4.9399 - accuracy: 0.0036\n",
      "[4.939947605133057, 0.003631578991189599]\n"
     ]
    }
   ],
   "source": [
    "test_seq, test_label = split_data_label(data)\n",
    "test_seq = np.stack(test_seq.values)\n",
    "test_seq = test_seq[..., np.newaxis]\n",
    "\n",
    "test_label = test_label.values\n",
    "test_label = to_categorical(test_label, num_classes=95)\n",
    "\n",
    "test = tf.data.Dataset.from_tensor_slices((test_seq, test_label))\n",
    "test = test.batch(32) #(수정) 모델 자체 배치 존재? - 학습시 fit 디폴트값도 32\n",
    "\n",
    "final_accuracy = model.evaluate(test)\n",
    "print(final_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
